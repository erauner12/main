---
up: "[[2024-W43]]"
description: ""
publish: false
starred: false
status: ""
type: note
tags:
  - periodic/daily
cssclasses:
  - "cards"
  - "cards-cols-1"
obsidianUIMode: source
obsidianEditingMode: live
template: "[[Daily]]"
created: 20241024110523
modified: 20241025095801
aliases:
  - Thursday - October 24th 2024
linter-yaml-title-alias: Thursday - October 24th 2024
title: Thursday - October 24th 2024
id: 10
week: "[[2024-W43]]"
yearly: "[[2024]]"
quarterly: "[[2024-Q4]]"
monthly: "[[2024-10]]"
daily: "[[2024-10-24]]"
month: "October"
weekday: Thursday
---

# Thursday - October 24th 2024

## Memos Personal

## Memos Work

## Working On

---

```
I need to make changes to my pull request regarding MecBounceNode. This process involves Kubernetes, where we have a running resource and a Python-based task that deletes the pod and waits for it to restart. I have some context on how this works through the code and diagrams, which I want to keep synchronized and up to date, as they provide a clear visualization of the process.

Based on the feedback I’ve received, I’ve captured insights in transcripts. I want to compile the most important points from these transcripts, focusing on the most relevant information. I will provide a series of transcripts, starting with the most recent ones, followed by those from the past ten days. We will aim to assimilate what changes to make to the existing code while prioritizing a simplified flow, considering that other tools can assist.

The transcripts I provide will cover various topics, but please focus only on references to the MecBounceNode task and the startup probe with ArgoCD on express (operator) nodes/pods, as they are interconnected. All other information should be considered only for context.

For context, the express operator is a kubernetes operator that manages the pods that are running our application but a pod is a pod. The prod deployer is the old tool that is being replaced by the helm chart to manipulate the custom resources that gives us the pods (that we are bouncing).

This is generally the current flow right now, which is intentionally thorough, so that we know what avenues to consider as we settle on the changes that we end up making:
- The information in the transcripts is likely to conflict with this diagram, and should for a good reason. I am trying to mold it into what the task should actually be concerned with based on the feedback.

the goal is to chip away at what we might not need in the task and identify what we do actually need. And help let this be the decision to make changes

the bounce actually works right now but I would like to align it closer to what it should actually be looking like.
```

https://claude.ai/chat/b82769cc-3efe-4160-8db3-abc2678721cd

```
- Better shutdown protection checking
- All the state tracking/continuation logic
- Startup probe time calculations
- Consistently using wait_till_ok
- Comprehensive stuck state detection
```

- This is in  
    …

```
1. Node state checking and monitoring
2. Pod termination handling with stuck detection
3. Cache rebuild status tracking
4. The main perform() method with all the logic tied together
```

- [ ] If the node is rebuilding, we should not restart it unless it is forced. We should let the user know the node is rebuilding and that we would advise that you not
- [ ] But there is a difference between rebuilding and catchup/efficient catchup.
- [ ] There is a difference between a pod being down and not existing at all (always take state into consideration). Also whether or not the custom resource for that pod even exists.
- [ ] We should probably be using the step state to determine what to do next

---

1. Core Functionality Should Be Simple:

- Stop node, start it back up
- Wait for a specified period (default ~10 minutes)
- Success = Pod restarts within time window
- Don't overcomplicate with extra monitoring/status

1. Startup Probe & Node States:

- Use startup probe instead of complex status checking
- If node state is down/non-existent, fail early
- In GitOps, down state is intentional and shouldn't be overridden

1. Shutdown Protection Handling:

- Try to disable shutdown protection as best effort
- If can't disable, notify user and proceed with pod deletion
- Don't force delete pods
- Frontend pods shut down quickly, backends may take longer

1. Status Reporting:

- Keep status updates focused on just the bounce operation
- Don't try to monitor entire cluster state
- Let separate monitoring/alerting handle broader status

---

1. Simplified State Machine:

- Reduced states to core pod lifecycle stages
- Removed monitoring complexity
- Focused on pod operations only

1. Enhanced Init Checks:

- Added explicit check for node down state
- Fails early if node shouldn't be bounced
- Maintains existing safety checks

1. Updated Diagram:

- Shows streamlined flow
- Focuses on core operations
- Clear success/failure paths

1. Built-in Timeouts:

- Added default timeouts in config
- 10 minutes for pod termination
- 10 minutes for pod readiness

```
well yes, I think probably both though. Because not all pods that we see will have startup probes, but if they are gitops clusters

def is_k8s_gitops(self) -> bool:

return self.cluster_type == ExpressClusterType.K8S_GITOPS

…

we will be able to use this, but I think regardless of whether or not they are gitops or not. after this is confirmed.

we should check whether or not
```

[gist:fb5f64e4dff26c2a431c70f9bfa9bf6a](https://github.medallia.com/gist/erauner/fb5f64e4dff26c2a431c70f9bfa9bf6a)


https://claude.ai/chat/b82769cc-3efe-4160-8db3-abc2678721cd
