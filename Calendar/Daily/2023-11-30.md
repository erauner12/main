---
id: 9
up: "[[2023-W48]]"
description: ""
publish: false
starred: false
status: ""
type: note
tags:
  - periodic/daily
cssclasses:
  - "cards"
  - "cards-cols-1"
obsidianUIMode: source
obsidianEditingMode: live
template: "[[Daily]]"
created: 20231130000100
modified: 20231201000100
aliases:
  - Thursday - November 30th 2023
linter-yaml-title-alias: Thursday - November 30th 2023
title: Thursday - November 30th 2023
week: "[[2023-W48]]"
yearly: "[[2023]]"
quarterly: "[[2023-Q4]]"
monthly: "[[2023-11]]"
daily: "[[2023-11-30]]"
month: "November"
weekday: Thursday
---

# Thursday - November 30th 2023

## Tasks

%% TCT_TEMPLATED_START 2023-11-30 00:00 %%
* Recurring
    - [x] Gratitude - Morning ✅2023-11-30
    - [x] Start Cook/Eat Breakfast ✅2023-11-30
    - [x] Take Vitamins ✅2023-11-30
    - [x] Check Calendar for what events are occuring ✅2023-11-30
    - [x] Fill Up/Drink Water Bottles ✅2023-11-30  
%% TCT_TEMPLATED_END 2023-11-30 23:59 %%
* ? Did these tasks align to your Goals?

# Rollover

# Daily Notes


Yeah, like, it will, so Argo events will be like the dedicated, like, component that receives instead of the application itself, and then the application will be, like, responsible for actually, like, taking the messages that were, like, received by Argo events, and then, like, turned into a message themselves. So, because, because then we, then, but, and that's, in that way, we're not actually ever missing anything. We're creating, like, a, like a, like a, like an event queue for everything that comes in. An event for everything that is coming in, right? Yeah, like, each event, whether it be, like, a, whether it be, like, a webhook or something different is going to be, like, the, like, we're, we're, but we're not going to, like, receive the, the, the webhook, like, directly. We're going to receive, we'll be getting it from, like, like, what is it called? I can't remember. I don't know why. I can't remember. What we have in between Argo events and the, like, event manager, like, part of the application. Why is it, why is it can't, what was that called? I need to look at the design document again. I learned my engineering. No, hold on. Sorry. Let me look at this. I'm looking at, okay, so the processing. Where is the diagram? Kafka. Yeah. Okay. So, Argo, Argo events will receive the event itself, and then a Kafka message will be made out of that, out of that event. And then, like, that's where SRE router, like, begins. I'll show you. Don't you think that will be, like, too many applications to handle for the router? I mean, router being one of its own application, right? Then there will be a different deployment for Argo events. That will be another thing that will be taken care of. Yeah. Yeah. So, can't we just have our own router and it receives the alerts directly? Or event, Argo events will help us in queuing it up, and we don't miss anything. That's basically what, that's what's happening, yeah. I mean, that's, I think that's what would be ideal. Otherwise, we would have to build that, we would have to build that somehow into the router, which I would, I feel like. Yeah, like, I don't want to have to be responsible for that. If something gets missed, you know, yes, what we will have the ability to do is still have, like, a Slack, like, message go, like, to a channel. But ideally, like, we don't want, we, then we would have to know which ones were missed and then go find those. We, like, we want to rely on a single place. And if we're, like, SRE router, for whatever reason, missed a message, then we're kind of screwed. Like, I mean, yes, it's doing what it's supposed to be doing most of the time, but it, it lacks resilience. If we're not able to have something to manage that portion for us, which I think this is what that is. Yeah, that does make sense. And we will also be receiving Slack and that. Okay, so are we done with the document? I mean, have we finalized it? Or have we started building anything around a SRE router? No, I haven't. I haven't. I've been working on other things, but I need to get back to it. We did create some JIRAs. But I haven't. No, I haven't started it yet. Do you think that I can or anyone from our team can contribute to it and we can have some JIRAs? Yeah, if you want to go ahead. Yeah, sure. I actually, you know, I want to. Because we have been talking about this. Yeah, yeah, absolutely. If there's any JIRAs you want to create towards the Epic, then, then feel free. No, but I want to know, like, how we are planning to, you know, approach this because I don't like, to be honest, I don't know how we are, you know, starting with it. Yeah. Events part, okay, Kamil has set it up. But about SRE router, like, what are the modules that we want to build? If we are building different services for it? Yeah. And how our architecture will be? That's kind of what we're still in the process of getting together. Like, I think the problem has basically been that we are, like, Varsamis is in the process of, like, getting the provisioning in G, like, cleaned up. And he's been at capacity. And I've also, like, been working on DCR. So that's, that's what's put a halt to it for right now. Like, it's not at a halt, but I just haven't made any progress. And that's why. Okay, so Varsamis, I can have a word with Varsamis tomorrow, because he comes in some more time between that, like, my working hours. Okay. I can, I'll talk to him. I'll see where it is going and how I can contribute to it. Okay. Yeah, go ahead, man. Okay. Okay. Do we have anyone else? Do we have any other things that we discussed today? Oh, I don't think so, man. I don't have anything. I just, yeah, that's mostly been kind of focusing on other other things the past couple of weeks. So you have been busy with some other stuff? Yeah, nothing with the router, because I want to work on the router. But like, the DCR, there's been a lot of changes to it that I've needed to, like, been working with the platform team to, like, test those changes. So that DC, because ultimately, like, what I want to be able to feed into router, just as I want to be able to feed alerts in, like, my prerogative is that I like, for my own selfish reasons, I want to, I want to point, I want to point requests that are DCR tickets into the router as well, because I don't, I don't think the current mechanism is, is that great? It's, it's great.


---


So this service account won't be just used in the router. We can also use it for any other automations that we think we need to do around SRE. I see what you're saying. Yeah. Well, I guess technically, yes, you could do that. But that's what the SRA API is for. It has all of it. Like all of that can be done within the scope of a task without needing to do it. You don't need to recreate your own service account for that, again. Yeah. I mean, yeah. It's just, ideally, the router won't have to care about how anything is done. It just needs to know what the source is and what needs to happen as a result of it. It doesn't need to know how to do it. But if we are defining some process to mitigate some issue, we need to have a template for that, right? Because that is how we are going to distribute it to other teams, right? Like how they can use it. Yeah. And that's kind of what the SRA API is. Yeah. Yeah. We need to get Camil. Here. Is Camil here? Yeah. Camil is here. So, Camil. Real nice. Hey, Camil, I'm glad you're here. Yeah, that's great. You joined on time. All right. Okay. Camil, I think he works around in my time. I'll be talking to him tomorrow. Which region is he in? He's in the Czech Republic. His time zone is, like, you know, overlapping with yours more so than mine. Like, the beginning of my day is the end of his. Ah, okay. Okay. Okay. So, for me, he is, I think, nine, five hours behind me. Four and a half hours. Okay. I can connect with him. I'll talk to him tomorrow. Then I can set a meeting with him. And do you want me to involve you as well for that? Or do you already know everything around SRAP? Yeah. I am aware of it. If you want, and if it's out of time, that makes sense for me, then, yeah, sure, invite me. But, like, I've been working, like, I'm working on, I'm working with him on it. So, it's a. Yeah. Sure, I'll talk to him tomorrow. I'll talk with him tomorrow, and then I'll set up something for next week. Okay. For SRAP, can you share the EPIC with me for that? Mm-hmm. But I don't know what tasks I need to talk to. And there was another thing that I wanted to share with you. Yeah, I saw that you made some changes to this cashier-abled code, but that PR was never merged. No, we need to get rid of that. The thing is, the code that anything related to a job that is not, like, a cron job that is doing, like, a cron job that is doing something, like, that's, like, you know, cleaning up channels or whatever, that should stay. But anything related to a job, an SRA router, like, that is something, like, for a cash rebuild, like, that needs to go. In fact, that's why I'm doing DCR, because I don't think the job, like, SRA bot shouldn't be doing that. Like, that's why the SRA API exists, is so that we can take the, there is no need for a job to exist, like, that some application has to keep track of doing that thing. Like, that's, we'll create the jobs. Okay, okay. So this PR that I see, I think it's very old. Yeah. So should I close this? Yeah, yeah, just close it. Okay, but when the cash rebuild command is now triggered, it is just for status, right? Mm hmm. So when this is triggered and the changes that you made, so these are not relevant anymore? Well, for DCR, the reason I was trying to get it to work is for DCR. And unfortunately, the way that DCR works, unless the SRA bot has access to the Kubernetes, like, you have to have access to the Kubernetes, like, roles. Yeah, like, because we need to be able to get, like, we can't reach it through command center. We need to reach it directly, like, through, like, a tunnel. And we don't have that ability, right, as far as I'm aware, from SRA bot. So that's where I got stuck. Okay. So like, what I'm going to do, and I actually have a JIRA open for right now is I'm just going to monitor the progress of the cash rebuilds. Like, with the job, the job will continue to persist until the cash rebuild is done, even if it takes like, you know, two, three days. Okay. But for SRA bot, that is just to check the status, whether it is running or not. But for that, also, you're saying that we need that Kubernetes direct access? I believe we do. Yeah. And I guess what I'm getting at is that, yes, it's nice that SRA bot can check the status. But what I'd like to do is move that, the logic that is checking the status directly to the job should, since it's already checking the progress and the status, it should be also, like, if it's going to update Slack, the job should be updating Slack, not some external thing that's checking it. So I want SRA bot to not even have to care about this. Okay, so we need to, so basically, SRA bot will connect with SRA API, get the data and then display it, something like that? Yeah, but SRA bot's not going to, but I mean, well, technically, it could, if we want it to. Because I can, I can make that, like, progress, like available via the SRA API, like. But I'm thinking more of something like the job, like, I'm thinking that I can just update a particular, like, channel with the job. And then the progress, because really, what's the point of checking the progress, right, to see if it's done until it's, until it fails? Like, I think what's more, less important is what the progress is and whether or not it failed. And so I'm trying to set up a way to be able to easily know what DCRs are in progress, which ones have failed, like, which ones do we need to restart? So that we don't need to sit here and have, like, a cron job telling us what the progress is of, like, multiple cache rebuilds. Like, that's kind of just, like, in my opinion, like, not, it's not necessary, you know? Okay, understood. But it don't, it has been necessary, because it's a long, it's something that takes a long time to do, and it's easy to lose track of. And that's why it was built into SRE bot. But if we, if we have a dedicated job to accomplish it, then it won't, I don't think we'll need something external like that. Okay. No, because Elvin and I think some people from release management are still using that command. They are. So yeah, for regular cache rebuilds. So I think probably the command should continue to work, but not for DCR. It should just continue to work for regular cache rebuilds until DCR becomes the, like, the main way that cache rebuilds are done. Which eventually probably will be the case, but it's not right now. Understood. Okay. It's still being kind of built. Okay. Okay, got it. So, cool. Then I'll talk with Kamil for SRE APIs tomorrow. And I'll talk with Varsamis for the router part, like, if it needs any help from us, or we can contribute in any way to that. Other than that, I don't have anything else to discuss today. Do you want to discuss anything? Yeah, I don't have much. I think whatever JIRAs we end up creating for, like, the SRE router, like, portion, like, let's work on creating those JIRAs together. Yeah. Because I think, like, right now, the JIRAs we've created have basically just been to, like, start the portion that's on the left side of the diagram. But, yeah, like, I think we also need to, and what really, we did create one JIRA, phase one SRE router consumer and processor. That's all we've created for this one right here. But we need to break that down into more pieces. So, yeah, I'd like to, I mean, I'd like to be a part of that as well. I just don't know exactly what pieces to break it up into yet. But, yeah, let's get it done. Let's get it done within the next couple of weeks. Okay. So we can meet up next week to decide on the JIRAs part.


---


## Notes


The main objective is to synchronize changes selectively, preferably while retaining the option of self-healing.


[Argo CD and Release Management with Helm Charts and ApplicationSets](https://cloud.redhat.com/blog/argo-cd-and-release-management-with-helm-charts-and-applicationsets#:~:text=The%20simple%20solution%20is%20to,targetRevision%20for%20each%20cluster%20separately)
* This could allow us to control the targetRevision per express instance from a single `targets.yaml` file.
* This actually could better solve the problem I am facing that turning selfHeal to false.
* If we wanted an additional level of control, say we update every `chart_version` inside of clusters.yaml.
* We could leverage a pre-sync script that checks whether or not the tenant specific k8s resources have a `takeChanges: true`. If pre-sync fails, then then that express instance will not get the change.
	* Ex gist: [hook example](https://github.medallia.com/gist/erauner/0066765167143e4a52376d217e3a8ab8)
