---
up: "[[2024-W23]]"
description: ""
publish: false
starred: false
status: ""
type: note
tags:
  - periodic/daily
cssclasses:
  - "cards"
  - "cards-cols-1"
obsidianUIMode: source
obsidianEditingMode: live
template: "[[Daily]]"
created: 20240603000100
modified: 20240604093234
aliases:
  - Monday - June 3rd 2024
linter-yaml-title-alias: Monday - June 3rd 2024
title: Monday - June 3rd 2024
id: 10
week: "[[2024-W23]]"
yearly: "[[2024]]"
quarterly: "[[2024-Q2]]"
monthly: "[[2024-06]]"
daily: "[[2024-06-03]]"
month: "June"
weekday: Monday
---

# Monday - June 3rd 2024

[[Tick Tick API]]

```
(
  (
    100 *
    (
      (
        4294967296 +
        1.2 * avg_over_time(express_cluster_fe:MemoryUsage_Used:max_over_28d_max_heap{dc!~"hnd1|icn1|jed1|phx1", cluster!~"survey.*|hase-.*|ccf-.*|socialmedia.*"}[1h])
      )
      - on (dc, cluster)
      min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe"}) by (dc, cluster)
    )
    /
    min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe"}) by (dc, cluster)
  )
  > 15
)
and
(
  (
    100 *
    (
      (
        4294967296 +
        1.2 * avg_over_time(express_cluster_fe:MemoryUsage_Used:max_over_28d_max_heap{dc!~"hnd1|icn1|jed1|phx1", cluster!~"survey.*|hase-.*|ccf-.*|socialmedia.*"}[1h] offset 1h)
      )
      - on (dc, cluster)
      min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe"}) by (dc, cluster)
    )
    /
    min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe"}) by (dc, cluster)
  )
  > 15
)
and
(
  (
    100 *
    (
      (
        4294967296 +
        1.2 * avg_over_time(express_cluster_fe:MemoryUsage_Used:max_over_28d_max_heap{dc!~"hnd1|icn1|jed1|phx1", cluster!~"survey.*|hase-.*|ccf-.*|socialmedia.*"}[1h])
      )
      - on (dc, cluster)
      min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe"}) by (dc, cluster)
    )
    /
    min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe"}) by (dc, cluster)
  )
  -
  (
    100 *
    (
      (
        4294967296 +
        1.2 * avg_over_time(express_cluster_fe:MemoryUsage_Used:max_over_28d_max_heap{dc!~"hnd1|icn1|jed1|phx1", cluster!~"survey.*|hase-.*|ccf-.*|socialmedia.*"}[1h] offset 1h)
      )
      - on (dc, cluster)
      min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe"}) by (dc, cluster)
    )
    /
    min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe"}) by (dc, cluster)
  )
)
> 1
```

```
(
  (
    100 *
    (
      (
        4294967296 +
        1.2 * last_over_time(express_cluster_fe:MemoryUsage_Used:max_over_28d_max_heap{dc!~"hnd1|icn1|jed1|phx1", cluster="tamarriott"}[1h])
      )
      - on (dc, cluster)
      min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe", cluster="tamarriott"}) by (dc, cluster)
    )
    /
    min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe", cluster="tamarriott"}) by (dc, cluster)
  )
  > 15
)
and
(
  (
    100 *
    (
      (
        4294967296 +
        1.2 * last_over_time(express_cluster_fe:MemoryUsage_Used:max_over_28d_max_heap{dc!~"hnd1|icn1|jed1|phx1", cluster="tamarriott"}[1h])
      )
      - on (dc, cluster)
      min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe", cluster="tamarriott"}) by (dc, cluster)
    )
    /
    min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe", cluster="tamarriott"}) by (dc, cluster)
  )
  -
  (
    100 *
    (
      (
        4294967296 +
        1.2 * last_over_time(express_cluster_fe:MemoryUsage_Used:max_over_28d_max_heap{dc!~"hnd1|icn1|jed1|phx1", cluster="tamarriott"}[1h] offset 1h)
      )
      - on (dc, cluster)
      min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe", cluster="tamarriott"}) by (dc, cluster)
    )
    /
    min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe", cluster="tamarriott"}) by (dc, cluster)
  )
)
> 0.5
```

```
# Define the time one hour ago
one_hour_ago=$(date -v -3H +%s)

# Define the Prometheus query
query=$(cat <<-END
group by (dc, cluster) (
  (
    (
      100 * (
        (
          4294967296 + 1.2 * max_over_time(express_cluster_fe:MemoryUsage_Used:max_over_28d_max_heap{dc!~"hnd1|icn1|jed1|phx1", cluster!~"survey.*|hase-.*|ccf-.*|socialmedia.*"}[1h])
        ) - on (dc, cluster) min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe"}) by (dc, cluster)
      ) / min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe"}) by (dc, cluster)
    ) > 20
  ) and
  (
    (
      100 * (
        (
          4294967296 + 1.2 * max_over_time(express_cluster_fe:MemoryUsage_Used:max_over_28d_max_heap{dc!~"hnd1|icn1|jed1|phx1", cluster!~"survey.*|hase-.*|ccf-.*|socialmedia.*"}[1h] offset 1h)
        ) - on (dc, cluster) min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe"}) by (dc, cluster)
      ) / min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe"}) by (dc, cluster)
    ) > 20
  ) and
  (
    (
      100 * (
        (
          4294967296 + 1.2 * max_over_time(express_cluster_fe:MemoryUsage_Used:max_over_28d_max_heap{dc!~"hnd1|icn1|jed1|phx1", cluster!~"survey.*|hase-.*|ccf-.*|socialmedia.*"}[1h])
        ) - on (dc, cluster) min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe"}) by (dc, cluster)
      ) / min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe"}) by (dc, cluster)
    ) - (
      100 * (
        (
          4294967296 + 1.2 * max_over_time(express_cluster_fe:MemoryUsage_Used:max_over_28d_max_heap{dc!~"hnd1|icn1|jed1|phx1", cluster!~"survey.*|hase-.*|ccf-.*|socialmedia.*"}[1h] offset 1h)
        ) - on (dc, cluster) min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe"}) by (dc, cluster)
      ) / min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe"}) by (dc, cluster)
    )
  ) > 1
)
END
)

# Perform the cURL request and process the results with jq
curl -s -G 'http://localhost:9090/api/v1/query' \
  --data-urlencode "query=${query}" \
  --data-urlencode "time=${one_hour_ago}" | jq -r '.data.result[] | "\(.metric.dc) \(.metric.cluster)"'
```

```
Cluster: bcp, DC: sea1
  - Maximum Increase: 5.74%
  - Current Heap: 149.00 GiB
  - Heap 168 Hours Ago: 127.00 GiB
  - Adjusted Heap: N/A
  - Heap size has been increased in the last 168 hours.
```
