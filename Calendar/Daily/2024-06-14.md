---
up: "[[2024-W24]]"
description: ""
publish: false
starred: false
status: ""
type: note
tags:
  - periodic/daily
cssclasses:
  - "cards"
  - "cards-cols-1"
obsidianUIMode: source
obsidianEditingMode: live
template: "[[Daily]]"
created: 20240614000100
modified: 20240618093807
aliases:
  - Friday - June 14th 2024
linter-yaml-title-alias: Friday - June 14th 2024
title: Friday - June 14th 2024
id: 10
week: "[[2024-W24]]"
yearly: "[[2024]]"
quarterly: "[[2024-Q2]]"
monthly: "[[2024-06]]"
daily: "[[2024-06-14]]"
month: "June"
weekday: Friday
---

# Friday - June 14th 2024

Everybody will file a ticket with us, say, oh, we need to do a forced rebuild on this. Means we deploy the new release, but now we need to do a rebuild on them. So we will normally trigger the forced rebuild on boot, kick that node, and that will finish the deployment, right? Propagate caches and all of that. Now what we can do is instead of them sending the ticket to us, and if this is in production by then, they can click the button, and that's going to force the rebuild on the same release that is deployed to, right? So that's how it's going to pick that up. I hope I made that clear for you. I don't know if that makes sense. I just wanted to understand exactly how this relates to what the current process is. So I think that makes sense. Right, the current process is very manual. It's like someone will come in and tell you, someone will file a ticket. We will then start that deployment by kicking that node off, setting this flag and kicking the node off, right? Now PS can do this themselves, or RMD can still ask us, and we will follow the DCR pipeline that we do today, but it's going to force a cache. Let's assume the other use case, right? We're going to E6 91 after 90 is deployed, and 91 is actually a cache rebuild deployment. So now in this case, it doesn't matter any which way we're going to force the rebuild, right? On the dynamic synchronizer. So even if the core would not have rebuilt the cache, we are forcing the dynamic synchronizer to start a rebuild on that. So we are safe. We are not doing something which is not expected in that situation. Yeah, yeah, yeah. I think it makes everything so much less confusing to have this dedicated node, you know? Right, the dynamic node, yes. Yeah. Agreed. Yeah, so yeah, this should really like, is it ever at any point, Sergio, that when this button is clicked, we're going to be in a state where the Express version, like let's say, well, I guess it doesn't matter. It doesn't matter what version of Express. Well, we should always get the version of Express that the backend is running on, I think. That's what we should supply. But obviously, right? No, no, no. What if it's a new deployment then? Yeah, so I'm, well. Uh, that's, I mean, we do have the PCs with this. We have time to, I mean, that is something that it would be interesting to mention in the demo. That is, what is the use case that we are trying to attack with the backfill case? And what is the other one? Right. The DCR tooling should be separate. This is just for the backfill, right? With the backfill, it will always get the Express release from the backend that time. Because it's a backfill. Yeah. Got it? We in the future may want to tweak and have two separate pipelines. One which might just trigger for backfills and then one which will just trigger based on regular deployments. Because for the regular deployments, which need a new release, you will have to figure out a way from where we get that new release. Because you can't look at the backend for that. You can look at the backend to know what your current running version is, but not the version that is going to get upgraded to. Today we are specifying that in the Jira ticket, right? As in the values in the Helm chart, the values.yaml file. So that at some point also has to be automated where we can fetch it from some place. Now, again, we don't have to think about it today. That is something which we have to think about and bring up into production at some point. Yeah. And I don't even think it needs to be a separate task. It just needs to be a flag on the task. Are you doingAutoflag. Right, right, right. Or are you doing a force on existing version? Something of thatCorrect, correct. Something of that, right. But yeah, that'sâ€¦ But if we did need a separate task, we could. I'm just, I'm trying to make it as all-encompassing as possible. Cool, cool.

---

so those three will be highlighted and that's it right like and then we'll start the demo and say thanks and again i mean 10 minutes we can't really speak a lot but the slides will have a lot of definition so in the in the demo document that i'm going to create there'll be a floor diagram that we'll create right and that will have all all the steps basic steps and people can review that if they need in the future like after the demo so do you want to like right as you start like we could we could just say hey we're kicking them up and you could begin to explain and as that is happening you could say and here here it is like right right so what we'll do have in there is exactly like you said we'll have one cluster that's going to start already at that time right so when i start speaking we'll kick off one one cluster to do the rebuild and the second one we'll wait and we'll initiate that when the time comes like we'll show it from like logging into the mec instance and then clicking the button and then showing them like the pipeline kicking in and all of that whereas in the meanwhile at least the first task that we start has moved along and has made more progress than the actual task we kick off so we can show them something right so yes definitely that's the reasoning to have two and we'll probably use them in that situation okay i'm really sorry that uh i'm not going to be they are probably i mean if i'm going to be for the demo i'm going to have like half of my head but i uh i i already had the tickets for probably like three months ago yeah oh yeah if we can change i know that it was going to happen i i feel really bad leaving you guys

---

From the product perspective, who bears the cost of a VCR now? Okay, because now they say, okay, we are going to the backfield and depending on the company that takes extra processing for two weeks and now they will be able to do this in a couple of hours because of or in a couple of days, one day, whatever, but that needs resources. So it's, this is, I think this is a very important point because definitely that we can charge our clients with. We can say, okay, you want to, you want to modify or add all of these cases? No problem. Wait for the next deployment that is free. Now you want to put them to work tomorrow without affecting your current operations. Then there's a cost to that. Yeah. I say, okay, we give you two DCRs per month. Yeah. And after that you have to be, I don't know. Yeah. That, that kind of scheme. What if like also, since we have the ability to be like, do you want it? It's going to be done by default in two days, but if you want it done in one day, then that's, you know, a certain amount of credits or, or whatever. I don't know. I don't know anything about that. And that would be a bit, that would be a bit difficult to work and push to the customer, I would say. Yeah. Right. Like, I mean, yeah. How are you going to define that two days is this price and then one day would be this price. I mean that everyone probably, you know, go with one day or something, but yeah. It's funny though, because it's possible now. It's the thing. No, but what I'm thinking is that now they accept things that they really shouldn't accept, like Walmart. They say, okay, next deployment, next cash reveal deployment is in three months. All of these programs, we are going to wait three months. That means they wait for all final deployment and all that. So again, this is, this is like more of a business side of a debate, which we probably need to bring up with them.

---

and definitely bring it to product that this could be a good way to maybe generate some income or sell it as a leverage to the customer saying, now you have this new functionality, which is actually gonna make your cluster a lot more stable all the time. Like you're not gonna waste time because with the backfilling, we were also seeing heap spikes and clusters would crash and all of that, right? So now all of that is also being taken away. So there will be ways when this goes out into production, we need to sell it because this means a lot of our customers will suddenly be super happy with us. It will help even any at-risk renewals to not probably turn and probably they'll be more excited to continue with us. So it's definitely agree on what you're saying. We need product to super sell this, like make it 10 times more bigger than it probably seems like, and also maybe add a cost to it if possible. But again, all of that, yes. We will have toI understand that this is a great feature. It does have a cost. Let's think about that cost and how we pay for it. Again, that's probably not for us to think, but we need to just open their eyes to it. Highlight it, yes. Open the can of worms so people can start talking about it. Exactly. Okay, fantastic. So I will continue for a bit more. As soon as I have the artifact, I will post it in the channel. Let's hope for the best. Yeah. I should only need to deploy that artifact to all the backends. I mean, technically the frontends, I don't need to, right? No, the frontends are the onesOh, my bad. The frontends do need it because they needYeah, yeah, yeah, yeah. Sorry, that was dumb. We'll pull it out to all of them. No. Okay, if you are talking about the button, the cash reveal button, the new button, Yeah. You don't need to deploy that everywhere. If you deploy that in the backend and then you run this in the backend, it's fine. That works. Ah, okay. But let's deploy it everywhere. I mean, it's a small department. It doesn't even need it. Yeah, yeah, yeah, yeah. It's less risk. Yeah. Okay.

---

I took out of this hackathon is that cherry picking that code, which I thought was going to be terribly difficult. It wasn't fair. It was very straightforward. Yeah. It was simple. So we could be able to go back and cherry pick in Walmart and all of them. Nice. Uh, so that's, that's something that we will need to discuss with, uh, with Sabri and them. But I, I, I am, I feel more confident now that this should be no problem. Nice. Yeah. Because that's, that's the, that's the holdup. I mean, if this goes to master today, you're talking nine months to Walmart. Yeah. Okay. Um, but now that I have been looking at, uh, integrating these in other branches and all that, I feel much better about it. Nice. Yeah. That's cool. Well, that, that kind of helps me like, to know that, like what, and when, what, what to prioritize and in what order on the workflow side too, because yeah, that's cool. Yeah. Don't, don't take it for granted that we are going to have dynamic synchro, like synchronizer in production at any specific time. Yeah. Yeah. I mean, it could be next week or next year. Yeah.

---

Fix MDBS backstage labels in OCI

To fix the MDBS backstage labels in OCI, follow these steps:

1. Navigate to `apps/mdbs/postgres/overlays/<dc>/<instance>/kustomization.yaml`
2. Update the labels section as follows:

```
  labels:
    app.kubernetes.io/part-of: com.medallia.express
```

1. Next, locate the file `metadata/hnd1/mdbs_sredecom3pods-db.yaml`
2. Update the following line:

```
app.medallia.com/environment: production
```

Change it to:

```
app.medallia.com/environment: prod
```

For reference, you can view the changes made in `mdbs_sredecom4pods-db.yaml` in this pull request: [Update mdbs_sredecom4pods-db.yaml by erauner Â· Pull Request #12138 Â· Atlas/cloud-deployment](https://github.medallia.com/Atlas/cloud-deployment/pull/12138/files)

---
