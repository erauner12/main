---
up: "[[2024-W22]]"
description: ""
publish: false
starred: false
status: ""
type: note
tags:
  - periodic/daily
cssclasses:
  - "cards"
  - "cards-cols-1"
obsidianUIMode: source
obsidianEditingMode: live
template: "[[Daily]]"
created: 20240529000100
modified: 20240529235152
aliases:
  - Wednesday - May 29th 2024
linter-yaml-title-alias: Wednesday - May 29th 2024
title: Wednesday - May 29th 2024
id: 10
week: "[[2024-W22]]"
yearly: "[[2024]]"
quarterly: "[[2024-Q2]]"
monthly: "[[2024-05]]"
daily: "[[2024-05-29]]"
month: "May"
weekday: Wednesday
---

# Wednesday - May 29th 2024

## Route Changes

- Set `group_by: ['…']` to disable grouping and ensure each alert is sent individually.
- Adjusted `group_wait` to 5 minutes to allow for a reasonable amount of time to buffer and deduplicate alerts before sending.
- Set `group_interval` to 1 minute to control the frequency of sending new alerts within a group.
- Set `repeat_interval` to 0 to disable repeating alerts since the automation is consuming them.

## Receiver Changes

- Modified the "sre/argo-events" receiver:
    - Set `send_resolved` to false to avoid sending resolved alerts to the automation.

## Reasons

- Sending each alert individually (`group_by: ['…']`):
    - Enables the automation to process each alert separately and take appropriate actions based on the specific alert.
    - Prevents the need for the automation to handle multiple alerts bundled together in a single notification.
- Adjusting `group_wait` to 5 minutes:
    - Allows for a reasonable amount of time to buffer and deduplicate alerts before sending them to the automation.
    - Helps prevent the automation from being overwhelmed with duplicate or rapidly firing alerts.
- Setting `group_interval` to 1 minute:
    - Controls the frequency of sending new alerts within a group to the automation.
    - Ensures that the automation receives new alerts in a timely manner without being flooded with excessive notifications.
- Disabling `repeat_interval` (`repeat_interval: 0`):
    - Since the automation is consuming the alerts, there is no need to repeat the notifications.
    - Avoids unnecessary repetition of alerts, as the automation is expected to handle each alert appropriately upon receiving it.
- Disabling `send_resolved` for the `sre/argo-events` receiver:
    - Avoids sending resolved alerts to the automation, as the focus is on processing firing alerts that require action.
    - Simplifies the automation's logic by only dealing with firing alerts and not having to handle resolved alerts separately.

```
# Recalculate expected values using the provided input series

# Provided input series
timestamps_used = [0, 60, 120]
raw_memory_usage_used = [24000000000, 25000000000, 23000000000]

timestamps_max = [10, 70, 130]
raw_memory_usage_max = [18000000000, 19000000000, 18500000000]

# Calculating the maximum value for heap_usage:raw_memory_usage_used_max
raw_memory_usage_used_max = max(raw_memory_usage_used)

# Calculate adjusted_consus_value
adjusted_consus_value = 4294967296 + 1.2 * raw_memory_usage_used_max

# Calculating spike_percentage
spike_percentage = [
    ((adjusted_consus_value - used) / used) * 100
    for used in raw_memory_usage_used
]

# Create a DataFrame to display the results
df = pd.DataFrame({
    'timestamp_used': timestamps_used,
    'raw_memory_usage_used': raw_memory_usage_used,
    'timestamp_max': timestamps_max,
    'raw_memory_usage_max': raw_memory_usage_max,
    'adjusted_consus_value': [adjusted_consus_value] * len(timestamps_used),
    'spike_percentage': spike_percentage
})

# Check for duplicate timestamps
df_combined = pd.DataFrame({
    'timestamp': timestamps_used + timestamps_max,
    'values': raw_memory_usage_used + raw_memory_usage_max
})

duplicates = df_combined[df_combined.duplicated('timestamp', keep=False)]

df, duplicates
```

```
- series: 'heap_usage:raw_memory_usage_used{pool="heap", env="production", serviceType="express-fe", cluster="tangerine", dc="can"}'
  values: '0 24000000000 60 25000000000 120 23000000000'
- series: 'heap_usage:raw_memory_usage_max{pool="heap", env="production", serviceType="express-fe", cluster="tangerine", dc="can"}'
  values: '10 18000000000 70 19000000000 130 18500000000'
```

```
# The recording rules in this file exist to help right-size container provisioning for production Express clusters.
# Note that the definition of "production" is loose. For Express-instrumented metrics, env="production" includes
# Kubernetes pods both for which the namespace is tenant-*-prod and tenant-*-nonprod. We attempt to include both types
# of namespaces while filtering out sandbox Express nodes based on the `pod` pattern. This is an imperfect relationship
# that might break in the future if naming conventions change.

groups:
  - name: "poe/consus_metrics_heap_fe"
    interval: "4m"  # Do this once per 4m to avoid 5m staleness while minimizing load. Maybe do this once per hour and use last_over_time()[1h] in queries?
    rules:
      - record: "express_cluster_fe:MemoryUsage_Used:max_over_28d_max_heap"  # Recommended FE node JVM size for -Xms (initial heap size) and -Xmx (maximum heap size). Recommended container memory request and limit will both be a function of this value.
        expr: 'max(max_over_time(MemoryUsage_Used{pool="heap", env="production", serviceType="express-fe"}[28d])) by (dc, cluster, env)'
        labels:
          team: "poe"
          service: "consus_metrics"
```

It's great to hear that the tests are now passing successfully! It seems that isolating the `heap_usage:recommended_heap` rule and ensuring unique timestamps resolved the issue. Now that the isolated tests have passed, you can integrate this change back into your main test file.

### Integrated Main Test File

Here’s how you can integrate the successful changes back into your main test file:

```yaml
rule_files:
- heap_usage_recording_rules.yaml
- heap_spike.yaml

evaluation_interval: 1m

tests:
- interval: 1m
  input_series:
  - series: 'express_cluster_fe:MemoryUsage_Used:max_over_28d_max_heap{cluster="tangerine", dc="can"}'
    values: '0 22000000000 60 22000000000'
  - series: 'MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe", cluster="tangerine", dc="can"}'
    values: '0 20000000000 60 20000000000'
  - series: 'heap_usage:recommended_heap{cluster="tangerine", dc="can"}'
    values: '0 30694967296 120 30694967296'
  - series: 'heap_usage:current_heap{cluster="tangerine", dc="can", env="production", pool="heap", serviceType="express-fe"}'
    values: '180 20000000000'
  - series: 'heap_usage:recommended_heap_gib{cluster="tangerine", dc="can"}'
    values: '240 28.586915969848633'
  - series: 'heap_usage:current_heap_gib{cluster="tangerine", dc="can", env="production", pool="heap", serviceType="express-fe"}'
    values: '300 18.62645149230957'

  promql_expr_test:
  - expr: 'heap_usage:recommended_heap{cluster="tangerine", dc="can"}'
    eval_time: 1m
    exp_samples:
    - value: 30694967296
      labels: 'heap_usage:recommended_heap{cluster="tangerine", dc="can"}'
  - expr: 'heap_usage:current_heap{cluster="tangerine", dc="can", env="production", pool="heap", serviceType="express-fe"}'
    eval_time: 2m
    exp_samples:
    - value: 20000000000
      labels: 'heap_usage:current_heap{cluster="tangerine", dc="can", env="production", pool="heap", serviceType="express-fe"}'
  - expr: 'heap_usage:recommended_heap_gib{cluster="tangerine", dc="can"}'
    eval_time: 3m
    exp_samples:
    - value: 28.586915969848633
      labels: 'heap_usage:recommended_heap_gib{cluster="tangerine", dc="can"}'
  - expr: 'heap_usage:current_heap_gib{cluster="tangerine", dc="can"}'
    eval_time: 4m
    exp_samples:
    - value: 18.62645149230957
      labels: 'heap_usage:current_heap_gib{cluster="tangerine", dc="can", env="production", pool="heap", serviceType="express-fe"}'

  alert_rule_test:
    - eval_time: 5m
      alertname: ExpressFEHeapUsageSpike30DayTrend
      exp_alerts:
        - exp_labels:
            alertname: ExpressFEHeapUsageSpike30DayTrend
            severity: warn
            cluster: tangerine
            dc: can
            env: production
            pool: heap
            serviceType: express-fe
            recipient: 'sre/unplanned-gc-monitor'
            service: sre/express
            team: "sre"
            current_heap_gib: '18.62645149230957'
            recommended_heap_gib: '28.586915969848633'
          exp_annotations:
            title: "Express Frontend Heap Usage Spike Detected in cluster `tangerine` at `can`"
            description: |
              The heap memory usage for the Express frontend cluster `tangerine` in `can` has experienced a significant spike.
              The current heap usage is `18.63 GiB`.
              The recommended heap value is `28.59 GiB`.
              The spike percentage is `34.83%`, exceeding the threshold of `20%`.
            action: "Investigate the cause of the heap memory usage spike (`34.83%`) for the affected cluster and consider optimizing memory usage or allocating more resources to prevent performance degradation."
```

### Explanation

- **Unique Timestamps:** Ensured unique and non-overlapping timestamps for all series.
- **Separate Tests for PromQL Expressions:** Each PromQL expression is tested with a specific evaluation time to ensure clarity and correctness.
- **Integrated Tests:** Combined the previously isolated successful tests into the main test file for a comprehensive check.

### Validation

Run the integrated test file to ensure everything works as expected:

```sh
bin/promtool.sh test rules rules/production_services/replicated-rules/testing-alerts/heap_spike.test
```

This approach should help maintain the passing state of your tests while ensuring all aspects are validated. If any issues arise, you can further isolate and debug specific sections as needed.
