---
up: "[[2024-W34]]"
description: ""
publish: false
starred: false
status: ""
type: note
tags:
  - periodic/daily
cssclasses:
  - "cards"
  - "cards-cols-1"
obsidianUIMode: source
obsidianEditingMode: live
template: "[[Daily]]"
created: 20240526134141
modified: 20240820104441
aliases:
  - Monday - August 19th 2024
linter-yaml-title-alias: Monday - August 19th 2024
title: Monday - August 19th 2024
id: 10
week: "[[2024-W34]]"
yearly: "[[2024]]"
quarterly: "[[2024-Q3]]"
monthly: "[[2024-08]]"
daily: "[[2024-08-19]]"
month: "August"
weekday: Monday
---

# Monday - August 19th 2024

```go
type ClusterStatus struct {
    // … existing fields …
    UpgradeStatus     UpgradeStatus `json:"upgradeStatus,omitempty"`
    LastFailedNode    string        `json:"lastFailedNode,omitempty"`
    RecoveryMode      bool          `json:"recoveryMode,omitempty"`
}

type UpgradeStatus string

const (
    UpgradeStatusNone     UpgradeStatus = "None"
    UpgradeStatusOngoing  UpgradeStatus = "Ongoing"
    UpgradeStatusPaused   UpgradeStatus = "Paused"
    UpgradeStatusComplete UpgradeStatus = "Complete"
)
```

---

## Documentation

- [WIP - Recovery/Stablization extension](https://github.medallia.com/gist/erauner/9d9c532704b00143c99d136ee77e695e)
- [Express Deployment Upgrade + Recovery](https://github.medallia.com/gist/erauner/46af3f201dfff46c689e962f251fcd03#6-upgrade-with-mixed-node-specific-overrides)

## Helm Chart

- [Refactor Helm Chart To Match Express Operator by erauner · Pull Request #71665 · Atlas/deployment](https://github.medallia.com/Atlas/deployment/pull/71665)

## Express Operator

- [Refactor Express Operator for Cluster Management by erauner · Pull Request #174 · Atlas/express-operator](https://github.medallia.com/Atlas/express-operator/pull/174/files#diff-8c57303fa747da0d799fca52ed4f961bdd2149e84396b634a1391155679249ad)

---

Here is a work plan for testing the cache copying process for a different cluster in Markdown format. The work plan is structured to allow easy replication for a new instance, specifying the instance name, instance ID, and DC as variables.

---

Here is the updated document with the additional log details included and a more streamlined approach for the initial environment variable setup:

---

```
export INSTANCE_NAME="varsamisktest"
export INSTANCE_ID="123634"
export DC="den"
```

```
aws --profile=${DC} --endpoint=http://s3.${DC}.medallia.com/ s3 ls s3://testbucket/${INSTANCE_NAME}/

PRE varsamisktest-be/
PRE varsamisktest-fe1/
```

```
2024-08-19 19:10:22.755 PDT [batcher.com.netflix.blitz4j.AsyncAppender.A1-process]   INFO  hepersistor.PumpCachePersistor  -Progress: ReadCaches[varsamisktest] (2 of 2 units), elapsed: 49.00 ms, ETA: 49.00 ms [Loading caches for varsamisktest with S3Downloader for drains [Drain express.ibs.wordloader.WordLoader WordLoader, Drain express.ibs.IbsLoader IbsLoader]][Summarized 2 messages of this type because the internal buffer was full]
```

```
2024-08-19 19:10:22.901 PDT [NodeServlet-JoinTopologyRequest-1]   INFO  hose.S3CacheStoreUtils          -Could not read link file varsamisktest/varsamisktest-fe2/varsamisktest/node/current
com.amazonaws.services.s3.model.AmazonS3Exception: The specified key does not exist. (Service: Amazon S3; Status Code: 404; Error Code: NoSuchKey; Request ID: null; S3 Extended Request ID: null; Proxy: null), S3 Extended Request ID: null
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1862)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleServiceErrorResponse(AmazonHttpClient.java:1415)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1384)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1154)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:811)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:779)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:753)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:713)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:695)
	at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:559)
	at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:539)
	at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5445)
	at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5392)
	at com.amazonaws.services.s3.AmazonS3Client.getObject(AmazonS3Client.java:1520)
	at express.db.hose.S3CacheStoreUtils.getCurrentFolderAbsolute(S3CacheStoreUtils.java:190)
	at express.db.hose.cachepersistor.loaders.S3Downloader.prepare(S3Downloader.java:97)
	at express.db.hose.cachepersistor.PumpCachePersistor.lambda$loadCachesWithStrategy$4(PumpCachePersistor.java:340)
	at common.processstatus.ProcessStatus.callSubProcess(ProcessStatus.java:351)
	at common.processstatus.ProcessStatus.callSubProcess(ProcessStatus.java:295)
	at express.db.hose.cachepersistor.PumpCachePersistor.loadCachesWithStrategy(PumpCachePersistor.java:337)
	at express.db.hose.cachepersistor.PumpCachePersistor.lambda$loadCaches$2(PumpCachePersistor.java:324)
	at common.processstatus.ProcessStatus.callSubProcess(ProcessStatus.java:351)
	at common.processstatus.ProcessStatus.callSubProcess(ProcessStatus.java:311)
	at express.db.hose.cachepersistor.PumpCachePersistor.lambda$loadCaches$3(PumpCachePersistor.java:323)
	at common.processstatus.ProcessStatus.callSubProcess(ProcessStatus.java:351)
	at common.processstatus.ProcessStatus.callSubProcess(ProcessStatus.java:311)
	at express.db.hose.cachepersistor.PumpCachePersistor.loadCaches(PumpCachePersistor.java:317)
	at express.db.hose.cachepersistor.PumpCachePersistor.loadCaches(PumpCachePersistor.java:310)
	at express.db.hose.NodeLoadCaches.load(NodeLoadCaches.java:67)
	at express.db.hose.ClusterTopologyClient.tryLoadCaches(ClusterTopologyClient.java:209)
	at express.db.hose.ClusterTopologyClient.lambda$joinAsPumpTargetInternal$2(ClusterTopologyClient.java:154)
	at io.opentelemetry.context.Context.lambda$wrap$1(Context.java:212)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at com.medallia.concurrent.executors.TrackedThreadPoolExecutor$TimedFutureTask.run(TrackedThreadPoolExecutor.java:140)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
```

```
2024-08-19 19:10:22.903 PDT [NodeServlet-JoinTopologyRequest-1]   INFO  hepersistor.PumpCachePersistor  -Ended: PreparingLoader[creating socket - downloading from S3 - copying cache]  - took: 148.00 ms - result: FAILED
```

```
2024-08-19 19:10:22.903 PDT [batcher.com.netflix.blitz4j.AsyncAppender.A1-process]   WARN  hepersistor.PumpCachePersistor  -Problem while reading caches from S3Downloader for company: varsamisktest with strategy S3Downloader[Summarized 2 messages of this type because the internal buffer was full]
java.io.UncheckedIOException: java.io.IOException: Current file not found
	at tiny.RethrowUtils.asRuntimeException(RethrowUtils.java:30)
	at tiny.Rethrow.asRuntimeException(Rethrow.java:120)
	at express.db.hose.cachepersistor.PumpCachePersistor.lambda$loadCachesWithStrategy$4(PumpCachePersistor.java:343)
	at common.processstatus.ProcessStatus.callSubProcess(ProcessStatus.java:351)
	at common.processstatus.ProcessStatus.callSubProcess(ProcessStatus.java:295)
	at express.db.hose.cachepersistor.PumpCachePersistor.loadCachesWithStrategy(PumpCachePersistor.java:337)
	at express.db.hose.cachepersistor.PumpCachePersistor.lambda$loadCaches$2(PumpCachePersistor.java:324)
	at common.processstatus.ProcessStatus.callSubProcess(ProcessStatus.java:351)
	at common.processstatus.ProcessStatus.callSubProcess(ProcessStatus.java:311)
	at express.db.hose.cachepersistor.PumpCachePersistor.lambda$loadCaches$3(PumpCachePersistor.java:323)
	at common.processstatus.ProcessStatus.callSubProcess(ProcessStatus.java:351)
	at common.processstatus.ProcessStatus.callSubProcess(ProcessStatus.java:311)
	at express.db.hose.cachepersistor.PumpCachePersistor.loadCaches(PumpCachePersistor.java:317)
	at express.db.hose.cachepersistor.PumpCachePersistor.loadCaches(PumpCachePersistor.java:310)
	at express.db.hose.NodeLoadCaches.load(NodeLoadCaches.java:67)
	at express.db.hose.ClusterTopologyClient.tryLoadCaches(ClusterTopologyClient.java:209)
	at express.db.hose.ClusterTopologyClient.lambda$joinAsPumpTargetInternal$2(ClusterTopologyClient.java:154)
	at io.opentelemetry.context.Context.lambda$wrap$1(Context.java:212)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at com.medallia.concurrent.executors.TrackedThreadPoolExecutor$TimedFutureTask.run(TrackedThreadPoolExecutor.java:140)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.io.IOException: Current file not found
	at express.db.hose.cachepersistor.loaders.S3Downloader.lambda$prepare$0(S3Downloader.java:97)
	at java.base/java.util.Optional.orElseThrow(Optional.java:408)
	at express.db.hose.cachepersistor.loaders.S3Downloader.prepare(S3Downloader.java:97)
	at express.db.hose.cachepersistor.PumpCachePersistor.lambda$loadCachesWithStrategy$4(PumpCachePersistor.java:340)
	… 21 more
```

```
2024-08-19 19:10:22.907 PDT [batcher.com.netflix.blitz4j.AsyncAppender.A1-process]   INFO  hepersistor.PumpCachePersistor  -Ended: S3Downloader[Download from S3] (0 of 3 units) - took: 152.00 ms - result: FAILED[Summarized 3 messages of this type because the internal buffer was full]
```

---

```
2024-08-19 19:10:14.329 PDT [RemoteDataSetMetaDataCache-1]   INFO  ver.RemoteDataSetMetaDataCache  -loadValueForKey for varsamisktest took 160 ms
```

```
2024-08-19 19:10:14.329 PDT [RemoteDataSetMetaDataCache-1]   INFO  ver.RemoteDataSetMetaDataCache  -setValue for varsamisktest, version varsamisktest-fe11L7ruBgVCkdlb546U6YMlA== unchanged
```
