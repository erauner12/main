---
up: "[[2024-W31]]"
description: ""
publish: false
starred: false
status: ""
type: note
tags:
  - periodic/daily
cssclasses:
  - "cards"
  - "cards-cols-1"
obsidianUIMode: source
obsidianEditingMode: live
template: "[[Daily]]"
created: 20240731000100
modified: 20240802232509
aliases:
  - Wednesday - July 31st 2024
linter-yaml-title-alias: Wednesday - July 31st 2024
title: Wednesday - July 31st 2024
id: 10
week: "[[2024-W31]]"
yearly: "[[2024]]"
quarterly: "[[2024-Q3]]"
monthly: "[[2024-07]]"
daily: "[[2024-07-31]]"
month: "July"
weekday: Wednesday
---

# Wednesday - July 31st 2024

```
DEBUG:StepDbPgScripts:Initializing DbAbstract with args: StepArgs(identities=['sretestdeploy'], context='AUTO-20240730144658', platform='mec', task_type='MecProvisionInstance', params_file='/var/folders/sx/y1zy8v1524g77mbpx7m9qq4m0000gp/T/tmplhjex8oy.yaml', working_dir_root='/Users/erauner/work/prov-ng/api/mec/sretestdeploy/MecProvisionInstance/AUTO-20240730144658', run_dc='den', secrets_file='/Users/erauner/work/prov-ng/api/secrets/secrets.yaml', config_directory='/Users/erauner/work/prov-ng/api/config', params_env_var=None, output_file=None, fanout_file=None, flow_control_file=None, test_run=True, local=True, state_on_s3=False, step_name='db_pgscripts')
DEBUG:StepDbPgScripts:Set db_name to: sretestdeploy
DEBUG:StepDbPgScripts:Initializing StepDbPgScripts
2024-07-31 14:01:46,521 - DEBUG - Step db_pgscripts initialized
DEBUG:__main__:Step db_pgscripts initialized
```

…

That's great news! I'm glad we were able to identify and fix the issue. This solution preserves the `db_name` that was set during the step's initialization while still allowing other variables to be updated from the previous step.

To summarize what was happening:

1. The `DbAbstract` class was correctly setting `db_name` during initialization.
2. However, when the workflow runner was updating the step's vars with the previous step's vars, it was completely overwriting the `vars` object, including the `db_name` that had just been set.
3. The new code updates the `vars` object more carefully, only setting values that don't already exist or are None.

This approach is more robust because:

1. It preserves values set during step initialization.
2. It allows for different steps to have different sets of variables without losing data.
3. It prevents accidental overwriting of important values.

To make this solution even more robust for the future, you might want to consider:

1. Adding a method to your `vars` classes for merging/updating, which could encapsulate this logic and make it reusable.
2. Adding more detailed logging around variable updates to make debugging easier in the future.
3. Implementing a more structured way of defining which variables each step expects and sets, to catch potential issues earlier in the development process.

Remember to test thoroughly with different scenarios to ensure this fix works consistently across your workflow. If you encounter any other issues or have any questions, feel free to ask!

```
# Recommendations for simplification:

# 1. Create a SnippetManager class:
# This class can handle loading, managing, and running snippets. It can encapsulate
# the snippet-related logic, reducing complexity in the WorkflowRunner class.

class SnippetManager:
    def __init__(self, config, snippet_config):
        self.config = config
        self.snippet_config = snippet_config
        self.snippets = self.load_snippets()

    def load_snippets(self):
        # Implementation of snippet loading logic
        pass

    def should_run_snippet(self, snippet_type):
        # Implementation of snippet running logic
        pass

    def run_snippets(self, snippet_type, step):
        # Implementation of snippet execution logic
        pass

# 2. Create a StepExecutor class:
# This class can handle the execution of individual steps, including
# running pre and post snippets, and managing step state.

class StepExecutor:
    def __init__(self, config, snippet_manager):
        self.config = config
        self.snippet_manager = snippet_manager

    def execute(self, step_name, step_vars):
        # Implementation of step execution logic
        pass

# 3. Create a WorkflowState class:
# This class can manage the state of the workflow, including loading and saving
# variables, and tracking the progress of steps.

class WorkflowState:
    def __init__(self, config):
        self.config = config
        self.vars = None
        self.steps_to_run = []

    def load_vars(self):
        # Implementation of variable loading logic
        pass

    def save_vars(self):
        # Implementation of variable saving logic
        pass

    def get_steps_to_run(self):
        # Implementation of step selection logic
        pass

# 4. Create a LoggingManager class:
# This class can handle all logging-related operations, including setup and
# writing to different log files.

class LoggingManager:
    def __init__(self, config):
        self.config = config
        self.logger = None

    def setup_logging(self):
        # Implementation of logging setup
        pass

    def log_steps_status(self, steps):
        # Implementation of step status logging
        pass

# 5. Create a TaskParameterManager class:
# This class can handle loading, merging, and rendering task parameters.

class TaskParameterManager:
    def __init__(self, config, user_params):
        self.config = config
        self.user_params = user_params

    def load_task_params(self):
        # Implementation of task parameter loading and rendering
        pass

# By introducing these classes, you can simplify the WorkflowRunner class:

class WorkflowRunner:
    def __init__(self, config: WorkflowConfig):
        self.config = config
        self.logging_manager = LoggingManager(config)
        self.logging_manager.setup_logging()
        self.logger = self.logging_manager.logger

        self.task_param_manager = TaskParameterManager(config, self.load_user_params())
        self.workflow_state = WorkflowState(config)
        self.snippet_manager = SnippetManager(config, self.load_snippet_config())
        self.step_executor = StepExecutor(config, self.snippet_manager)

    def run(self):
        if self.config.use_sre_api:
            return self.run_sre_api_task()

        self.workflow_state.load_vars()
        steps_to_run = self.workflow_state.get_steps_to_run()
        self.logging_manager.log_steps_status(steps_to_run)

        for step_name in steps_to_run:
            try:
                self.step_executor.execute(step_name, self.workflow_state.vars)
                self.workflow_state.save_vars()
            except Exception as e:
                self.handle_step_failure(step_name, e)
                break

        self.snippet_manager.run_snippets('global', None)

    # Other methods…

# These changes would help flatten the code structure, reduce nesting,
# and make the code more modular and easier to maintain. Each class would
# have a single responsibility, making the code easier to understand and test.
```

```
	├── run_workflow.py # entrypoint
	│
	├── config/
	│   └── workflow_config.py
	├── core/
	│   ├── __init__.py
	│   ├── workflow_runner.py
	│   ├── snippet_manager.py
	│   ├── step_executor.py
	│   ├── workflow_state.py
	│   ├── logging_manager.py
	│   └── task_parameter_manager.py
```

```
	└── tests/
	    ├── __init__.py
	    ├── test_workflow_runner.py
	    ├── test_snippet_manager.py
	    ├── test_step_executor.py
	    ├── test_workflow_state.py
	    ├── test_logging_manager.py
	    └── test_task_parameter_manager.py
```
