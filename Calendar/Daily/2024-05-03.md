---
up: "[[2024-W18]]"
description: ""
publish: false
starred: false
status: ""
type: note
tags:
  - periodic/daily
cssclasses:
  - "cards"
  - "cards-cols-1"
obsidianUIMode: source
obsidianEditingMode: live
template: "[[Daily]]"
created: 20240503071450
modified: 20240504092948
aliases:
  - Friday - May 3rd 2024
linter-yaml-title-alias: Friday - May 3rd 2024
title: Friday - May 3rd 2024
id: 10
week: "[[2024-W18]]"
yearly: "[[2024]]"
quarterly: "[[2024-Q2]]"
monthly: "[[2024-05]]"
daily: "[[2024-05-03]]"
month: "May"
weekday: Friday
---

# Friday - May 3rd 2024

## Prompt

```
I need to create a script to perform a specific set of operations within a repository. This will involve generating YAML files in various locations.

Before that, we must extract values from an XML file (per instance) to populate those YAML files. The content of the YAML files will depend on the clusterconfig-<dc> repository and the XML file from which we are retrieving the values.

We will provide a list of instances in a text file for the script to look at before starting, and we will only create yaml files for the provided instances in the file.

every other xml file instance inside of the clusterconfig repo(s)should be ignored for now.

If the target instance provided in the list already exists in the deployment repo location, then please do not overwrite the yaml file. Just ignore creating it and move to the next

ex:

cat copy_intances.txt
aa
allegro
allianzlifena
bankintercx
banorte
bnpparibas
bouyguestelecom
ctc
<instance>
...

…

be sure to provide logging so I can see where we fail as we iterate on the script

```

## Script Base Path

`copy_cluster_config_instance_values_to_deployment_dcr.py` is the script you will be creating to interact with everything else:

```
ls -1
clusterconfig-can
clusterconfig-den
clusterconfig-fra1
clusterconfig-ger
clusterconfig-sc4
clusterconfig-sea1
clusterconfig-sin1
clusterconfig-smf1
clusterconfig-syd1
clusterconfig-uk
clusterconfig-yul1
copy_cluster_config_instance_values_to_deployment_dcr.py
copy_intances.txt
deployment
```

## Details

```
clusterconfig-<dc>

ex:
clusterconfig-fra1
```

Xml example:

```
cat clusterconfig-sea1/aa.xml
<cluster name="aa" domain="medallia.com" short-host-name="aa" sla-tag="prod" igslug-parallel-frontend-enabled="false">
	<kube-express-service name="aa-be" tls-only="false" service-type="express-kube" ipAddr="10.53.30.1" allowedIps="10.53.30.0/24" cpuCount="3.0" jobRamInMB="182886" jobDiskInMB="85182" namespace="tenant-101485-prod" priority="prod" privileged="true">
		<param key="config-version" value="4812380919ca1ccb7fdfe15587e141306207d298" />
		<param key="artifact" value="express-e689.136" />
		<param key="memory-max" value="143g" />
		<param key="port" value="9100" />
		<param key="container-ip" value="10.53.30.1" />
		<param key="memory" value="143g" />
		<param key="generation" value="4" />
		<env-var key="FABRIC_INSTANCE_ID" value="1" />
		<env-var key="FABRIC_SERVICE_ENVIRONMENT" value="production" />
		<env-var key="ATLAS_TLS_ENABLED" value="true" />
		<env-var key="ATLAS_SVC_COMMON_CONFIG_VERSION" value="master" />
		<env-var key="FABRIC_SERVICE_NAME" value="express-be" />
		<env-var key="EXPRESS_NODENAME" value="aa-be" />
		<env-var key="EXPRESS_CLUSTER" value="aa" />
		<nfs mountPoint="/express/workdir/shared" share="10.63.12.14://sharedworkdir/aa" />
		<nfs mountPoint="/express/workdir/shared/feed-file-store" share="10.63.12.14://feedfs_01" />
```

```
we will be extracting values from each xml

Always use the BE node to get these values:

kube_express_service = root.find(f".//kube-express-service[@name='{company_dir}-be']")

ex value to extract:
tls-only="false"
…
<param key="artifact" value="express-e687.176" />

…

<nfs mountPoint="/express/workdir/shared" share="10.30.130.8//vol/sharedworkdir2/airbnb" />

etc
```

```
When we create a yaml file in the designated location, it will look like this

cat deployment/apps/dcr/overlays/fra1/deliveroo/values.yaml

dc: fra1
expressVersion: express-e689.121
heapMemoryGiB: 80
instance: deliveroo
isTlsEnabled: false
namespace: tenant-101804-prod
nodeCount: 0
sharedWorkdirMount: /sharedworkdir/deliveroo

...

The clusterconfig will populate these values from the:
<kube-express-service name="<instance>-be" in each xml

...

dc: <clusterconfig xml "dc">
expressVersion: <clusterconfig xml "artifact"">
instance: <clusterconfig xml "name">
isTlsEnabled: <clusterconfig xml tls-only>
namespace: <clusterconfig xml namespace>
sharedWorkdirMount: <clusterconfig xml "nfs  "share"> (for mountPoint="/express/workdir/shared")

# not instance specific but should should still be added.
heapMemoryGiB: 80
nodeCount: 0


```

## Paths

Clusterconfig repo:

```
clusterconfig-<dc>/<instance>.xml
```

Maps to:

```
deployment/apps/dcr/overlays/<dc>/<instance>/values.yaml
```

Ex:

```
ls -lh clusterconfig-sc4
total 6712
...
-rw-r--r--  1 erauner  staff   6.7K May  3 13:41 allianzlifena.xml
```

```
deployment/apps/dcr/overlays/sc4/allianzlifena/values.yaml
```

`deployment/apps/dcr/overlays/`

```
deployment/apps/dcr/overlays/
├── fra1
│   ├── deliveroo
│   │   └── values.yaml
│   ├── entain
│   │   └── values.yaml
│   ├── telefonica
│   │   └── values.yaml
│   └── telekom
│       └── values.yaml
├── lon
│   ├── bbva
│   │   └── values.yaml
│   ├── libertyglobal
│   │   └── values.yaml
│   ├── veon
│   │   └── values.yaml
│   └── vf
│       └── values.yaml
├── sc4
│   ├── allianzlifena
│   │   └── values.yaml
│   ├── applefeedback
│   │   └── values.yaml
│   ├── bankofamerica
│   │   └── values.yaml
│   ├── banorte
│   │   └── values.yaml
│   ├── capitalone
│   │   └── values.yaml
...
├── sea1
│   ├── facebook
│   │   └── values.yaml
│   ├── wfc
│   │   └── values.yaml
│   └── workday
│       └── values.yaml
├── sin1
│   └── xlaxiata2
│       └── values.yaml
└── yul1
    └── systemdcrtest2
        └── values.yaml
```

Create this file in: `deployment/metadata/<dc>/`

- `sre_dcr_-<"name" from clusterconfig>_prod.yaml`

```
tree deployment/metadata/fra1/ | grep sre_dcr
├── sre_dcr_deliveroo_prod.yaml
├── sre_dcr_entain_prod.yaml
├── sre_dcr_telefonica_prod.yaml
├── sre_dcr_telekom_prod.yaml
```

Append the file name like this to:

- `deployment/metadata/<clusterconfig dc>/kustomization.yaml`

```
cat deployment/metadata/fra1/kustomization.yaml  | grep sre_dcr
- sre_dcr_telekom_prod.yaml
- sre_dcr_entain_prod.yaml
- sre_dcr_deliveroo_prod.yaml
- sre_dcr_telefonica_prod.yaml
```

Here are the contents of this file:

- `sre_dcr_-<"name" from clusterconfig>_prod.yaml`

```
cat deployment/metadata/fra1/sre_dcr_deliveroo_prod.yaml

apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  labels:
    app.medallia.com/environment: production
    app.medallia.com/team: sre
    express.medallia.com/cluster-name: <"name" from clusterconfig>
    valuesVersion: '20240425211100'
  name: dcr--<"name" from clusterconfig>
  namespace: argocd
spec:
  destination:
    namespace: <namespace from clusterconfig>
    server: https://kubernetes.default.svc
  project: dcr
  source:
    helm:
      releaseName: dcr-<"name" from clusterconfig>
      valueFiles:
      - ../overlays/<dc>/<"name" from clusterconfig>/values.yaml
    path: apps/dcr/helm_0.0.5/
    repoURL: git@github.medallia.com:Atlas/deployment.git
    targetRevision: master
  syncPolicy:
    automated:
      allowEmpty: true
      prune: true
      selfHeal: true
```

## Scripts

Here are some unrelated example scripts from different projects to help you get started.

## For Getting Data From Xml Files

```
import os
import sys
import xml.etree.ElementTree as ET
import argparse

def parse_arguments():
    parser = argparse.ArgumentParser(description="Compare storageSharedPattern values.")
    parser.add_argument("-v", "--verbose", action="store_true", help="Print configuration and clusterconfig values for each company.")
    return parser.parse_args()

def read_storageSharedPattern_value(file_path):
    with open(file_path, "r") as file:
        return file.read().strip()

def find_share_value(xml_file, company_dir):
    tree = ET.parse(xml_file)
    root = tree.getroot()
    kube_express_service = root.find(f".//kube-express-service[@name='{company_dir}-be']")
    if kube_express_service is not None:
        nfs_element = kube_express_service.find("./nfs[@mountPoint='/express/workdir/shared']")
        if nfs_element is not None:
            return nfs_element.get("share").replace(":", "")
    return None

def compare_values(dc, company_dir, storageSharedPattern_value, share_value, verbose):
    if share_value != storageSharedPattern_value:
        inconsistent_instances.append((dc, company_dir))
    if verbose:
        print(f"Data Center: {dc}")
        print(f"Company: {company_dir}")
        print(f"Configuration value: {storageSharedPattern_value}")
        print(f"Clusterconfig value: {share_value}")
        print("---")

def process_company(dc, company_dir, verbose):
    configuration_dir = os.path.join("configuration", "variables", dc_mapping[dc]["configuration"])
    qastaging_path = os.path.join(configuration_dir, company_dir, "express", "qastaging")
    storageSharedPattern_file = os.path.join(qastaging_path, "storageSharedPattern.var")
    if os.path.exists(storageSharedPattern_file):
        storageSharedPattern_value = read_storageSharedPattern_value(storageSharedPattern_file)
        clusterconfig_dir = dc_mapping[dc]["clusterconfig"]
        xml_file = os.path.join(clusterconfig_dir, f"{company_dir}.xml")
        if os.path.exists(xml_file):
            share_value = find_share_value(xml_file, company_dir)
            if share_value is not None:
                compare_values(dc, company_dir, storageSharedPattern_value, share_value, verbose)
            else:
                print(f"NFS mountPoint not found for {company_dir} in {dc}")
        else:
            print(f"XML file not found for {company_dir} in {dc}")
    else:
        print(f"Skipping {company_dir} in {dc} as 'storageSharedPattern.var' file does not exist")

if __name__ == "__main__":
    args = parse_arguments()
    inconsistent_instances = []

    dc_mapping = {
        "sea1": {"configuration": "sea1.medallia.com", "clusterconfig": "clusterconfig-sea1"},
        "can": {"configuration": "can.medallia.ca", "clusterconfig": "clusterconfig-can"},
        "den": {"configuration": "den.medallia.com", "clusterconfig": "clusterconfig-den"},
        "lon": {"configuration": "lon.medallia.eu", "clusterconfig": "clusterconfig-uk"},
        "sin1": {"configuration": "sin1.medallia.com", "clusterconfig": "clusterconfig-sin1"},
        "syd1": {"configuration": "syd1.medallia.com.au", "clusterconfig": "clusterconfig-syd1"},
        "sc4": {"configuration": "sc4.medallia.com", "clusterconfig": "clusterconfig-sc4"},
        "fra1": {"configuration": "fra1.medallia.eu", "clusterconfig": "clusterconfig-fra1"},
        "smf1": {"configuration": "smf1.medallia.com", "clusterconfig": "clusterconfig-smf1"},
        "yul1": {"configuration": "yul1.medallia.ca", "clusterconfig": "clusterconfig-yul1"}
    }

    for dc, paths in dc_mapping.items():
        configuration_dir = os.path.join("configuration", "variables", paths["configuration"])
        for company_dir in os.listdir(configuration_dir):
            if os.path.isdir(os.path.join(configuration_dir, company_dir)):
                process_company(dc, company_dir, args.verbose)

    print("Inconsistent instances:")
    for dc, instance in inconsistent_instances:
        print(f"{dc}: {instance}")
```

- Instead of mapping of `configuration` location, map to the deployment location  
     Ex:

```
"fra1": {"clusterconfig": "clusterconfig-fra1"},

…

cat deployment/apps/dcr/overlays/fra1/
```

## For Making Changes to Deployment Repo Yaml Files

### For Values Files

```
import os
import subprocess
import yaml

# Function to get the instance name from values.yaml
def get_instance_name(values_file):
    with open(values_file, 'r') as file:
        values = yaml.safe_load(file)
        return values.get('instance')

# Function to get the cache size from the bash script output
def get_cache_size(instance):
    command = f"./groovy {instance} test.groovy | html2text"
    output = subprocess.check_output(command, shell=True, text=True)
    lines = output.split('\n')
    for line in lines:
        if line.startswith(instance):
            cache_size = int(line.split()[3])
            return cache_size
    return None

# Function to update the values.yaml file with the new cache size
def update_values_yaml(values_file, cache_size):
    with open(values_file, 'r') as file:
        values = yaml.safe_load(file)
        values['cacheSize'] = cache_size
    with open(values_file, 'w') as file:
        yaml.dump(values, file)

# Main script
base_path = 'add_cache_size/deployment/apps/dcr/overlays'

for dirpath, dirnames, filenames in os.walk(base_path):
    if 'values.yaml' in filenames:
        values_file = os.path.join(dirpath, 'values.yaml')
        instance = get_instance_name(values_file)
        if instance:
            cache_size = get_cache_size(instance)
            if cache_size is not None:
                update_values_yaml(values_file, cache_size)
                print(f"Updated {values_file} with cache size: {cache_size}")
            else:
                print(f"Cache size not found for {instance}")
```

### For Metadata Files

```
import os
import yaml
import re

def get_latest_helm_version(app_dir):
    helm_dirs = [d for d in os.listdir(app_dir) if d.startswith("helm_")]
    return sorted(helm_dirs)[-1]

def process_overlays(app, latest_helm_version):
    overlays_dir = f"apps/{app}/overlays"
    for dc in os.listdir(overlays_dir):
        dc_dir = os.path.join(overlays_dir, dc)
        if os.path.isdir(dc_dir):
            for instance in os.listdir(dc_dir):
                instance_dir = os.path.join(dc_dir, instance)
                values_file = os.path.join(instance_dir, "values.yaml")
                if os.path.isfile(values_file):
                    with open(values_file, "r") as f:
                        values = yaml.safe_load(f)
                        node_count = values.get("nodeCount", 0)
                        print(f"Instance: {instance}, Node Count: {node_count}")
                        if node_count == 0:
                            metadata_file = f"metadata/{dc}/sre_{app}_{instance}_prod.yaml"
                            if os.path.isfile(metadata_file):
                                with open(metadata_file, "r") as mf:
                                    metadata_content = mf.read()
                                    updated_metadata_content = re.sub(
                                        r"apps/{}/helm_\d+\.\d+\.\d+/".format(app),
                                        f"apps/{app}/{latest_helm_version}/",
                                        metadata_content
                                    )
                                with open(metadata_file, "w") as mf:
                                    mf.write(updated_metadata_content)
                                print(f"Updated {metadata_file} with {latest_helm_version}")

if __name__ == "__main__":
    app = "dcr"  # Change this to the desired app, e.g., "express"
    app_dir = f"apps/{app}"
    latest_helm_version = get_latest_helm_version(app_dir)
    print(f"Latest helm version: {latest_helm_version}")
    process_overlays(app, latest_helm_version)
```
