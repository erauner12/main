---
up: "[[2024-W22]]"
description: ""
publish: false
starred: false
status: ""
type: note
tags:
  - periodic/daily
cssclasses:
  - "cards"
  - "cards-cols-1"
obsidianUIMode: source
obsidianEditingMode: live
template: "[[Daily]]"
created: 20240530000100
modified: 20240531165520
aliases:
  - Thursday - May 30th 2024
linter-yaml-title-alias: Thursday - May 30th 2024
title: Thursday - May 30th 2024
id: 10
week: "[[2024-W22]]"
yearly: "[[2024]]"
quarterly: "[[2024-Q2]]"
monthly: "[[2024-05]]"
daily: "[[2024-05-30]]"
month: "May"
weekday: Thursday
---

# Thursday - May 30th 2024

```
groups:
- name: sre/heap_usage
  rules:
  - record: heap_usage:spike_percentage
    expr: |
      100 * (
        (
          4294967296 +
          1.2 * last_over_time(express_cluster_fe:MemoryUsage_Used:max_over_28d_max_heap{dc!~"hnd1|icn1|jed1|phx1", cluster!~"survey.*"}[30m])
        )
        - on (dc, cluster)
        min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe", dc!~"hnd1|icn1|jed1|phx1", cluster!~"survey.*"}) by (dc, cluster)
      )
      / min(MemoryUsage_Max{pool="heap", env="production", serviceType="express-fe", dc!~"hnd1|icn1|jed1|phx1", cluster!~"survey.*"}) by (dc, cluster)
```

---

```
one_hour_ago=$(date -v -1H +%s)
curl -s -G '[http://localhost:9090/api/v1/query](http://localhost:9090/api/v1/query)' --data-urlencode "query=(
  max by (cluster) (
    (
      express_cache_rebuild_parsed_surveys_total_count{application=\"express\", env=\"production\"}
      / express_cache_rebuild_expected_surveys_total_count{application=\"express\", env=\"production\"}
    ) * 100
  ) < 100
)
and
(
  max by (cluster) (
    sum by (cluster) (
      express_cache_rebuild_duration_total_ms{application=\"express\", serviceType=\"express-fe\"}
    ) / (24 * 60 * 60 * 1000)
  ) >= 0
)" --data-urlencode "time=${one_hour_ago}" | jq -r '.data.result[] | "\(.metric.cluster) \(.value[1])%"'
```

```
aetnacvs 76.78893336309834%
anthemlistens 29.553901283691346%
bcp 9.323551282326703%
chanel 81.55868041509339%
estacio 55.61246814060882%
falabella 25.46096802824276%
offlinerebuild 87.10799252632815%
statefarm 11.838779588907537%
wework 38.975313873678495%
wpp 0%
```

[[SREPROVNG-665] Fix issue with TLS customers not monitoring DCR properly - Medallia](https://jira.medallia.com/browse/SREPROVNG-665)

- Init
- Is this ssl enabled true
- Set `group_by: ['…']` to disable grouping and ensure each alert is sent individually.
- Adjusted `group_wait` to 5 minutes to allow for a reasonable amount of time to buffer and deduplicate alerts before sending.
- Set `group_interval` to 1 minute to control the frequency of sending new alerts within a group.
- Set `repeat_interval` to 10 years to disable repeating alerts since the automation is consuming them.

---

```
one_hour_ago=$(date -v -1H +%s) curl -s -G '[http://localhost:9090/api/v1/query](http://localhost:9090/api/v1/query)' \ --data-urlencode "query=max(MemoryUsage_Max{env=\"production\", nodeName=~\"systemdcrtest2-(c[0-9]+-)?f.+\", pool=\"heap\", dc=~\"yul1\"})" \ --data-urlencode "time=${one_hour_ago}" | jq -r '.data.result[] | { "metric": .metric, "timestamp": .value[0], "value": .value[1] }' | jq
```

---

```
curl -s -G '[http://localhost:9090/api/v1/query](http://localhost:9090/api/v1/query)' \ --data-urlencode "query=max_over_time(MemoryUsage_Used{env=\"production\", nodeName=~\"systemdcrtest2-(c[0-9]+-)?f.+\", pool=\"heap\", dc=~\"yul1\"}[30m])*1.2+4294967296" \ --data-urlencode "time=${one_hour_ago}" | jq -r '.data.result[] |
```

---

```
202405281717-SREPROVNG-634-30617505
```

---

```
kubectl get services --context fra1 --all-namespaces --no-headers | grep -E '.*-prod-db-.*-0'
```

```
kubectl get service <service-name> -n <namespace> --context fra1 -o jsonpath='{.spec.publishNotReadyAddresses}'
```

```
kubectl patch svc <service-name> -n <namespace> --context fra1 -p '{"spec":{"publishNotReadyAddresses":true}}'
```

Pull Request Description:

- Add `publishNotReadyAddresses: true` to the db.yaml Helm chart
- Allows Express DB services to expose Pods in Terminating state
- Prevents connection failures when Pods are terminating (up to 30+ minutes)
- Applies to Express clusters managed by ArgoCD (excludes "-0" suffix DB services)

This change addresses the issue of Pods in Terminating state being removed from the Express DB service backend, causing connection failures for clients. By adding `publishNotReadyAddresses: true` to the service spec in the db.yaml Helm chart, the service will continue exposing Pods even when they are in the Terminating state, ensuring uninterrupted connectivity.

Note: For Express clusters with DB services ending in "-0" (e.g., telefonica), manual patching is required as these services are created by the provisioning script and not managed by ArgoCD.
