---
up: "[[2024-W44]]"
description: ""
publish: false
starred: false
status: ""
type: note
tags:
  - periodic/daily
cssclasses:
  - "cards"
  - "cards-cols-1"
obsidianUIMode: source
obsidianEditingMode: live
template: "[[Daily]]"
created: 20241029115131
modified: 20241030093038
aliases:
  - Tuesday - October 29th 2024
linter-yaml-title-alias: Tuesday - October 29th 2024
title: Tuesday - October 29th 2024
id: 10
week: "[[2024-W44]]"
yearly: "[[2024]]"
quarterly: "[[2024-Q4]]"
monthly: "[[2024-10]]"
daily: "[[2024-10-29]]"
month: "October"
weekday: Tuesday
---

# Tuesday - October 29th 2024

## Memos Personal

## Memos Work

## Working On

[clusterconfig-sc4/banorte.xml at master · DeployerConfig/clusterconfig-sc4](https://github.medallia.com/DeployerConfig/clusterconfig-sc4/blob/master/banorte.xml)

---

```python
@retry(
        stop_max_attempt_number=5,
        wait_exponential_multiplier=1000,
        wait_exponential_max=100000,
    )
    def _emit_metrics(self) -> None:
```

- Can provide a function that tests what kind of exception that it is

---

```
-Djava.security.egd
```

```
node-id=test-fd1
roles=FRONTEND,SYNCHRONIZER
```

```
-Ds3cachestore.signerOverride=AWSS3V4Signer
```

```
bash-4.4$ cat s3cachestore.properties
accessKey=PSFBIAZFIAAADOAN
secretKey=DD6700008+63ceBBF66E8Ff9a79b85GEIEPNDFIMIPJODF
endpoint=http://s3.den.medallia.com
bucket=testbucket

socketTimeout=3600000
connectionTimeout=300000
```

- Will not be visible here in configuration but this is what it is using.

---

I'm going to make some changes to the existing process. I've realized that in the provisioning in G, we don't need to monitor the startup probe and the readiness probe. This adds unnecessary complexity. I would like your help in removing this part of the code for now.

The scope of the change is to redirect the process to achieve the same outcome but without the class we introduced for the probe. We should not depend on the startup probe because not all node types will have one. Instead, we can implement a mechanism that waits as long as the task needs and sets a high threshold for how long we will wait for it to finish.

We can use the container's restart status as an indicator of failure. By the time we reach the rollout phase, we can assume that everything else has occurred, and the container restarting is a clear sign that the health has been compromised.

There is a parameter called "wait for node," which will determine whether we wait for the entire process or end it before the pod comes back. This means we will recognize that the pod has started again but not wait for the container to come back up.

We will remove the startup probe and replace it with a similar monitoring method. Instead of relying on the startup probe, we will use whether the Express container has restarted to determine if the application came back up correctly or if it failed.

```
2024-10-29 14:49:53,901 INFO step_bounce_node Retrieved cluster state:
- varsamisktest-fe1: SYNCHRONIZED
- varsamisktest-fe2: SYNCHRONIZED
- varsamisktest-fe3: SYNCHRONIZED
- varsamisktest-fe4: SYNCHRONIZED
2024-10-29 14:49:53,901 DEBUG abstract_step updating step state to: PutStatusBody(stepName='bounce_node', stepState='RUNNING', updatedAt='2024-10-29T19:49:53.901636Z', stepNameExtra='', stepTargets=[], stepStateDetail=['Monitoring cluster state for node: varsamisktest-fe3', 'Current cluster state:', '   varsamisktest-fe1: SYNCHRONIZED', '   varsamisktest-fe2: SYNCHRONIZED', '➡️ varsamisktest-fe3: SYNCHRONIZED', '   varsamisktest-fe4: SYNCHRONIZED'])
```

```
def _update_state(self, new_state: BounceState, detail: str = "", extra_details: Optional[dict] = None):
        self.current_state = new_state
        if extra_details is None:
            extra_details = {}

        if new_state in [BounceState.WAITING_FOR_POD_READY, BounceState.NODE_BOOTING] and self.startup_config:
            elapsed = int(self.startup_config.elapsed_time())
            max_time = self.startup_config.max_startup_time()
            remaining = max(0, max_time - elapsed)

            startup_info = {
                "Startup Probe Status": f"Container running for {self._format_time_duration(elapsed)}",
                "Time until probe failure": self._format_time_duration(remaining),
                "Maximum startup time": self._format_time_duration(max_time),
            }
            extra_details = {**startup_info, **extra_details}

        extra_details["Current State"] = new_state.value
        if new_state in [BounceState.NODE_BOOTING, BounceState.NODE_BOOTED, BounceState.NODE_SYNCING]:
            extra_details["State Type"] = "Node State"
        else:
            extra_details["State Type"] = "Process State"

        message = f"Bounce node state: {new_state.value}" + (f" - {detail}" if detail else "")
        log.info(message)

        # Update step state with full details
        state_message = [message]
        if extra_details:
            state_message.extend(f"{k}: {v}" for k, v in extra_details.items())
        self.update_step_state(StepState.RUNNING, state_message)

        self.notify_slack(message, "state", extra_details)
```

```
def _is_cr_up(self):
        cr = self.k8s.get_namespaced_express_object(
            self.vars.topology.namespace,
            self.vars.topology.node_by_name(self.params.node_name).name,
            ExpressObjectType.BACKEND if self.is_be else ExpressObjectType.FRONTEND,
        )
        return cr["spec"]["state"]["up"]
```

```
I think there's something funky going on with this. And I wanna know if, like, because I think that, I don't think we actually have to, like, create a time stamp than when we delete, because it doesn't necessarily need to persist like this. Right? Like, I think that we'd be better off, like, using the method that, every other, like, every every other, method that has to wait for some amount of time is using, which doesn't which also doesn't require a, like, a check like this. So

ex:

    def create_state_check(
        cls,
        operation_name: str,
        max_attempts: int = 30,
        multiplier: int = 1000,
        max_wait: int = 10000,
        error_state: Optional[BounceState] = None,
        success_state: Optional[BounceState] = None,
        notify_on_retry: bool = True,
    ) -> Callable[[Callable[…, T]], Callable[…, T]]:

…

error

Traceback (most recent call last):
  File "/Users/erauner/git/provisioning-ng/prov_platform/mec/MecBounceNode/bounce_node_abstract.py", line 83, in wrapper
    result = func(self, *args, **kwargs)
  File "/Users/erauner/git/provisioning-ng/prov_platform/mec/MecBounceNode/step_bounce_node.py", line 758, in _wait_for_pod_down
    raise StepBounceNodeException(f"Pod did not terminate within {self.params.wait_for_termination_s} seconds")
prov_platform.mec.MecBounceNode.step_bounce_node.StepBounceNodeException: step 'StepBounceNode' failed in '_wait_for_pod_down' with: Pod did not terminate within 3600 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/erauner/git/provisioning-ng/prov_platform/mec/MecBounceNode/step_bounce_node.py", line 1274, in bounce_k8s
    self._execute_pod_deletion()
  File "/Users/erauner/git/provisioning-ng/prov_platform/mec/MecBounceNode/step_bounce_node.py", line 1065, in _execute_pod_deletion
    if not self._wait_for_pod_down():
  File "/Users/erauner/.pyenv/versions/3.9.7/envs/provisioning-ng/lib/python3.9/site-packages/retrying.py", line 56, in wrapped_f
    return Retrying(*dargs, **dkw).call(f, *args, **kw)
  File "/Users/erauner/.pyenv/versions/3.9.7/envs/provisioning-ng/lib/python3.9/site-packages/retrying.py", line 257, in call
    return attempt.get(self._wrap_exception)
  File "/Users/erauner/.pyenv/versions/3.9.7/envs/provisioning-ng/lib/python3.9/site-packages/retrying.py", line 301, in get
    six.reraise(self.value[0], self.value[1], self.value[2])
  File "/Users/erauner/.pyenv/versions/3.9.7/envs/provisioning-ng/lib/python3.9/site-packages/six.py", line 719, in reraise
    raise value
  File "/Users/erauner/.pyenv/versions/3.9.7/envs/provisioning-ng/lib/python3.9/site-packages/retrying.py", line 251, in call
    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)
  File "/Users/erauner/git/provisioning-ng/prov_platform/mec/MecBounceNode/bounce_node_abstract.py", line 97, in wrapper
    raise BounceNodeAbstractStepException(f"{operation_name} failed: {e}")
prov_platform.mec.MecBounceNode.bounce_node_abstract.BounceNodeAbstractStepException: step 'BounceNodeAbstractStepException' failed in '__init__' with: Pod termination failed: step 'StepBounceNode' failed in '_wait_for_pod_down' with: Pod did not terminate within 3600 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/erauner/git/provisioning-ng/lib/abstract_step.py", line 741, in _perform
    self.perform()
  File "/Users/erauner/git/provisioning-ng/prov_platform/mec/MecBounceNode/step_bounce_node.py", line 1287, in perform
    self.bounce_k8s()
  File "/Users/erauner/git/provisioning-ng/prov_platform/mec/MecBounceNode/step_bounce_node.py", line 1282, in bounce_k8s
    raise StepBounceNodeException(f"Bounce operation failed: {e}")
prov_platform.mec.MecBounceNode.step_bounce_node.StepBounceNodeException: step 'StepBounceNode' failed in 'bounce_k8s' with: Bounce operation failed: step 'BounceNodeAbstractStepException' failed in '__init__' with: Pod termination failed: step 'StepBounceNode' failed in '_wait_for_pod_down' with: Pod did not terminate within 3600 seconds

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/erauner/git/provisioning-ng/step.py", line 156, in <module>
    step._perform()
  File "/Users/erauner/git/provisioning-ng/lib/abstract_step.py", line 749, in _perform
    raise AbstractStepException(f"step failed with {ex}") from ex
lib.abstract_step.AbstractStepException: step 'StepBounceNode' failed in '_perform' with: step failed with step 'StepBounceNode' failed in 'bounce_k8s' with: Bounce operation failed: step 'BounceNodeAbstractStepException' failed in '__init__' with: Pod termination failed: step 'StepBounceNode' failed in '_wait_for_pod_down' with: Pod did not terminate within 3600 seconds
2024-10-29 16:39:51,463 CRITICAL step step failed with exception: step 'StepBounceNode' failed in '_perform' with: step failed with step 'StepBounceNode' failed in 'bounce_k8s' with: Bounce operation failed: step 'BounceNodeAbstractStepException' failed in '__init__' with: Pod termination failed: step 'StepBounceNode' failed in '_wait_for_pod_down' with: Pod did not terminate within 3600 seconds, cause: step 'StepBounceNode' failed in 'bounce_k8s' with: Bounce operation failed: step 'BounceNodeAbstractStepException' failed in '__init__' with: Pod termination failed: step 'StepBounceNode' failed in '_wait_for_pod_down' with: Pod did not terminate within 3600 seconds, context: step 'StepBounceNode' failed in 'bounce_k8s' with: Bounce operation failed: step 'BounceNodeAbstractStepException' failed in '__init__' with: Pod termination failed: step 'StepBounceNode' failed in '_wait_for_pod_down' with: Pod did not terminate within 3600 seconds, exiting.

 - The terminal process "/bin/zsh '-l', '-c', 'python /Users/erauner/git/provisioning-ng/step.py -N -L --customer-identities varsamisktest --context XD1RiC3bHQ --platform mec --task-type MecBounceNode --working-dir /Users/erauner/work/prov-ng/api --config-directory /var/provision/api/config --secrets-file /Users/erauner/work/prov-ng/api/secrets/secrets.yaml --params-file /Users/erauner/work/prov-ng/api/params.yaml --output-file /Users/erauner/git/provisioning-ng/output/ --run-dc den --debug bounce_node'" terminated with exit code: 255.
 - Press any key to close the terminal.

code:

    def create_state_check(
        cls,
        operation_name: str,
        max_attempts: int = 30,
        multiplier: int = 1000,
        max_wait: int = 10000,
        error_state: Optional[BounceState] = None,
        success_state: Optional[BounceState] = None,
        notify_on_retry: bool = True,
    ) -> Callable[[Callable[…, T]], Callable[…, T]]:
```

```
def periodic_monitor():
            while not self.monitor_stop_event.is_set():
                self._monitor_pod_state()
                if self.current_state != BounceState.COMPLETED:
                    self._monitor_cluster_state()
                time.sleep(30)

        self.monitor_thread = threading.Thread(target=periodic_monitor, daemon=True)
        self.monitor_thread.start()
```

---

- `create_state_check` could be renamed to `retry_with_state_management`
- `retry_with_backoff` could be renamed to `retry_with_exponential_backoff`



```
2024-10-30 00:59:24,095 INFO step_monitor Bounce node state: Initializing
2024-10-30 00:59:25,181 INFO bounce_node_abstract Express container readiness in progress: step 'StepMonitor' failed in '_wait_for_express_ready' with: RETRY: Pod not healthy: {'phase': 'Running', 'conditions': ['PodReadyToStartContainers=True', 'Initialized=True', 'Ready=False', 'ContainersReady=False', 'PodScheduled=True'], 'ready': False}
2024-10-30 00:59:30,829 INFO bounce_node_abstract Express container readiness in progress: step 'StepMonitor' failed in '_wait_for_express_ready' with: RETRY: Pod not healthy: {'phase': 'Running', 'conditions': ['PodReadyToStartContainers=True', 'Initialized=True', 'Ready=False', 'ContainersReady=False', 'PodScheduled=True'], 'ready': False}
```




```
bounce_node

2024-10-30 01:04:58,401 INFO step_bounce_node Starting bounce process
2024-10-30 01:04:58,401 INFO step_bounce_node Bounce node state: Initializing
2024-10-30 01:05:00,941 INFO step_bounce_node Original pod UID: a31a6004-d174-4634-bacd-ecb92b09b158
2024-10-30 01:05:00,941 INFO step_bounce_node Initial container restart count: 0
2024-10-30 01:05:00,942 INFO step_bounce_node Bounce node state: Waiting for pod termination
2024-10-30 01:05:01,930 INFO step_bounce_node Pod deletion initiated with grace period: 30s
2024-10-30 01:05:02,002 INFO step_bounce_node Pod varsamisktest-fe2 still terminating…
2024-10-30 01:05:07,145 INFO step_bounce_node Pod varsamisktest-fe2 still terminating…
…

2024-10-30 01:05:38,640 INFO step_bounce_node New pod detected with UID: 4c238831-4dc8-49e7-bd72-ab4c5348f125
2024-10-30 01:05:38,640 INFO step_bounce_node Pod successfully bounced
2024-10-30 01:05:38,640 INFO step_bounce_node Bounce node state: Completed
2024-10-30 01:05:39,524 INFO step_bounce_node Saving current bounce state

monitor step

2024-10-30 01:06:15,931 INFO step_monitor Bounce node state: Initializing
2024-10-30 01:06:19,653 INFO bounce_node_abstract Express container readiness in progress: step 'StepMonitor' failed in '_wait_for_express_ready' with: RETRY: Pod not healthy: {'phase': 'Running', 'conditions': ['PodReadyToStartContainers=True', 'Initialized=True', 'Ready=False', 'ContainersReady=False', 'PodScheduled=True'], 'ready': False}
2024-10-30 01:06:25,333 INFO bounce_node_abstract Express container readiness in progress: step 'StepMonitor' failed in '_wait_for_express_ready' with: RETRY: Pod not healthy: {'phase': 'Running', 'conditions': ['PodReadyToStartContainers=True', 'Initialized=True', 'Ready=False', 'ContainersReady=False', 'PodScheduled=True'], 'ready': False}
…
2024-10-30 01:08:32,002 INFO bounce_node_abstract Express container readiness in progress: step 'StepMonitor' failed in '_wait_for_express_ready' with: RETRY: Pod not healthy: {'phase': 'Running', 'conditions': ['PodReadyToStartContainers=True', 'Initialized=True', 'Ready=False', 'ContainersReady=False', 'PodScheduled=True'], 'ready': False}
2024-10-30 01:08:37,490 INFO tunnel starting kubectl tunnel to pod/varsamisktest-fe2 in tenant-123634-prod
Forwarding from 127.0.0.1:56004 -> 9100
Handling connection for 56004
Handling connection for 56004
2024-10-30 01:08:38,726 INFO tunnel stopping kubectl tunnel to pod/varsamisktest-fe2 in tenant-123634-prod
2024-10-30 01:08:38,727 INFO tunnel starting kubectl tunnel to pod/varsamisktest-be in tenant-123634-prod
Forwarding from 127.0.0.1:56011 -> 9100
Handling connection for 56011
Handling connection for 56011
2024-10-30 01:08:40,079 INFO tunnel stopping kubectl tunnel to pod/varsamisktest-be in tenant-123634-prod
2024-10-30 01:08:40,083 INFO step_monitor Express container is ready and synchronized
2024-10-30 01:08:40,083 INFO step_monitor Express container monitoring completed successfully
2024-10-30 01:08:40,083 INFO step_monitor Bounce node state: Completed
```



```
2024-10-30 01:22:53,590 INFO step_bounce_node Starting bounce process
2024-10-30 01:22:53,590 INFO bounce_node_abstract Bounce node state: Initializing
2024-10-30 01:22:54,141 INFO step_bounce_node Original pod UID: 4c238831-4dc8-49e7-bd72-ab4c5348f125
2024-10-30 01:22:54,141 INFO step_bounce_node Initial container restart count: 0
2024-10-30 01:22:54,142 INFO bounce_node_abstract Bounce node state: Waiting for pod termination
2024-10-30 01:22:54,509 INFO step_bounce_node Pod deletion initiated with grace period: 30s
2024-10-30 01:22:54,589 INFO step_bounce_node Pod varsamisktest-fe2 still terminating…
2024-10-30 01:22:59,732 INFO step_bounce_node Pod varsamisktest-fe2 still terminating…
2024-10-30 01:23:04,882 INFO step_bounce_node Pod varsamisktest-fe2 still terminating…
2024-10-30 01:23:10,031 INFO step_bounce_node Pod varsamisktest-fe2 still terminating…
2024-10-30 01:23:15,180 INFO step_bounce_node Pod varsamisktest-fe2 still terminating…
2024-10-30 01:23:20,328 INFO step_bounce_node Pod varsamisktest-fe2 still terminating…
2024-10-30 01:23:25,455 INFO step_bounce_node Pod varsamisktest-fe2 still terminating…
2024-10-30 01:23:30,594 INFO step_bounce_node New pod detected with UID: b3cbcf34-4309-48da-937a-6d12686cca29
2024-10-30 01:23:30,594 INFO step_bounce_node Pod successfully bounced
2024-10-30 01:23:30,594 INFO bounce_node_abstract Bounce node state: Completed
```


```
2024-10-30 01:25:34,581 INFO step_monitor Bounce node state: Initializing
2024-10-30 01:25:35,592 INFO bounce_node_abstract Express container readiness in progress: step 'StepMonitor' failed in '_wait_for_express_ready' with: RETRY: Pod not healthy: {'phase': 'Running', 'conditions': ['PodReadyToStartContainers=True', 'Initialized=True', 'Ready=False', 'ContainersReady=False', 'PodScheduled=True'], 'ready': False}
2024-10-30 01:25:40,741 INFO bounce_node_abstract Express container readiness in progress: step 'StepMonitor' failed in '_wait_for_express_ready' with: RETRY: Pod not healthy: {'phase': 'Running', 'conditions': ['PodReadyToStartContainers=True', 'Initialized=True', 'Ready=False', 'ContainersReady=False', 'PodScheduled=True'], 'ready': False}
...

```
