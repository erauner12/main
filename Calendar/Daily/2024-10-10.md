---
up: "[[2024-W41]]"
description: ""
publish: false
starred: false
status: ""
type: note
tags:
  - periodic/daily
cssclasses:
  - "cards"
  - "cards-cols-1"
obsidianUIMode: source
obsidianEditingMode: live
template: "[[Daily]]"
created: 20241010095318
modified: 20241011104810
aliases:
  - Thursday - October 10th 2024
linter-yaml-title-alias: Thursday - October 10th 2024
title: Thursday - October 10th 2024
id: 10
week: "[[2024-W41]]"
yearly: "[[2024]]"
quarterly: "[[2024-Q4]]"
monthly: "[[2024-10]]"
daily: "[[2024-10-10]]"
month: "October"
weekday: Thursday
---

# Thursday - October 10th 2024


I think one additional aspect to consider is that, at the pod probe layer, it might be beneficial to indicate what is happening at this level. The startup probe is at the pod level, but it is probing the container, specifically the Express application container. The logic and flow of the diagram look really good; however, it needs to acknowledge the differences in layers and the granularity of the custom resource, pod, and container.



Make a global change to Govcloud, colos, OCI



```
You guys like want to follow the approach that we currently following OCI to deploy MC clusters, right?

But we are currently working on like applying GitOps in colors as a proof of concept, proof of concept or like as a party.

We want to prove party between protploid and what following the GitOps approach, that's the goal of our project.

And we have developed, we did kind of the same thing that you're planning to do.

We took the help from OCI and built upon it and like made it work for colors.

Now this help is using Citrix for both internal and external ingresses.

But we plan to use it as things are in place right now, meaning like that we will still use the load balancers.

But we do at the Citrix resources.

So we do have them in place but we don't so we don't switch the next to them.

So yeah, that's in a nutshell what we've been doing and what where we are.

We already have the, I can't tell you more, we have like automation to do deployments but this is like again as I told you it's like just in a proof of party state.

We also have a script that we can, we are using to migrate from cluster config to deployment repo.

So we read whatever is in the XML file.

So the next you're not using.

Okay.

But we can come up with something similar like whatever you're using.

So yeah, I guess where we are.

We've been migrating non-express related stuff for a while and didn't push too hard on express because there was other blockers before we got there.

But the past few months we finished a lot of the stuff that was blocking including migrating to a staging, comm services, sandbox employer and all of the MEC sandboxes are in Kubernetes now in GovCloud.

There's some stuff like again unrelated to express that's still getting migrated but express is going to be I think the last stretch and our requirement is not necessarily we can't use prod deployer.

It's got to be a get based approach which I know both the OCI and the one year proposing are.

So there's not, you know when we say like we wanted to do the OCI approach solely because that was the one example I could see of.

That's why we used it also.

So right now all the prod instances in GovCloud are deployed with GC deployer which is I don't know how familiar you guys are with it but it has a yaml that you feed it and it uses Titan and order shitter and stuff to make a deployment plan similar to what sandbox employer is doing.

So if we have, if the method that you guys are working on in Kuulos if we can adopt that to to GovCloud migration wise rather than like translating exit mails we'll have to use Titan commands right to pull FEs and stuff out of it to pull the information from Titan and shut down one at a time whatever.

But there's only 32 I think instances right now and GovCloud says not even if it's only partially automated or we're using some like, it's not a big idea I guess if it's not like.

We can give you a tour because we also forgot to mention that we also added those as our DCD applications like with this sense of version that it's being used and like they were already deployed this way and you can basically use the same template help with using help tap.

Sorry sorry I didn't mean it.

No no it's okay it's okay it's just about to show you some stuff.

It's about the three long months.

And there are some improvements that we're asking because I don't know in which version of the Xpress operator you don't if you don't know.

Yeah okay.

It should be the latest I think the same colors we just updated not the longer but if not we can get it there.

Okay okay yeah because we are asking we are in the middle of like safe is implementing some improvements in the operator but I don't know when those will reach you.

They are actually they are actually related to getting out of deadlock situations like for example all the nodes are down then because of some logic of the order of things like how nodes should come up like it might end up in a deadlock and then we need to now what we're asking from safe is like to be able to recover from this automatically without an intervention because it should be the case.

That's one of the features then there are other improvements like in timing of reconciliation because like we found out that for a cluster of like four nodes with no data inside it took like approximately an hour to reconcile but they improve those on this so it will be faster.

It depends of course on the size of a cluster and the size of the data set and this stuff.

But yeah anyway so I'll show you like oops.

How is it handling a NFS because I think in OCI raids now it's using the whatever NFS driver like for OCI.

It's also just mounting the host path.

Yeah yeah yeah so this is like the said said deers that's what we're saying right?

Yeah we're doing it.

It's like a certain thing.

And in Titan based stuff there's a shared storage service that like creates the folder and stuff on the host pack like in NFS beforehand does that not is that not necessary here is something I was thinking about.

No no so look like because we but you're talking about provisioning new ones right this part of the provisioning process I guess because you created ones and then like it's using it.

Yeah yeah potentially so if you're doing it out of band that's cool too I just curious if.

So no we're not like because we I don't know if you know about our product or our framework we have an automation framework it started like as a framework to automate the provisioning of new class customer instances and then customers for other applications slowly we import the data other applications not only let me see and then we also started doing other type of automation not related to provisioning like migrating data bases actually getting grove scripts and etc etc.

And they those NFS directories the sub directors are created as part of this automation that provisions the clusters we're using this step in the workflow and yeah yeah we're using our workflows under the foot we have an API server in front of it which you can takes a request and like creates a the workflow based on the template and we also have a separate code base with where we maintain the actual scripts of the workflows and as steps and this is one one of the steps like we create the this the sub director in the NFS storage and but as you can see we are these are the values for a single instance like we bring we are bringing in when we are migrating also static IPs but don't know if that's something probably that's something you're still using also and so we took under consideration this and there is the here you see that we're defining the express version and config change it for the cluster call cluster configuration which means that all of the nodes will have the same version and config change it but you can you can also define it only for specific type no type or for specific node down to and the deeper you go the more presence it has like and and so I'm just mentioning it because it was a requirement for us that in cases of troubleshooting they would need to deploy different versions and so on but in a nutshell those are the values and here you see okay I can show you the exact instance is it is the DB part of the express operator handling?

No unfortunately not No unfortunately no because we have paid the scripts that is doing that but in the case of wood life we have it but there's a lot of like not resistance but there are a lot of things that need to change from the mdbs thing I guess so we can we can do that but in our current phase we don't deal with that but okay you could bring it in because I know that the no CI they do have it I guess my I'm in an ideal world yeah I think it would be a lot better if it's all together but my more higher priority goal is to meet the configuration where it's going to be everywhere else rather than like what what happened in our amesos is they developed like whatever GC deployer this new weighted deploy that was going to replace prod deployer dove cloud and APS-E2 go to that and then they said never mind we're not using that so we're the only ones using this deployer that like half supported so I'm hesitant to like get too far out in front of of something and then be left on an island yeah yeah sure so yeah yeah yeah yeah okay so this is the same environment deploy it's saying like it has everything some things are automatically created by the operator maybe you're aware of it already but if not like because for its node there is a yeah a service created by the operator and there is a also state state but yeah the service at least and then there are some other kind of services with a with a I don't know automatically that but okay let's not of importance right now yeah so what is the best starting point like as a base right now in there look you need to take a look of like a values file but we have this is this is the latest template this is the one that we're using action how one one that okay yeah you can find extensive documentation put those to mr.

Evan here which he put a lot of effort like also documenting everything how the hands up is supposed to be working whether whatever the different values how you're supposed to say things and so on he's talking about residence inside like it's extensive like I think you could find the answers you're looking for there so what I what I would like to do rather than copy your home chart and tweak it for working for dev cloud and then going from there I mean I do want to do that but I'd like to make the helm chart work for both yeah and right right now we have got the deployment and Atlas deployment and they're separate at some point in the future they might be the same repo I don't know but like yeah anytime the helm chart we go to 1.0.1 here we update it in the look this is a very valid point that you're making and we are aware of it and we plan to do it in a second phase because we have a deadline until the end of kombir and say to deliver this party but it's like it's in our I think one of the biggest priorities because we're discussing with Larry as well the other day and I think that one of the biggest priorities would be for the next phase to unite a unify the helm chart and there is no reason that we still need to use the contour for example for internal access in OCI they already have cedrix also and what we plan to do but we need to talk we need to come in a consensus with CIF like we want to extract the helm chart in a proper hand repository version it properly make it work for everything because in the bottom line it's Kubernetes if you have like the same APIs and and so on and stuff like it should work and but we will be able also to say like okay and go cloud we use the version with this tag or we can tag your your versions differently we can keep them in a separate branch in the repository or whatever like this I mean there's the same versions right but I know I know that things are slower to be propagated to go from sometimes I'm the same like it doesn't it doesn't happen we do deployments more frequently than everywhere else because we got updated base images all the time so it's actually usually easier to get newer versions if if there's a big change to like an application that has to go through like an audit then yeah it's a lot slower and it's got to go back there but this like deployment infrastructure yeah it should be yeah okay then then it's even it's even better but but in the bottom line like you can be in a separate tag like you don't need to build the same tag like you didn't be whatever like yeah but that's what we plan we plan to unify them like version it properly and make everything use the same thing what's the timeline right now you guys have a deadline to have like this working POC or whatever but look this this is now in its in a stable in a stable state like this is what we're using for and we give it to people to actually test it and they will write the acceptance document so this is really used right now but it's still in the but our deadline is like the end of the real deadline because there was a soft deadline for 15th of uh in october we're gonna meet that but there is like a soft deadline on the end of october okay and then and against uh what we took with we're telling you in the other minute right do you just want to have like a distance up and right right that's it well yeah i want to be end of november yeah i just so yeah i'd like to be able to start working on figuring out what needs to be different uh for go cloud and yeah get something working in staging but i just for actually migrating i don't if if you guys are gonna supposed to be at a more final state at the end of october like waiting waiting until you're done with this and we can make and we can update home charts to work for both before we start rolling it out so there's not like a migration of home charge later or whatever you know i mean yeah um then so like we can have we can be at a point where we have a test instance running with it and say oh these are all the things we had to change between to get it working in go cloud ideally i can try to change them so that they're you know backwards like work both ways and we can work to merge that together before we do all the migrations i don't know something sense yeah that's for me uh i recommend you to use all these times to check the reputation okay um yeah me for everybody the big the biggest difference is i mean i've looked through through this stuff some the uh deployment wise some differences that we have um network services is still not provided a network services supported in grass controller in go cloud so we have contour we have contour but i do we do not use it for anything customer facing because otherwise i'd have to support that so they're like an mEC and stuff is still using l-bass because network services support us that until there's something uh that they will support so we'd probably just not include the ingresses right now and that it would be handled the same way it is currently yeah okay um that's uh that's okay because like we got the if this is a case look maybe i should have like uh this especially straightforward right just like yeah yeah because we do it right here yeah yeah because we do have like um i'm saying now we do have the data center we don't have the way it's uh in which fabric you're not fabric in which infrastructure is being deployed if you want like what is the infrastructure is it go get get up is it colo is it like uh yeah oci or something else there is button like we could we could put logic in the in the template and say something like okay if it's not in if it's if it's a gov cloud data data center then this we will go to the ingresses and we will not include those in the rendered they will not render those templates you know we can easily do that if you want the um something like that but i would i would now it seems that we need to have some done or some some value in the in the values file probably somewhere here when this generic settings and say like if it's called cloud if it's like oci or if it's colo or is it cloud yeah isn't it's a thought of where you want to put that logic though because you could also just have like ingress included false or something right like like more like but if you go to the if you go to the global values though you'll see like uh the way that we're overriding and whatnot it might make oh yeah sorry it might make it move lady we have a global conflict like we have a global conflict so you have both these yeah they see conflict and we can say here yeah it's called cloud or whatever and then we can read that file which is good because you can still override it if you wanted to say because what i worry about if you just have like a dub-kug tag now i want to test because we have an ingress controller and i want one to be to have ingress now you know like this you can override specifically for individual ones anyway i guess i guess i guess uh okay that's what the main okay yeah like uh like ingresses own or whatever like brain zone yeah and uh we could also use the the centric's ip drains because we do need that and we can just detect if you have this we we render them if you don't have it we don't remember yeah it is only i kind of like what you were saying about the oci colos uh and then yeah uh sorry oci colos and dub cloud like the difference yeah but also yeah that's what we're saying that if they if the guys want to test then then either they will need to i don't know say like kind of that this is not uh with a conclude or something but like with the what the what the god's actually go ahead as long as you handle it the same as the dcs where it's like oci defaults dub cloud defaults yeah you know and then you could still override it if you want and it's clear like it's the same pattern you're using press that's a be easy to read it i think uh just taking into account this global config into this precedence system like would allow for that but right now we don't we're only taking into consideration the precedence of like node and uh dc and then the nodes themselves so that makes sense so i in general we don't have to maybe solve it all on the call but like that step between okay we have it working and it's different and here's how we want to define it everywhere you know like do we want to do default global here like whatever the same discussion we're having for each individual thing that's the part i think ideally i'd like to solve before we roll it out every yeah like we get it working then we decide on an approach yeah rather the standard medallion way is like we have something working and then now we start pushing it into pro-chainable way through so that's what i'm hoping to it i think uh i think once we get uh this mark of parity and um check box whatever like we can hopefully start making more like changes that we need to to the helm chart without being having to be as i mean care that's not true like i just want to make sure that like i'm not breaking anything before this very important date so yeah making you want i'll hold it on our side yeah but i have a lot of uh like probably like a water hose or a fire hose worth of like ideas of but how i want to change to make it more efficient and i just don't want to like throw a crayon bat all into this very first phase yeah that's fine and even i'm not saying also necessarily that it needs to be like completely final before we start rolling it out but in a state where we can keep up with changes you know like we have a process in place and we have agreed on how it's going to work so that when you have you are implementing something like it comes to go back to and it's not like a year later we're way different and we got to pull a bunch of that that's that's i may have one note to this sorry guys uh because when when where some of us was talking about this uh deadline with the uh end of october this means really just the feature parity with the prot-de-player right uh there then they're assuming that this is going to be accepted and there's going to be a phase two of this project that uh should include some further changes on you know beyond the feature parity like being able to manage uh you know DCR nodes dynamic front ends uh it's like uh instances sandboxes things like that so and even safe plans to make uh some probably significant changes to the to the express operator as well so there might be still changes coming uh to to the solution uh so just to let you know that this is definitely not a final state or even if you're talking about uh october 30 then this is not going to be something that we will be migrating in production instances too because there are a lot of more requirements that we need to do or meet in order for you know the management to say hey you know we are ready to you know start migrating things yeah and i don't have a i personally don't have a deadline for the migrations in gov cloud like if it makes the most sense for us to fit that in somewhere later like in that roadmap that you already have been cool like let's bring that up i don't know i mean management has a push for the migration because it lets us deprecate ermazos and gov cloud and saves a bunch of infrastructure costs you know like we can get a rid of ermazos controllers and like uh just the AWS bill savings from doing that so first personally i'd rather do it where it makes the most sense and i'm comfortable with that as long as everybody what i don't like is like you guys have a roadmap and we're not on it and i'm trying to like you know merge in at some point in the future if it's if we're everybody's in agreement about when it's gonna happen then that's cool with me i think we just had to push that back to you know what i think that we should start including you guys in the loop because like there are as coming mentioned there are some things going to be discussed and decided with the safety like they want to make changes like in the express operator so you should be part of these those discussions because maybe you have like requirements that we are not aware of like and so on so i think you should be included in the loop in lots of cases and we will we will be in sync because that's that's actually what everybody wants like they they're not denying everybody understands that it's way better if we have common templates for everyone and yeah yeah okay um cool so Luis when i only talked to Tony i guess like figure out i think the deadline that they gave for migration for us was somewhat arbitrary to put a stake in the ground to say hey we actually are serious we need to get the migrations done so if we act if we have a counter proposal of hey it would make more sense if we did it at this point in the general timeline then we probably could come back with that um but i i can certainly start working on getting something working on our side to so that we have input on what what differences we have that we would need in the helm chart going forward but yeah if i could it hasn't helped in understanding in the ideal state at what point would we uh start the actual migration part what point in your road map and timeline it would make the most sense for gov hub to start migrating then we can ask that back of of Tony and vinka and stuff and see i don't seems reasonable but yeah one thing is the planning for the upcoming phases as i mentioned another thing is that before we are able to migrate instances to get ops basically to this solution uh some other stuff needs to happen right like because if you're assuming that you know this whole thing says that there is not going to be a prot employer right so there has to be a way how to you know maintain these instances right we need to educate uh you know l1's pro team that's a benefit that we have for a gov cloud we don't have protopler right now so all the stuff that they're like oh no we can't get rid of protopler because we wouldn't be able to do this crazy like shadow node like i don't know what like all the weird ops that we that we rely on protopler for we can't do right now we have stuff running in a row mezzos deployed by titan like it's very limited to what kind of special operational side things that we have to do so supporting every single function of protopler would not would be above parity for us right like if it's just running uh yeah and did i hear you correctly that you did you mentioned that you just have 30 make instances or yeah 32 so yeah because when when uh asking is that you know on top of this this helm chart and you know it's supposed to operate yourself we are also introducing some kind of automation as far as i mentioned at the beginning so that you know when the release management team wants to deploy you know the whole data center with hundreds of clusters that you know they probably don't want to do a you know pull requests on their own uh to to you know to make the deployment so we have an automation on top of this which would probably not be applicable in your environment because that's uh you know unless we decide otherwise but i think it doesn't make much sense to try to you know include everything that we have uh in terms of automation yeah because since you just have 32 instances and you know uh the including or introducing the all the pieces that the automation is built uh built with would require a lot of you know inside about because we know that you have strict security requirements right regarding the versions of packages that are installed in the docker images you know base images things like that so uh you would have to uh account for that as well yeah yeah i think even if it was like oh yeah we definitely want that automation to i think that's can be uh future discussion you know like getting stuff in Kubernetes and getting rid of our messos we have a huge win even if everything's completely manual because it's already manual so it's not at least it's all running the same place um but yeah i think what that makes sense to be your team um okay a suit who should we include like in the in the loop is it euro anybody else on your team like and yeah i think just to know from now on if we have discussions with safe like we'll send you the invite you can be there you can be there i would suggest you have there or suit at least listening and like and see what the plans are for sure yeah if you if you include me um i think we'll probably include an even Alex around this call too but you include me i can i can make sure that everybody gets on it okay okay yeah yeah so and uh part of the method i want to send you in um it's right now our uh top is like in um in the pre-prod brands so in in deployment repo so this send you like this uh where it is right now and we have a there's like a i don't know maybe we started the ad you guys um it's like a mEC takupaneti's migration govcloud channel um that they made recently um if you're not in there i'll add you guys in there just as we work through uh getting something working and staging if we have questions about like the hell that help church working and or i don't know like thought process of why we decided certain things um i probably just tag you guys in there uh to discuss and slack the fiscal which which standards up uh you know i don't know what what's called uh i'm hearing here we'll add you you have a big feeling very cool i don't know anything else you think uh oh oh we're talking about it i appreciate you guys uh taking the time to go through this it's okay we want like we have a common target you know we want to we get and find the templates and the the concerts like at least yeah i think it'll be good forever um cool do you have anything else to waste that you wanted to go together no well maybe uh my assemblies you were working on only two to three instances from yeah yeah yeah i mean i mentioned it like in the in the beginning like because the guys don't use actually some profiles they have some other both gov deploy gov deployer okay so this is the blur yeah right which you have treated like some yamos but okay if you give us like a um an example of the of uh this yamofile we can do them also include that and one i think in the script that we have it's not a big deal you you have a link to the script i'm just curious yeah yeah i'm i'm doing this sequencing yeah it's like it's quick and dirty it was done quick and dirty so suddenly passing and i'll send it to you and it worked no one is going to say anything over that but yeah but it works the other thing is that it it works uh um uh both ways so if there's something wrong we can roll back that's how i did it like so when we we can migrate the gitos or go back to legacy and that's how we call it because in our case like uh we have the XML file and like we we extract the values from there then we change the name so we kind of disable it from the protibular this way and or at least make it possible be disabled and then like but then we i kind of thought that okay what if like something breaks and like they want to revert or also include the logic to revert this thing but i don't know so in this redeployer those yamofiles they're like always static and you just change values in there like uh how does it work or you just send it like a post request to something like yeah it's like a post request basically you have the yaml file i mean it is not actually in e sort of get ops we make PRs to the to the yaml files but then you have to spin up uh there's a gc driver okay container that consumes the yaml and makes it but in order for this this this driver to consume it like it needs to be in some get repository right if it's not there like it would not be able to yeah i mean it's this way it's doing it it's not that sophisticated it's just you could give it whatever yaml you wanted we happen to by a process only give it yamels after they were merged to master you know like with a PR and everything but there's nothing preventing you from uh deploying whatever yaml you you want if you have access it's not actually talking to get home it's taking a file like a whatever file you feed it locally but okay okay right here to yay um okay yeah it's pretty limited yeah i would send this to you like we didn't match it yet in the epic that we'll take concern with you with them it's okay i would appreciate okay and cool so we're willing to hear the rest of the guy in the s if we can and i think we share what he has for his motivation too and let's see right yeah i just started those things in the junta like those links that and never know that the documentation page is impossible it's like is like we're willing to flag looking at the repo right everyone it is well yeah i really start trying to make it that way we do have an okay yeah expect eventual consistency so between github and and passific when it comes to the documentation okay uh okay yeah thank you so we can call it unmitting yeah okay yeah here we go see you guys see you thank you yeah hi really so so so so
```




---


[SREPROVNG-874 - Cleanup unfinished step states by kkantar · Pull Request #136 · medallia/sre-provisioning-api-server](https://github.medallia.com/medallia/sre-provisioning-api-server/pull/136)


[sre-provisioning-api/spec/task/mec/MecDeployClusters.yaml at SREPROVNG-776-gitops · medallia/sre-provisioning-api](https://github.medallia.com/medallia/sre-provisioning-api/blob/SREPROVNG-776-gitops/spec/task/mec/MecDeployClusters.yaml)



```
I would like to expand on the handoff between the rendered manifest and the Express operator, specifically regarding how the parameters change. When a set of parameters changes, the deployment revision also updates accordingly. This process involves calculations based on the JSON representation of each node, which reflects its entire set of potential changes. When a change occurs, a new calculation becomes available to each node.

When the Express operator detects a change, it updates not only the deployment revision but also the pod that serves as the deployment dependency and upgrade prerequisite. By doing this, we ensure that both custom resources are updated simultaneously. However, only the pod with actual changes to its specification will be updated.

For instance, if we change a single node, the rendered manifest will show two deployment revision calculations that have changed. Ultimately, only one of those pods will be affected, even though two custom resources were influenced by the Helm calculation. This illustrates how a single change to the values.yaml file can impact the reconciliation process for multiple nodes.
```


```
CLIENT_SECRETCLIENT_ID=e50061c8-a5e3-4424-9b9a-a6fb57d87a98
CLIENT_SECRET=f77633d1-f243-45f1-b6a9-23fd3d204944
```


[Express Deployment Upgrade + Recovery](https://github.medallia.com/gist/erauner/46af3f201dfff46c689e962f251fcd03)



```
.

Please consider the following points regarding these changes. This is crucial because it highlights the purpose of the revision calculation. In the upgrade diagrams I will share in my next message, pay attention to how I distinctly compare scenarios. For instance, when you update a single node that is already on the same revision as the other nodes, we only need to update that specific node.

In cases where we are overriding only parts of the cluster, or when we want all clusters—regardless of whether they have been overridden—to reconcile to the same version, everything must be upgraded to ensure uniformity at the cluster level. For example, all nodes should have the same express version and the necessary configuration changes.

My main point is that I need you to grasp this distinction to understand why the deployment revision is essential. If you can comprehend the examples and the accompanying mermaid diagrams, and incorporate this logic into the diagrams—perhaps by dedicating a section to check whether a change is needed based on the deployment revisions in the rendered manifest—it will clarify why this additional complexity is necessary.

the assumption from the operator's point of view is that if any of the helm chart's parameter's are changing (global or tenant) that the deployment revision will also change at the same time. which is why it works this way
```




```
diff --git a/confluence-docs/misc/express_application_management_roles.md b/confluence-docs/misc/express_application_management_roles.md
--- a/confluence-docs/misc/express_application_management_roles.md
+++ b/confluence-docs/misc/express_application_management_roles.md
@@ -1090,13 +1090,13 @@
 
-    subgraph expressCluster[Express Cluster (Pods)]
-        subgraph fe1[FE1 Pod (order: 1)]
+    subgraph expressCluster[Express Cluster Pods]
+        subgraph fe1[FE1 Pod order: 1]
             fe1Container["Express App Container"]:::component
         end
-        subgraph fe2[FE2 Pod (order: 2)]
+        subgraph fe2[FE2 Pod order: 2]
             fe2Container["Express App Container"]:::component
         end
-        subgraph be[BE Pod (order: 3)]
+        subgraph be[BE Pod order: 3]
             beContainer["Express App Container"]:::component
         end
-        subgraph fe3[FE3 Pod (order: 4)]
+        subgraph fe3[FE3 Pod order: 4]
             fe3Container["Express App Container"]:::component
```



```
diff --git a/confluence-docs/misc/express_application_management_roles.md b/confluence-docs/misc/express_application_management_roles.md
--- a/confluence-docs/misc/express_application_management_roles.md
+++ b/confluence-docs/misc/express_application_management_roles.md
@@ -1178,9 +1177,9 @@
-    %% Value Sources (Ordered by Precedence)
-    subgraph ValueSources[Value Sources (Ordered by Precedence)]
+    %% Value Sources Ordered by Precedence
+    subgraph ValueSources[Value Sources Ordered by Precedence]
         direction TB
-        GC[5. Global Config]:::config
-        DC[4. Data Center Config]:::config
-        CC[3. Cluster Config]:::config
-        NT[2. Node Type Config]:::config
-        NS[1. Node-Specific Config]:::config
+        GC[Global Config]:::config
+        DC[Data Center Config]:::config
+        CC[Cluster Config]:::config
+        NT[Node Type Config]:::config
+        NS[Node-Specific Config]:::config
     end
```
