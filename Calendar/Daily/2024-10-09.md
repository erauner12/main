---
up: "[[2024-W41]]"
description: ""
publish: false
starred: false
status: ""
type: note
tags:
  - periodic/daily
cssclasses:
  - "cards"
  - "cards-cols-1"
obsidianUIMode: source
obsidianEditingMode: live
template: "[[Daily]]"
created: 20241009113055
modified: 20241010095319
aliases:
  - Wednesday - October 9th 2024
linter-yaml-title-alias: Wednesday - October 9th 2024
title: Wednesday - October 9th 2024
id: 10
week: "[[2024-W41]]"
yearly: "[[2024]]"
quarterly: "[[2024-Q4]]"
monthly: "[[2024-10]]"
daily: "[[2024-10-09]]"
month: "October"
weekday: Wednesday
---

# Wednesday - October 9th 2024

```
can you please help me respond to each and every github comment left on my markdown document.

I will provide the document here, and then we will address each point as we go.

…

I'll provide the comment, and then which line it was left on and then we will address that point in the markdown and then provide rationale/reasoning in the github comment itself:

I'll provide my subjective input as well at the end of each so that you can know how to make the change:

> <line>

<comment>

- <input>

….

here is the first one:

> The wording "at Kubernetes cluster-level scope" is a bit clumsy. Consider "at the scope of a Kubernetes cluster".

 **Providing control at Kubernetes cluster-level scope** for managing multiple customer instances across different namespaces.

- I think this could actually be better said. The confusion between express cluster and kubernetes cluster is what is causing this confusion. kubernetes cluster is like at the DC (datacenter) kubernetes context level. And express cluster-level is like meaning express nodes (pods) in a given namespace.
```

If I recall correctly, what was removed was reference to the long-term recommendation. I did not consider it a short-term change for the express operator; it was essentially a long-term suggestion. We recognized that while this might be somewhat relevant, we could reintroduce it for the purpose of this document. However, it is out of scope. Our primary concern right now is defining the current state and understanding the roles involved. This will lead us to why we need to make an immediate or short-term change. Therefore, I will close this topic, as it is no longer relevant since I removed the content.

```
can you please help me respond to each and every github comment left on my markdown document.

I will provide the document here, and then we will address each point as we go.

…

I'll provide the comment, and then which line it was left on and then we will address that point in the markdown and then provide rationale/reasoning in the github comment itself:

I'll provide my subjective input as well at the end of each so that you can know how to make the change:

> <line>

<comment>

- <input>

….

here is the first one:

> ### 3. GitOps Workflow Overview

> #### 3.1. Deployment Repository, Kustomize, Argo CD, and Express Operator Interaction

The only remaining component worth considering is the Argo CD server, which periodically syncs the Argo CD application without any manual intervention. This functionality is an integral part of the service. While this automatic syncing is beneficial for deployment—regardless of the specific tools used—it’s important to note that if you need to force a sync, the Argo CD API allows you to do so. This feature can be particularly useful when initiating operations, such as deployments or resource adjustments, that require immediate syncing rather than waiting for the next scheduled sync. You don't need a complex method to demonstrate this; simply showing that the Argo CD application syncs periodically and that a forced sync is possible from an external tool will suffice.
```

# Enhanced \_crs_exist Method to Properly Filter Sandbox Backends

## Problem

The `_crs_exist` method in the `ExpressClusterTopology` class was failing to correctly identify and filter out sandbox backends, particularly in Cloud environments. This caused issues with the DigitalProvisionAccount task initialization and led to inconsistent behavior between Cloud and Colos environments.

## Root Cause

The method did not account for different naming conventions and environment variables used to identify sandbox backends in Cloud vs. Colos environments. It also threw exceptions for unexpected configurations, which could interrupt the provisioning process unnecessarily.

## Solution

1. Modified the `_crs_exist` method to check for nodes that start with "{instance}-".
2. Implemented checks for sandbox-specific environment variables:
    - express_sla_tag: sbx
    - FABRIC_SERVICE_ENVIRONMENT: sbx
3. Filtered out any backends identified as sandboxes based on these environment variables.
4. Replaced the exception with a warning log for unexpected configurations, allowing the process to continue.

This change allows the code to run consistently in both Cloud and Colos environments by correctly identifying and filtering out sandbox backends.

## How to Test

Run the unit test:

```
python -m unittest discover -v -s tests/unit
```

## Expected Behavior

### Before the Change

The method would raise an exception when encountering multiple backends, including sandboxes. This would cause the provisioning process to fail.

Real-life example (Cloud - jed1):

```
kubectl get backends -n tenant-124672-prod --context jed1
NAME             AGE
roshn-be         77d
roshn-roshn-be   7d6h
```

In this case, the method would fail due to the presence of both `roshn-be` and `roshn-roshn-be`.

### After the Change

The method now correctly identifies the production backend and ignores the sandbox backend. It returns `True` if there's exactly one production backend and at least one frontend, `False` otherwise.

Using the same example:

```
kubectl get backends -n tenant-124672-prod --context jed1
NAME             AGE
roshn-be         77d
roshn-roshn-be   7d6h
```

The method will now return `True`, considering only `roshn-be` as the production backend and ignoring `roshn-roshn-be` as a sandbox.

This behavior is consistent across both Cloud and Colos environments:

Colos example (sc4):

```
kubectl get backends -n tenant-101044-prod --context sc4
NAME                                          AGE
...
be-testing-login5-thermofisher-6bf329f8       10d
be-testing2-login5-fourseasons-50574568       11d
be-uat-login5-fourseasons-83c39226            10d
login5-be                                     4d15h
```

In this case, the method will identify `login5-be` as the production backend and ignore all others with the `be-` prefix as potential sandboxes.

## Next Steps

1. Consider implementing a standardized labeling system for backends across all environments to simplify future identification and filtering.

---

I'm going to get demodcrtest2 /demodcrtest3 working tomorrow morning before standup, just need to:

- delete all resources in the namespace
- apply resources

---

I want to consider the feedback that Augusta has provided regarding what has been said so far. However, I approach this with some hesitation because I’m unsure about the implications of her comments. As I update you based on her feedback, could you also provide me with a list of relevant questions to ask her in the GitHub comments? This will help me dig deeper into what her suggestions mean for making changes to the express operator.

For example, if I want to make a minor change to a single cluster in the express operator, such as adding a feature to the front end, I would like to understand how that change is picked up exactly. Specifically, how does the change get picked up and when does it take effect within the data center? Additionally, how do controller revisions factor into this type of change in a controlled way? Are you able to leverage the controller revisions in such a way that we can update one express cluster at a time?

Regarding your second point, I’m not as concerned about making changes to multiple data centers at once. My assumption is that it would not be rolled out this way, because that seems like it would be dangerous (admittedly, we are also prone to this right now with the less than ideal way that we treat helm chart versioning). I digress, My primary focus is on changes to a single data center and how those changes affect all clusters. If a change needs to be reverted across the entire data center, I want to understand exactly what level of control over the mechanism that decides which express cluster (s) get those changes

I also seek clarity on how changes are applied to the data center. Are changes applied immediately, if not, what triggers the change? How can we determine which version of the operator has the latest changes? How do we know which clusters have already gotten the latest those changes and which have not? Are some types of changes enacted immediately while others take effect later or regardless of the type of change, does the reconciliation process update all resources in the same way?

What I am getting at is that want to understand how the control mechanism works. For comparison, with a Helm chart, we can test updates on a single cluster on a single branch within the deployment repo, if successful, update the helm chart version (which once again admittedly the process that we have in place right now for doing this with helm chart versions could be drastically improved, by externalizing the helm chart definition but I digress again) roll out the version update to other clusters at our discretion. For example, we can track which clusters are on which version of the chart using labels only.

To provide some context, I want to know how this process compares to my understanding of Helm chart versions and their management. Regardless of the roles and responsibilities we establish for express, there should be a solid understanding of both layers, depending on the changes need to be made. I’m interested in how changes are rolled out across all Kubernetes clusters and express clusters on all layers

I realize this is a lengthy message, but I want to know which of these topics are important and how we can frame them into actionable changes. Additionally, I would appreciate suggestions for more questions to ask her in the GitHub thread.

---



```
helm template foo helm_quick_cashing_dynamic_sync --values overlays/den/demodcrtest2/values.yaml | kubectl delete -f - --context den
```

```
kubectl get all -n tenant-124628-prod --context den
Warning: kubevirt.io/v1 VirtualMachineInstancePresets is now deprecated and will be removed in v2.
NAME                                                    READY   STATUS      RESTARTS   AGE
pod/den-prod-db-demodcrtest2-0                          1/1     Running     0          120d
pod/den-prod-db-demodcrtest2-monitor-0                  1/1     Running     0          110d
pod/den-prod-db-demodcrtest2-pg-backup-28808650-2wsmt   0/1     Completed   0          167m
pod/den-prod-db-demodcrtest2-pg-backup-28808710-v6k7d   0/1     Completed   0          107m
pod/den-prod-db-demodcrtest2-pg-backup-28808770-fj6jp   0/1     Completed   0          47m

NAME                                                TYPE           CLUSTER-IP   EXTERNAL-IP                                    PORT(S)    AGE
service/demodcrtest2-custom-page-ingress-403-prod   ExternalName   <none>       custom-page-ingress-403-prod.shared-services   8080/TCP   38h
service/demodcrtest2-custom-page-ingress-404-prod   ExternalName   <none>       custom-page-ingress-404-prod.shared-services   8080/TCP   38h
service/den-prod-db-demodcrtest2-metrics            ClusterIP      None         <none>                                         9187/TCP   121d

NAME                                                READY   AGE
statefulset.apps/den-prod-db-demodcrtest2           1/1     121d
statefulset.apps/den-prod-db-demodcrtest2-monitor   1/1     121d

NAME                                               SCHEDULE     SUSPEND   ACTIVE   LAST SCHEDULE   AGE
cronjob.batch/den-prod-db-demodcrtest2-pg-backup   10 * * * *   False     0        48m             121d

NAME                                                    COMPLETIONS   DURATION   AGE
job.batch/den-prod-db-demodcrtest2-pg-backup-28808650   1/1           10s        168m
job.batch/den-prod-db-demodcrtest2-pg-backup-28808710   1/1           10s        108m
job.batch/den-prod-db-demodcrtest2-pg-backup-28808770   1/1           11s        48m
job.batch/den-prod-db-demodcrtest2-setup                1/1           47s        121d
```



```
diff --git a/apps/express/output.yaml b/apps/express/output.yaml
--- a/apps/express/output.yaml
+++ b/apps/express/output.yaml
@@ -1289,9 +1289,9 @@
     sharedStorages:
       - mountpoint: /express/workdir/shared
-        path: vol/sharedworkdir_den/demodcrtest2
+        path: /vol/sharedworkdir_den/demodcrtest2
         server: 10.207.12.25
       - mountpoint: /express/workdir/shared/feed-file-store
-        path: vol/feedfile_vol
+        path: /vol/feedfile_vol
         server: 10.207.12.25
     terminationGracePeriodSeconds: 60
     readinessProbe:
```
