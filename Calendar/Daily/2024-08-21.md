---
up: "[[2024-W34]]"
description: ""
publish: false
starred: false
status: ""
type: note
tags:
  - periodic/daily
cssclasses:
  - "cards"
  - "cards-cols-1"
obsidianUIMode: source
obsidianEditingMode: live
template: "[[Daily]]"
created: 20240526134105
modified: 20240822090827
aliases:
  - Wednesday - August 21st 2024
linter-yaml-title-alias: Wednesday - August 21st 2024
title: Wednesday - August 21st 2024
id: 10
week: "[[2024-W34]]"
yearly: "[[2024]]"
quarterly: "[[2024-Q3]]"
monthly: "[[2024-08]]"
daily: "[[2024-08-21]]"
month: "August"
weekday: Wednesday
---

# Wednesday - August 21st 2024

Actions

New admin commands

Here is the updated documentation that reflects the requested changes:

---

```
could you help me setup a few tools in my helm environment?

I would like to limit the scope of my usecases to local testing for now, but ensure that everything we do would be able to be easily automated /triggered by a pull request if need be

Ideally, we should be able to easily version control the configuration of what we are talking about. Ideally, there are minimal dependencies.

I would like to you to help document usage of these tools as well and include examples on how to use these things.

there is some existing documentation and the project knowledge as well as scenarios (specifically the upgrade scenarios that I am trying to better equip the chart to handle)

also, however we do this should have in mind that our current tooling consists of using helm charts in a certain way, we only leverage the templating capabilities and then argocd applies the result. we do not use any of the package manager functionality of helm.

We are also managing a chart which is handling a multi-tenant configuration. all of the tenants in this case are production clusters. For now, we should model the tooling around this flow because it is what is currently needed. but make sure that however we set things up can be easily extended if we wanted to adjust the way that we use it.

let me describe my pain points, and what tools I think could help with these. I would like your help in implementing these tools to address my pain points in a clean and useful way.

we should work on the implementation of these tools one at a time.

…

I have a few things I would like to setup in this repo that will help me more easily maintain the helm chart from now on.

for context, all I do now is basically:

APPLICATION="express"
CHART_VERSION="helm_1.0.0"
DC="den"
INSTANCE="varsamisktest"

helm template --debug $INSTANCE ./$CHART_VERSION \
  --values ./$CHART_VERSION/values.yaml \
  --values ./overlays/common-general-values.yaml \
  --values ./overlays/common-express-values.yaml \
  --values ./overlays/common-alldc-values.yaml \
  --values ./overlays/den/varsamisktest/values.yaml > rendered_manifest.yaml

this is too many values to have to supply in different places. and some of the paths are specific to a given overlay/tenant. It's tedious to switch between different tenants and kubectl apply to the right kubernetes context (which is the dc "den" in this case or "yul1"

…
name: varsamisktest-be
copyCachesFrom: null
provisioningPrerequisites: null
upgradePrerequisites:
  - conditionStatus: "True"
    expressNode: varsamisktest-fe2
    expressVersion: "express-e689.160"
    kind: Frontend
    podConditionType: Ready
name: varsamisktest-fe1
copyCachesFrom: null
provisioningPrerequisites:
  - conditionStatus: "True"
    expressNode: varsamisktest-be
    expressVersion: "express-e689.161"
    kind: Backend
    podConditionType: Ready
upgradePrerequisites: null
name: varsamisktest-fe2
copyCachesFrom: fe1
provisioningPrerequisites:
  - conditionStatus: "True"
    expressNode: varsamisktest-fe1
    expressVersion: "express-e689.160"
    kind: Frontend
    podConditionType: Ready
upgradePrerequisites:
  - conditionStatus: "True"
    expressNode: varsamisktest-fe1
    expressVersion: "express-e689.160"
    kind: Frontend
    podConditionType: Ready
name: varsamisktest-fe3
copyCachesFrom: fe2
provisioningPrerequisites:
  - conditionStatus: "True"
    expressNode: varsamisktest-fe2
    expressVersion: "express-e689.160"
    kind: Frontend
    podConditionType: Ready
upgradePrerequisites:
  - conditionStatus: "True"
    expressNode: varsamisktest-be
    expressVersion: "express-e689.161"
    kind: Backend
    podConditionType: Ready
name: varsamisktest-fe4
copyCachesFrom: fe3
provisioningPrerequisites:
  - conditionStatus: "True"
    expressNode: varsamisktest-fe3
    expressVersion: "express-e689.160"
    kind: Frontend
    podConditionType: Ready
upgradePrerequisites:
  - conditionStatus: "True"
    expressNode: varsamisktest-fe3
    expressVersion: "express-e689.160"
    kind: Frontend
    podConditionType: Ready
…

and then i look at the diff of the output manifset and then apply it directly to a given context to monitor the progress of the changes and make sure it works.

this includes the improving and make easier my process/workflow of testing the helm chart locally as I am adding/modifying it (helmfile + helm diff) but also from an integration testing point of view as well. Because the custom kubernetes resource I am passing this manifest too too is what I am monitoring the behavior of the how the operator takes my inputs

it's hard to tell as I am changing things what is going to change before I change it.

I need to know this so that I can make sure I am safe to commit the change after verifying the output result is what I would expect

I often use kubectl apply -f on the manifest in between changes

I have a lot of different tenants values files (which all point to/share different common/global values. I would like to simplify the command I use to run this for a given tenant (store reference to these paths for a specific tenant)

I have several helm chart versions that are currently being stored in my local repository (I cannot change this right now, but it is ok but argocd just points at then). but my point is, I need an easy way for these test clusters to be able to

^ I just want to have an easy workflow for tying all of these things together to improve the overall experience of updating/maintaining the chart. Switch between versions (ex helm_1.0.0 to another helm_1.0.1) version easily without distrupting my workflow. same with tenants, I need to be able easily switch between these without fuddling too much in my editor, it should be more simple to specify the inputs for a given tenant while I am testing it without having so much in a single command.

…

so next problem is that, I need to actually start unit testing my helm chart because I have a particular problem that is easy to miss that is very problematic.

The express operator is expecting a unique deploymentRevision value.Right now it is created by a helm chart calculation that does not consider the whole spec sometimes because when I add/change parameters to the helm chart, sometimes I forget some parameters and then I forget to notice that the deploymentRevision did not change after I rendered the manifest and if I apply it then basically the operator does not process this properly.

I need to to have something to actually test my chart with after making changes. so for example, the way that I aggregate all of the node parameters -> deployment revision is very sensitive in express.yaml (I need to make it better and document the usage of it better but that is besides the point)

I would like to try introducing helm unittest for this purpose. my first usecase for a test is specifically to quickly test each individual/combination of existing parameter to ensure that the deploymentRevision changes along with it. (or any unique deployment revision is updated along with it). This will help me feel better about how it is currently setup than I do now.

generally

…

so to sum it up

I would like to try leveraging helmfile + helm diff for making the workflow easier

Then I would like to try helm unit test for the issue I describd above.

then ideally, we can introduce a makefile as well that can be easily called any of these types of tools others to quickly call a series of these things to make it easier.

I want to revise existing documentation and even introduce new documentation if it is needed that will make the process of installing/using these tools easier than it is if you do not. But we should also provide the good ol fashioned helm template command equivalents in case the user does not want to actually use these dependencies to their benefit. It might also actually help them understand what the tools are actually doing so that they trust it more.

any other tools you think I might find useful for this purpose, please feel free to recommend as well if it fits the bill.

Before we proceed, can you understand my requirements and read them back to me to make sure you understand it so we can create a markdown checklist of what to start working on.

we should work on one at at time and we will iterate/test/try things and then move forward
```

# Helm Chart Maintenance Improvement Checklist

## 1. Implement Helmfile and Helm Diff

- [ ] Set up Helmfile configuration
- [ ] Integrate Helm Diff plugin
- [ ] Create Helmfile templates for different tenants
- [ ] Document usage and benefits of Helmfile + Helm Diff

## 2. Implement Helm Unit Tests

- [ ] Set up Helm Unit Test framework
- [ ] Create tests for `deploymentRevision` calculation
- [ ] Implement tests for various parameter combinations
- [ ] Document usage of Helm Unit Tests

## 3. Create Makefile

- [ ] Define targets for common tasks (e.g., lint, test, diff)
- [ ] Include targets for switching between chart versions
- [ ] Add targets for working with different tenants
- [ ] Document Makefile usage

## 4. Update Documentation

- [ ] Revise existing documentation to reflect new tools
- [ ] Create new documentation for tool installation and usage
- [ ] Provide examples of both new tooling and traditional Helm commands
- [ ] Document best practices for maintaining the multi-tenant chart

## 5. Workflow Optimization

- [ ] Streamline process for switching between tenants
- [ ] Improve method for changing chart versions
- [ ] Simplify command inputs for specific tenants

## 6. Additional Tools (if needed)

- [ ] Research and recommend any additional tools that may be beneficial
- [ ] Implement and document any additional tools
