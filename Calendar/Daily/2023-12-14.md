---
id: 9
up: "[[2023-W50]]"
description: ""
publish: false
starred: false
status: ""
type: note
tags:
  - periodic/daily
cssclasses:
  - "cards"
  - "cards-cols-1"
obsidianUIMode: source
obsidianEditingMode: live
template: "[[Daily]]"
created: 20231214000100
modified: 20231215152632
aliases:
  - Thursday - December 14th 2023
linter-yaml-title-alias: Thursday - December 14th 2023
title: Thursday - December 14th 2023
week: "[[2023-W50]]"
yearly: "[[2023]]"
quarterly: "[[2023-Q4]]"
monthly: "[[2023-12]]"
daily: "[[2023-12-14]]"
month: "December"
weekday: Thursday
---

# Thursday - December 14th 2023

## Tasks

%% TCT_TEMPLATED_START 2023-12-14 00:00 %%

%% TCT_TEMPLATED_END 2023-12-14 23:59 %%
- ? Did these tasks align to your Goals?

# Rollover

# Daily Notes



What you're proposing is more like choose the OCI model, go everywhere with that, and then in a second phase, lift and make that shorter. Look, as I said, this is not a proposal, right? That's exactly what, it's a guideline for discussion. And what you're saying now is a very valid question. And that's what I try to capture also with Express Operator and define what is a deployment. My question is, should we invest in something that already exists or to something new, as you're saying? And I'm fully like to go with each of those, like I'm not biased towards one or the other. I want us to understand that this is what we're doing and we put all the investment there because for sure we're going to dedicate man hours and effort to do something and solve this. If it's like based on existing tools or like create something new, it's up to us to decide. Mm-hmm. Yeah. If we want to standardize first based on what we have right now.


---


We're trying to do GitOps without even knowing, but without having the tools. And that's why they came up with this XML sheet that they keep the definitions of things and then like they translate it to infrastructure. But today we have like standardized tools to do that. And so we should move and we already have a working example. So it's like, it doesn't make sense to still keep on doing what we used to do because of necessity. There are a lot of, a bunch of different historical reasons that why we did things the way we actually did. It was, it was tailored to Aurora. Yeah. Yeah. That's what I also understand. And then when it, I think it's time to, okay, nowadays we are all agreed that we are running coordinates. We are all agree that we want to have declarative things instead of having imperative things because you don't have reconciliation or imperative things. And hence you have a bunch of different issues in production that we are having with the product right now. So that's one thing. The other thing is basically we have the tools. So we need, essentially we are all, I think we are all agree. Yes. As Agustina said, have a word if not, but the thing is we want to go to the declarative things using Argo CD and deploying in an OCI-ish mode. Then we need, if we have the agreement, it's fantastic because we are all on the same page. And then we need to deep dive a little bit on that, what that means. We have different options there. We have the Argo CD, which is the thing that we are going to declare there. Then we can use, I don't know, I will say things on the air, just wanted to give my vision here. Yeah. Either way we go defining something in Argo CD and then letting the operator orchestrate the whole circuits around that. That's one thing. The other thing is basically delegate that to Argo CD and use, I don't know, waves to orchestrate the different steps. That's another option. Use a workflow, Argo workflow, that's a third option. I don't know. We have several options to use the standard tools that we already have to deploy things in a more quantitative way and declarative way. Okay. But I have another question, which comes from this, like, do we keep the CRDs or no? That's the thing that we need to decide here. That's an entire, yeah. But it is a key question because if we decide to keep them, then it means that we need to invest in the orchestrator, which is like goes hand by hand with it. Right? If I can have the share, I want to know about some of that in, in, yeah, let's, sorry, yeah, I wanted to, I was going to say. Sorry for that. But we assume that we are going to go with the OCI-ish model and because that we have prepared a comparison table of circuits to do this. That's also because we, like the declarativeness of the solution is a requirement, the solution has to be declarative. Yeah, exactly. Because everything is declarative. So. But, and one more thing, though, to point out that because you mentioned there, we need to provision the same way and we don't need the workflows or whatever, or data tickets to be open. But there are, you need to take under consideration that when we are provisioning some, a cluster, there are other things outside the Kubernetes infrastructure that needs to happen. So we need to create DNS records. We need to talk to Express Admin. We need to do a bunch of things, put internal DNS, external DNS and so on. So these things still need to happen somehow. Yeah, yeah. And for this, we will still keep the workflow, but I agree that there are even other ways that can be done in an operator. Sorry? Yeah, both solutions that we have here, that can be done inside of a workflow, can be done inside of an operator. We can also try to turn other, or model other parts of the infrastructure in Kubernetes, like DNS records. You could have a resource defining a DNS record and then a component, like an operator just for DNS records, reconciling that resource and automatically running that call to Das or anything. But that's kind of out of our scope. That's more like network services or a few, I think, but those things could also be modeled in the Kubernetes cluster and we could, in that way, we make them declarative too, but that's nice to have. So what we are trying to simplify and standardize the MSC production stack, deprecate layers with overlapping responsibilities. That's what I mentioned when I said, okay, we can take one of the solutions or flavors that we have right now, but we still, at some point, have to address this and maybe flatten the stack because a lot of tools in there overlap and if we can leverage Kubernetes native and open source alternatives, that is great. Why? Sorry, if you can go to the previous one, the ones that are overlapping, you mean like, as we said, like ProDeployer with the cluster config repository and what else? So ProDeployer has orchestration, an operator can do the orchestration like it is doing it in OCI and I understand, side note, that that logic has bugs, but we haven't prioritized that fix because we don't know if we are going to keep that orchestration logic, but that is an overlap. Another overlap is the Argo workflows creating other Kubernetes resources like namespaces for the MSC tenant and other stuff. That is what the operator does, the operator translates from a primary resource, which is the backend and the frontend custom definitions that we created to secondary resources like pods, network policies, disruption budgets, services. We could also add the namespace as a secondary resource and create it inside the operator. So those are overlaps that are needed. And there is also the Helm chart. The Helm chart also creates resources that could be secondary resources within the operator. Ok, and a question, because I know, for example, like in this…

---


So Aurora, to migrate to Kubernetes fast, we just made some changes and made it work. But it's a bit weird. It lacks maintainers, has several layers with no clear responsibilities, is what we covered. And it's different depending on the environment, is what you mentioned about different flavors. Requirements, we have the things that we have to support in this diagram that Fer showed. For us, declarative implementation is like a must. We have to go declarative. And then here, I just copied what I saw in your document of high-level requirements. I think those are great. And we maybe have to develop this a bit more, but not a lot. As Armand said, we don't want to go into super long conversations with Kubernetes management. Not in this first iteration. Yeah, yeah, yeah. Make it work. And then with the things working, we can have some shoulders to start having those conversations. Yeah, because that is also a big question for me, because I know that a lot of teams started using this so-called Kafka Deployer. And I do know that for QA environments, even for MSC clusters, they do use Grafiki Deployer. And they were pushing other teams to use it. So it was pushed as a standard. And I don't know if that's the answer for the MSC case or not. We need a tool that people can have visibility over what is being deployed, what is the state of the things that are being deployed, and so on. But yeah, as you say, it's like a second iteration. Let's focus on fixing.


---


Source, the only thing you can do is mark the express node as up or down with this field that we have, that is a state up, and even set it to true or false to. Which is using protiplier to manipulate, right? You can use it directly. But yeah, protiplier is wrapping that. And you can update that through the protiplier, but you can also edit that through QCPM. OK. And we would have to implement the operational steps in the express operator. So the operator already catches edits in the custom resource, and that triggers a reconcile function. We would have to check this operational fields. And if we see that, I don't know, the field copy caches is in true, the operator will have to run the copy caches function. And we would have to implement that function and implement that run. So that's the difference. Well, here is just designing operational fields and implementing those operations. Here is developing the scripts for everything, the entire operation, and the operation. And we would have to push the YAML definitions to the ROCD repo. That is also code that we have to have. And there's also a step to create the workflow templates for provisioning and every other operation that we need. So provision would look like, so in the Argo workflows world, execute the workflow with the right parameters to provision, I don't know, target NEC. Execute the provisioning workload with the parameters that target needs. And the workflow would push the stateful sets, network policies, ingress, service, all the resources that you need to set up an NEC cluster to the ROCD repo. Why? Because we need it to be declarative and we need it to have a desired state. So we needed to have this step to push everything we create to the ROCD repo. In the Express Operator world, we In the Express Operator world, it would be just push the custom resource representing that NEC cluster or all the Express nodes in that NEC cluster to the ROCD repo. The Express Operator would see that creation and translate the custom resource to pods, network policies, ingress, services creation, every other secondary resource that we need for an NEC cluster. And the results would be the same in both, an NEC running in Kubernetes. I put a note here because I know that you guys like Helm. In both alternatives, we can use Helm or customize to ease the management of all the YAMLs that we would have. We would be interfacing with a lot more YAMLs here in this solution, as you can see, because in this world, we don't have a custom resource to wrap all these and to interface with. So we would be interfacing with the stateful set, network policies, ingress. And here in this world, we would be interfacing with the pod.


---


today is happening in the provisioning ng repository because we do have scripts but it's like kind of said we're sharing functionality because we have a crazy inheritance tree and that's a different story but what gives you the this gives you the ability is like that you can version it you can run a unit tests you can run integration tests and so on and you can make it more reliable and say this way so that's why i'm not a big fan of like putting it in atlas deployment i haven't seen the trouble that you that you are saying and if you could could you share maybe one example so i can see what it's all about because i haven't seen it like i thought it's all manifests that i didn't know that people are defining yeah it's basically it's basically a long manifest uh with the scripts but i uh but i believe you can instead of having the scripts exposed in the manifest you can have images you you can have it pointed to images and have the code elsewhere we can we can edit this it was just to uh to say that there is a difference here is uh in express operator we have a source in a separate repo that is built we have an artifact a single artifact with the code to provision and operate uh mec it is less flexible because a new version has to be released if mec provisioning and operation uh changes but i that is not the case if you have the scripts exposed in atlas deployment but it will be the case if you have the steps of the workflow in separate repos that are built and and version and we found this this option less risky because the artifact since there is an artifact we can follow a release process and basically test it and validate it and have some time to harden it in a pre-prod environment and yeah because this is actually one of the other points that was visible in our document it's or became more visible and it was that everybody's afraid of the operator because of the of its blast radius and my response to that is like okay why the the problem is the blast radius and like because i really believe that if you have proper unit testing integration testing end-to-end testing and then you have stages you can be pretty sure that a small change cannot bring down clusters let's say or you can catch it very very early yeah think of the blast radius in within the the operator it's basically in the past it


---


Who do you think can give us this answer? Because I can't. Maybe we don't have people anymore that can give us that answer. But maybe what we can do to find this out is just do a PLC. Try to run an MEC cluster with that flavor in Colo and see where it breaks. Yeah. Maybe we can start with that. OK, that's one. OK, good. So we do have an action item. I also make a note that we'll give you a demo of what provisioning NG is for. Because it started as a way to provision new accounts for the MEC clusters. But it turned out to be an automation framework. Because I know that the database teams are using it for migrating databases. We do provisioning of other applications, which are like go to the API and create users and stuff like that. So it's kind of more broader now, the use case. It's not only that. Or they use it for executing groovy scripts in all MEC clusters and things like that. So it's kind of more like an automation framework at the moment. That's nice. If we could include the provisioning of databases in this solution, too, it would be amazing. Because the current solution is also something that was tailored to Aurora. And it's not working very well in Kubernetes. DBs is out of the scope of this. We didn't consider it. But if we could include it, that would be amazing. I would love to do that. Because the current way that we use PG scripts and run a job, it's just, it is, even with automation, the most ridiculous thing. Yeah, don't get excited. Because I think that's how the migrations are happening. We're still using some images provided by the DBAs. But if you look in OCI. I was present in the Target migration, the Target DB migration today. And they are using PG scripts. But it doesn't mean that we can make it part of this list. Like in OCI, they are provisioning databases via the deployment repo and Helm chart. Or maybe not a Helm chart. I don't know. But the significance is that it's possible. And that we should, if we can, account for that in this as well. But something I also wanted to mention is that, OK, these huge migration efforts that we have from going from one deployment method to another are pretty, I mean, it's a lot of work. And one thing I hope that we are able to do in this process is come up with a way to be able to do this work behind the scenes without having to do this massive migration. So that in the meantime, L1 or whoever doesn't have to know, oh, we're using prod deployer for this express cluster. Oh, we're using OCI for this. Oh, we're using this. Oh, we're using that. If through leveraging this automation framework, we can make that decision not have to be made by them. So that based on wherever it is deployed, that it can be triggered in that way. So having gone through the DC migration effort, it's so having to just sit there and migrate everything. I hope that we can somehow avoid having to do that in this process of migrating to whatever the new and improved deployment method is. I hope that we can do that. Let's do baby steps. And have you read the Project Unicorn? Yeah. Yeah, it sounds like you're organizing a rebellion here. Anyway, OK. What is that? Have you heard about Project Phoenix and Project Unicorn books? Oh, Project Phoenix I read. Yeah, so he has a second one, second one which is called Project Unicorn. It's kind of taking place in the same timeline, but different story. It's nice. I'm reading it right now. Oh, I didn't know about that one. Yeah, I will look it up. OK, let's put a full stop. It was a great discussion. I think we're great.


---


OTHERS: Yeah.

OTHERS: Thanks a lot.

OTHERS: I'll be him.

OTHERS: Just joining.

OTHERS: And Luis told me like you guys prepared also something like for today because we also prepared like a document.

OTHERS: Yeah, we did prepare something to showcase today and yeah, let's wait for Luis so we can.

OTHERS: Start the meeting and we can just be cool.

OTHERS: Who offers.

OTHERS: Yeah, ours, ours is just like.

OTHERS: Two slides to buy the conversation, not a proposal or anything.

OTHERS: I don't know what's.

OTHERS: I don't know if yours is a proposal or.

OTHERS: It is no, it is like so, so it's kind of the same, but one to the user different format.

OTHERS: If you don't mind to try something new.

OTHERS: And we can we can we can see that also.

YOU: You're currently.

OTHERS: because maybe we did cover, I don't know, I wanted to thank you beforehand so I could see a bit what you had but I wanted to try something different which I know it's effective like it's not like a presentation I will share with you knowing this start maybe this document and I would ask all of us let's say to take five or ten minutes let's maybe say ten it's a sort it's a sort of document like two two and a half pages like I would like you to retro and as you go put your comments now it's it's again it's like just a guideline it's not a proposal at the moment but hopefully that will lead us to some kind of more of a design look So let's take like until 1510 to through and like put your comments as you go and like I will say come and see you wouldn't need more time.

OTHERS: Is that okay?

YOU: "Well, that is the way through the new season." "I don't like it because it's so awkward." "Yeah.

OTHERS: Okay.

OTHERS: Thank you.

YOU: It works." Do you not care?

YOU: I let him in.

YOU: Do you want to see me the other day?

YOU: I don't care.

YOU: I'm the one that's just under control.

YOU: you're the one that just Arabianist.

YOU: I don't care!

YOU: I thought you were the last one to come here.

YOU: I don't care.

YOU: I wasn't conscious of you.

YOU: I was trying to get you back.

YOU: I told you, you didn't know what to do!

YOU: I was jealous of you.

OTHERS: How is it looking like in a little time?

OTHERS: I'm pretty much reading the whole argument.

OTHERS: I'm just studying some comments around things.

OTHERS: Thank you.

OTHERS: Okay, I want to move forward on this.

OTHERS: Thank you, Raj, for the document that you guys elaborated here.

OTHERS: Essentially, what I'm seeing here is there are a couple of things that we need to elaborate a little bit and discuss further more.

OTHERS: Such things, for example, I just left the comments there.

OTHERS: I know you guys left a bunch of other comments.

OTHERS: But for example, one thing that came up here, it's basically the GovCloud deployment.

OTHERS: It's yet another flaky word of things around me.

OTHERS: We are using some sort of thing, pro deployer-like, I would say.

OTHERS: But instead of defining the macros or maybe the cluster definitions within XML files, we are using Java files instead.

OTHERS: It's kind of like pro deployer, but it's own version.

OTHERS: Yeah, exactly.

OTHERS: But it's still running on Kubernetes, right?

OTHERS: So far, right?

OTHERS: Say again, sorry, please.

OTHERS: Is that already done?

OTHERS: I thought that they were working with that.

OTHERS: This is a migration?

OTHERS: Yeah, it's, it's, we have a corner is running goftal.

OTHERS: But the thing is, all the clusters right now in goftal are running in our meshes.

OTHERS: Right, the migration is not sorted.

OTHERS: Okay, okay.

OTHERS: So it's like once the business yet.

OTHERS: But that's part of the issue.

OTHERS: And that's why we started this conversation because we, the migration in the corner is migration in goftal is blocked.

OTHERS: We don't have a solution to deploy MEC in go cloud.

OTHERS: And part of this with because we don't have a way to deploy MEC in go cloud.

OTHERS: Because essentially the deployer that we have currently having in goftal, it's tight just to the our the order.

OTHERS: the piece of hope that that interacts with with the corner is it's not developed yet.

OTHERS: Okay, that's so that's we need the component.

OTHERS: Right.

OTHERS: Okay, because I look from my from my understanding at least up to now it's like that we yes, that is pro deployer.

OTHERS: But we have an example the cloud solution like the OCI solution, which is like not using a pro deployer at all from a then stand.

OTHERS: We're only and that's why we don't have a pro deployer.

OTHERS: Yeah, so for me or for our team, we need to get closer to this in all of the flavors.

OTHERS: And I hope we all agree on this.

OTHERS: Yeah, I think we are really.

OTHERS: Thank you very much Yeah, we want to agree on that.

OTHERS: We need to make sure that we are doing the same thing across all the different environments and as vanilla as possible.

OTHERS: Exactly.

OTHERS: Okay.

OTHERS: That's the scope of this.

OTHERS: Even though we have either an operator or not basically extending the Kubernetes API to have an operator, it will depend on the use case that we currently have.

OTHERS: But yeah, that's agreement.

OTHERS: We need to do it in the same way in every environment and we need to do it in as vanilla as possible.

OTHERS: Yeah, okay.

OTHERS: Sorry, Evan, can you are you taking notes already?

OTHERS: Or can you take notes?

YOU: some of that of Well, Yeah, I am.

YOU: I'm taking a few here.

OTHERS: Thanks.

YOU: Just love you like I'm like.

OTHERS: We can also record the conversation if you want.

OTHERS: Oh, we need it.

OTHERS: Yeah, sorry.

OTHERS: Yeah.

OTHERS: Because I promised also, thanks.

OTHERS: Thanks Augustina.

OTHERS: No, that's okay.

OTHERS: No, it's recording recording in progress.

OTHERS: Okay.

OTHERS: The thing here is basically there are a couple of conversations.

OTHERS: I put some notes basically on, for example, in the operational part of the MEC clusters, there are a lot of complexity there about the operation of the cluster because we have a lot of requirements for release management, for example.

OTHERS: I will give a couple of examples.

OTHERS: You need to deploy in a specific version, in a specific front end, and make it dark, which means basically do not serve traffic outside.

OTHERS: Because there is something, I don't know.

OTHERS: That's a weird thing that could happen.

OTHERS: The thing here is that being said, there are conversations that we need to have with release management to make sure that we can standardize the most of the operation.

OTHERS: for the express casters.

YOU: and then the next slide is the last slide.

OTHERS: But that conversation, it's another battle.

OTHERS: So you're saying that there is a requirement of offline deployments when it comes to GovCloud environments.

OTHERS: That's just an example.

OTHERS: There are a lot of parts.

OTHERS: Honestly, I don't know where every single requirement.

OTHERS: Yeah, yeah.

OTHERS: So this is exactly the point.

OTHERS: I, from this meeting, what we're looking for, what we want to take out is like, first of all, some basic common goals that we will set, that's what we want to get to.

OTHERS: That's what we want to be in, like, I don't know, six months from now, one year from now, it depends.

OTHERS: And the other things like gather requirements, as you're saying, like, this is one requirement.

OTHERS: We realize that it's only our team and yours right now on this call.

OTHERS: But in order for us to …

OTHERS: come up with a better, more technical proposal.

OTHERS: It's like we need to go through this and understand it's other, be on the same page and like come up with some more technical document and not this.

OTHERS: What I'm trying to say here is basically we need to, I don't think to in order for the sake of the process, we need to set that common line here, which is basically instead of gather the requirements, because gather requirements in this case, there could be thousands.

OTHERS: I mean, it could be an idea.

OTHERS: So if you go to a release management and say, hey, can you bring me out the requirements that you have for class of deployments, they can, every day, they can add a new one.

OTHERS: So what we need to do, I do think what we need to do here is basically, And use the look.

OTHERS: I recommend that SIGL, SIOLA, made in the past, that has all the different requirements that we are doing right now, because they are basically using it actively.

OTHERS: You know, these floats are diagram that he was showing the other time.

OTHERS: I can share the diagram.

OTHERS: Yes, so.

OTHERS: And we need to set that as a base, right?

OTHERS: Let me one second.

OTHERS: Okay.

OTHERS: Yeah, but there I believe we used to have some boxes as well, right?

OTHERS: And we are.

OTHERS: No, no, no, no, no, no.

OTHERS: In this argument, we don't have some boxes.

OTHERS: It's a scope just to make deployments.

OTHERS: Okay, which is this one?

OTHERS: Yeah, this one.

OTHERS: Yeah, okay.

OTHERS: It's just a scope for production deployments.

OTHERS: I think it's we are going to tackle this this part, right, the production deployments.

OTHERS: We don't we don't want so far to go to some boxes, etc.

OTHERS: Because in we are some other fog conversations, negotiations, I don't know a lot of things.

OTHERS: So I want you to ask to focus in here and said that this is basically the requirements.

OTHERS: These are the requirements.

OTHERS: Here you you have all the different things or actions or operations that you make you should be doing with this tool that we are trying to elaborate.

OTHERS: And that they do support right?

OTHERS: Yeah, hold on because like this is this is this showing like what we're doing right now for colors and what we're doing for OCI and what we're doing eventually for gold cloud.

OTHERS: This is what we should do in every single place essentially.

OTHERS: But it's different from…

OTHERS: as we said, according to the type of environment.

OTHERS: No, no, no, no.

OTHERS: The requirements and the operations should be the same.

OTHERS: But the technology is different.

OTHERS: That's another thing.

OTHERS: Yeah, but that's what we're saying.

OTHERS: Like so we want to not have to deal with three different problems, which is variation.

OTHERS: We'll say we want to deal with one problem and adjust everything to that solution.

OTHERS: We'll say.

OTHERS: Exactly.

OTHERS: I mean, if we have something that is blocking us to use the approach we're using in OCI to call us, we need to eliminate those blockers, let's say.

OTHERS: So we can use the same technology stack if you want, or technology tools.

OTHERS: We are saying the same thing.

OTHERS: Okay.

OTHERS: We are saying the same thing.

OTHERS: What I'm trying to say here is, yes, you have the reason there.

OTHERS: We need to do the same thing across the different environments.

OTHERS: But the thing here is, basically in every single environment that we are trying to deploy, we should support this particular operations in the different phrases in the program.

OTHERS: That's a flow.

OTHERS: I get it.

OTHERS: So in a technical document like this will be a flow that will show the steps.

OTHERS: Yeah exactly.

OTHERS: But yeah, then with this in mind, with the tool that we choose, it's basically should be based in these things.

OTHERS: It should support, sorry, these things.

OTHERS: Yeah.

OTHERS: And then we have the tool.

OTHERS: The tool basically, we are all agree that we want to define the clusters using our city.

OTHERS: Okay.

OTHERS: Yeah.

OTHERS: Then there, that's the definition part.

OTHERS: Okay.

OTHERS: Then we have the orchestration part that it's basically where we need to discuss or we will celebrate the a little bit more.

OTHERS: Yeah, so we're going to, because the orchestration part is basically done by the deployer right now.

OTHERS: And then we need to take a decision here.

OTHERS: We want to orchestrate the deployment using Argos CD, the Argos Suite, I would say, or we want to use the operator.

OTHERS: That's what I wanted to say, because orchestration in some cases, it's over, not in some cases, the orchestration is being done in OCI, for example, by the operator, right?

OTHERS: So we just change values in a repository.

OTHERS: And then Argos CD kicks in.

OTHERS: And what happens in the MSE cluster has to do with how the operator is doing so, right?

OTHERS: Right.

OTHERS: So the orchestration in collo and this is in So ProDeployer.

OTHERS: that's the response.

OTHERS: Yeah, yeah, that's the difference.

OTHERS: So that's what I was saying.

OTHERS: And I liked your comment, Agustina, that we need, first of all, to maybe define better the life cycle of an MC cluster, which you said, like, it should be provisioning, operation and decommissioning, right?

OTHERS: And we want to talk right now, about the operation part, right?

OTHERS: Changing the, the MC, the express version, changing external configuration, and so on.

OTHERS: And we are doing-- The thing is, the operation will change, depending on how you provision the MC cluster.

OTHERS: Meaning, meaning on the underlying environment, like, if it's like-- If you decide to use the vote for the OCI model, and push the definitions to the Yergo CD repo.

YOU: I guess you're not going to see that by yourself.

YOU: So, sorry, I forgot to comment on this.

OTHERS: Then your operations to operate you have to go to the Argosaerito and edit those definitions versus you'll use the column model which is go through a pro-liploiere you then have to operate through pro-liploiere and yeah like I believe pro-liploiere is just a CLI it's not even a comp.

OTHERS: Yeah, yeah exactly.

OTHERS: The pro-liere it's a component on its own.

OTHERS: What I meant is the conversation is tied right we cannot discuss operations without discussing provisioning we have to discuss both the version.

YOU: I'm sorry, I forgot to comment on this.

OTHERS: Yeah look right now and that's the thing like right now we have those flavors we need to go to have prepared a document and say that our proposal is for example move away from pro-liploiere and plus config and go towards the OCI model.

OTHERS: And that's what we will put into a more technical document.

OTHERS: I believe.

OTHERS: And then we will try to implement part of it is like retrofitting what is already there.

OTHERS: But we're not for sure if we say that we're going to propose that we're going to follow the OCI model.

OTHERS: Like then there is no question.

OTHERS: Everything new should be provisioned in that way.

OTHERS: No matter where it is, except the case of Go Cloud, which I guess we still have some milestones.

OTHERS: We need to follow the OCI deployment.

OTHERS: I agree on that.

OTHERS: But we need to add adjustments to that part.

OTHERS: Because the orchestration is not working properly.

OTHERS: Right.

OTHERS: And I have a question about that.

OTHERS: I see two parts.

OTHERS: Either we first go with standardization.

OTHERS: I mean, use what we have right now.

OTHERS: choose between the OCI and color flavors and standardized using the chosen solution.

OTHERS: And then we improve that solution, like we make a lift to that solution.

OTHERS: Or we lift first, which means we create a new solution first, and then roll out that everywhere.

OTHERS: Because both of these methods, flavors, whatever we want to call it, have issues.

OTHERS: We have very tall stacks that we don't need.

OTHERS: We don't need these many layers, like our workflow, pushing things to our VACD, and then using the operator.

OTHERS: There's a lot of responsibilities overlapping, and we don't need these many tools in the provisioning stack or the additional stack or the decommissioning stack.

OTHERS: We don't need this many.

OTHERS: So we have to do improvements at some point, but we should decide maybe I was more of the idea of create the new thing, the new world, and then roll out everywhere.

YOU: So this is something that is not something that is something that's so evident, to have a model that could be left under the cost of bringing the end to the end.

YOU: This thing is the result.

OTHERS: But maybe what's happening is what your proposal is, more like choose the OCI model, go everywhere with that, and then in a second phase lift.

OTHERS: And make that a shelter.

OTHERS: Look, as I said, this is not a proposal, right?

OTHERS: That's exactly what it's a guideline for discussion.

OTHERS: And what you're saying now is very bad question.

OTHERS: And that's what I tried to capture also in the, with express operator and defining what is that blow-and-doll, say like my question is, should we invest in something that already exists or to something new, as you are saying.

OTHERS: And I'm fully like to go with each of those, like I'm not biased towards one or the other.

OTHERS: But I want us to understand that this is what we're doing and we put all the investment there.

OTHERS: Because for sure we're gonna dedicate man hours and like an effort to do something and solve this.

OTHERS: If it's like based on existing tools or like create something in you, it's up to us to decide.

OTHERS: Yeah, we want to stand that as first based on what we have right now.

OTHERS: I think we all agree or maybe we can discuss this right now, that the LCI flavor is more aligned with what we want.

OTHERS: Why?

OTHERS: Because it's declarative and we have a declarative vision and we have a desired state and we don't have the things with the column model and predi-player.

YOU: I would say that if you had a model that is actually is not a very good example of what we can do with it.

YOU: We have to be able to do it in the first place.

OTHERS: Predi-player just create things impenetively and then leave them and watch and reconcile.

YOU: We can do it in the first place.

YOU: So, we are going to have to be able to do it in the first place.

YOU: So, you can do it in the first place.

YOU: We can do it in the first place.

OTHERS: So if we want to take one of the solutions and standardize without doing any lift, I think we can agree that the OCI flavor would be the chosen one.

OTHERS: But please, right now, would be the time to say no.

OTHERS: We prefer the column.

OTHERS: No, we don't prefer the color flavor because as I said in the previous call, as I said in the previous call to me, it seems like we were trying to do get offs without even knowing, but without having the tools.

OTHERS: And that's why they came up with this XML sheet that they keep the definitions of things and then like they they translated to infrastructure, but today we have standardized tools to do that.

OTHERS: And so we should move and we already have a working example.

OTHERS: So it's like, doesn't make sense to still keep on doing what we would use to do because of necessity.

OTHERS: There are a lot of a bunch of different historical reasons that why we did the things the way we actually did.

OTHERS: It was tailored to Audora.

OTHERS: Yeah, yeah.

OTHERS: That's what they also understand.

OTHERS: And then when I think it's time to, okay, nowadays we are all agree that we are running Kubernetes.

OTHERS: We are all agree that we want to have the clarity things instead of having imperative things because you don't have reconciliation or imperative things.

OTHERS: And hence you have a bunch of different issues in production that we are having with the product probably right now.

OTHERS: So that's one thing.

OTHERS: The other thing is basically we have the tools.

OTHERS: So we need it.

OTHERS: Essentially, We are all…

OTHERS: I think we are all agree.

OTHERS: Let's.

YOU: If that's a situation you're not sure what…

OTHERS: as Hwkena said, have a word if not.

YOU: and it's not that…

YOU: if that's a situation you're not sure what's a situation you're not sure what's a situation you're not sure what's a situation you're not sure what's a situation you're not sure what's a situation you're not sure what's a situation you're not sure about…

OTHERS: But the thing is, we want to go to the clarity of things using Argosity and deploying in a no-ci-ish mode.

YOU: And what's a situation you're not sure about…

YOU: If that's a situation you're not sure about…

YOU: if that's a situation you're not sure about…

YOU: If that's a situation you're not sure about…

OTHERS: So if we have the agreement, it's fantastic, because we are all in the same page.

YOU: If that's a situation you're not…

OTHERS: And then we should dip dive a little bit on that.

YOU: If that's a situation you're not sure about…

OTHERS: What that means.

OTHERS: Yes.

YOU: And what's a situation you're not sure about…

YOU: If that's a situation you're not sure about…

OTHERS: We have the Argosity, which is the thing that we are going to declare there.

OTHERS: Then we can use, I don't know, I always say things on the air.

OTHERS: Just want it to give my vision here.

OTHERS: Either way, we go defining something in Argosity and then letting the operator orchestrate the whole circuits around that.

OTHERS: That's one thing.

OTHERS: The other thing is basically the legate that to Argosity and use, I don't know, waves to orchestrate the different steps.

YOU: There's a lot of things that we're not going to do.

OTHERS: That's the another option.

OTHERS: use a workflow, I go workflow, that's a third option.

OTHERS: I don't know.

OTHERS: We have several options to use the standard tools that we already have to deploy things in a more cool and at this way and in the class.

OTHERS: Okay.

OTHERS: But I have another question which comes from this.

OTHERS: Like, do we keep the CRDs or no?

OTHERS: That's the thing that we need to decide here.

OTHERS: Yeah.

OTHERS: It is a key question because if we decide to keep them, then it means that we need to invest in the orchestrator, which is like goes hand by hand with it.

OTHERS: If I can have the share, I will have some of that in in.

OTHERS: Yeah.

OTHERS: Let's say, yeah, I wanted to ask you to say.

OTHERS: Sorry for that, but we assume that we are going to go with the OCI-ish mode.

OTHERS: though.

OTHERS: And because that we have prepared a comparison table of great some points to the this.

OTHERS: That's also because we like the the claritiveness of the solution is a requirement that the solution has to be declared.

OTHERS: Everything is a claritim.

OTHERS: So, and go for the clarity, but in one, one more thing though to point out that because you mentioned there, we need to provision the same way and we don't need the workflows or whatever or data tickets to be open.

OTHERS: But there are you need to take under consideration that when we are provisioning some a cluster, there are other things outside the Kubernetes infrastructure that needs to happen.

OTHERS: So we need to create DNS records.

OTHERS: We need to talk to express up and we need to do a of things put internal DNS, external DNS and so on.

OTHERS: So these things still need to happen somehow.

OTHERS: Yeah, yeah.

OTHERS: And for this, we will still keep the workflow.

OTHERS: But I agree that there are even other ways that are for deployment.

OTHERS: Sorry.

OTHERS: That would be an upgrade.

OTHERS: Yeah.

OTHERS: Both solutions that we have here that we that can be done inside of a workflow can be done inside of an operator.

OTHERS: We can also try to to turn other or model other parts of the infrastructure in Kubernetes, like DNS records.

OTHERS: You could have a resource defining the DNS record and then a component like an operator just for the DNS records reconciling that resource and automatically running that call to that or anything.

OTHERS: But that's kind of out of our scope.

OTHERS: That's more or like an other services or a few, I think.

OTHERS: But those things could also be modeled in the Cornelist cluster.

OTHERS: Okay.

OTHERS: And we could, that way we make them the clarity too.

OTHERS: But.

OTHERS: Okay.

OTHERS: That's a nice to have.

OTHERS: So what we are trying to simplify and standardize the MSE production stack, deprecate the layers, we're overlapping responsibility, that's what I mentioned when I said, okay, we can take one of the solutions or flavors that we have right now, but we still at some point have to address this and maybe flatten the stack because a lot of tools in their overlap.

OTHERS: And if we can leverage Cornelist native and open source alternatives, that is great.

OTHERS: Why?

OTHERS: Because our current implementation is in parallel.

OTHERS: So if you can go to the previous one, the ones here that are overlapping, You mean as like…

OTHERS: we said, like pro deploy with the cluster config repository and what else like so.

OTHERS: So pro deploy your has a situation and operator can do the orchestration like it is doing it in in OCI and I understand side note that that logic has bugs but we haven't prioritized that fix because we don't know if we are going to keep that orchestration project but that is an overlap.

OTHERS: Another overlap is the argo cd_argo_workflow creating other coordinators resources like main spaces for the emmc tenant and other stuff.

OTHERS: That is what the operator does.

OTHERS: The operator translates from primary resource which is the backend and the frontend custom definitions that we created to secondary resources like pod network policies, disruption balance services, we could also add the namespace as a secondary resource and create it inside the operator.

OTHERS: So those are overlaps that are unneeded and we'll see.

OTHERS: And there's also the home chart.

OTHERS: The home chart also creates resources that could be secondary resources within the operator.

OTHERS: Okay.

OTHERS: And a question because like I know, for example, like in digital application that the clusters are multi-tenant or not clusters, we don't call them clusters, but the deployments and the environments there are like multi-tenant.

OTHERS: But I remember that whenever we needed a namespace to be created, we had to open a ticket somewhere.

OTHERS: I don't remember if it was your team like some other.

OTHERS: I don't think so.

OTHERS: We don't get requests for namespace creation.

OTHERS: We do get pull requests for namespaces creation.

OTHERS: We need the deployment security repository.

OTHERS: microservices themes just open for a few minutes.

OTHERS: there to add namespaces and roll-based access control to those namespaces and we reveal them.

OTHERS: In the premise, good thing.

YOU: and then you're going to be able to see that.

OTHERS: Yeah, and I think you have a tool to automatically create theOTHERS: With the, with the, with theOTHERS: Right, so that's an overlap.

YOU: So, if you're going to be able to see that, you're going to be able to see that.

OTHERS: We could be creating, we could automatically create the namespace and roll-based access control and everything that's in the glimpsiality in the express operator code.

OTHERS: Good, yeah, okay.

OTHERS: So, yeah, why you want to do this?

OTHERS: The current solution is imperative, at least in Carlos.

OTHERS: Our vision is declarative.

OTHERS: We want to use the reconciler pattern.

OTHERS: We want to have a desired state.

OTHERS: We want to follow, well, the current solution also follows abstractions from our old platform.

OTHERS: That's what we meant when we said the product lawyer was tailored to Aurora and to migrate to Grenadier is fast.

YOU: And there was a lot of issues with because that last lot.

OTHERS: We just made some changes and made it work, but it's a bit weird.

OTHERS: It lacks maintainers, has several layers with no clear responsibilities.

OTHERS: This is what we covered.

OTHERS: Anis different depending on the environment is what you mentioned about different flavors.

YOU: if the president had this advantage, and if he had to take his halfsurfaced options, the president would have to discuss his agency.

OTHERS: Requirements, we have the things that we have to support in this diagram that Kera showed.

OTHERS: For us, the clarity implementation is a must.

OTHERS: We have to go to the clarity.

OTHERS: Here I just copied what I saw in your document of high level requirements.

OTHERS: I think those are great.

OTHERS: We have and we maybe have to develop this a bit more, but not a lot.

OTHERS: As Kerman said, we don't want to go into super long conversation with this man.

OTHERS: in this first iteration?

OTHERS: Yeah yeah, let's go!

OTHERS: make it works and then we can, with the things working, we can have some show alerts to start having those conversations.

OTHERS: Yeah, because there is also like a big question for me because I know that a lot of teams started using this so-called the FAQ deployer and I do know that for QA environments, even for MEC classes like they do use the FAQ deployer, but and they were pushing other teams to use it so it kind of like it was pushed as a standard and I don't know if that's the answer for the MEC case or not.

OTHERS: But when it kind of, yeah, we need kind of like a tool that people can have visibility over what is being deployed, what is the state of the things that are being deployed and so on.

OTHERS: But yeah, as you say it's like a second iteration.

OTHERS: Let's focus on fixing those bigger problems right now.

OTHERS: Okay.

OTHERS: So we talked about flattening the provisioning and operational stack.

OTHERS: The two alternatives that we see is either go full, I will workflow or full express operator.

OTHERS: I will show the Lucidchub so we can see this bigger.

OTHERS: I'm doing it.

OTHERS: I'm not sure yet.

OTHERS: So this is separated in lanes.

OTHERS: So we have the development of this new deployer or provisional and thing that operates would be like, how the MEC provision would look like with this HFDs alternatives and how the operation of FNMC would look like with HFDs alternatives.

OTHERS: So for the development, this is super high level.

OTHERS: or have level high level, it doesn't have any detail, but just to spot some differences in the MEC design, depending on which one of these we choose.

OTHERS: So in the ARGO workflow, we would develop it, developing that would mean develop the scripts for every MEC steps, so if you look at this, we have a lot of provisioning steps, while approving in Provo also because we also lift the…

OTHERS: That's basically the proposal that they say, bringing to the table that it's cutting off some of the pieces that are not required.

OTHERS: We have upgrade steps and operations that need to be implemented, so the first step in this ARGO workflow, I'll turn and it the on.

OTHERS: development would be to develop all those scripts, the scripts that we need in each step of the workflow, the provisioning workflow and the operational workflows.

OTHERS: And we would have many workflows.

OTHERS: I think we would have like a workflow for provisioning or a workflow template for provisioning.

OTHERS: And workflows, their operation.

OTHERS: That's how I imagine it.

OTHERS: If you're not referring to the to the workflow that we already have.

OTHERS: No, no, I'm assuming that we need to be able to.

OTHERS: Just creating workflows without the abstraction layer that we already have, which is provisioning in Z.

OTHERS: I don't see.

OTHERS: Right.

OTHERS: And we wouldn't have-- OK.

OTHERS: Well, we can look at that in the next-- Yes.

OTHERS: But we wouldn't have custom definitions.

OTHERS: Whereas in the operator, we would design a custom resource it feels that can trigger the sound.

OTHERS: this operational steps, which is what we are lacking today.

OTHERS: Today, you can provision any C nodes by creating these custom resources, but you can't operate through the custom resource.

OTHERS: The only thing you can do is mark the express node as up or down with this field that we have, that is to state up and you can set it to true or false.

OTHERS: Which is using prot-deployer to manipulate.

OTHERS: And right?

OTHERS: You can use it directly, but yeah, prot-deployer is wrapping that and you can update that through prot-deployer, but you can also edit that through QCTM.

OTHERS: Okay.

OTHERS: And we would have to implement the operational steps in the express operator.

OTHERS: So the operator already catches edits.

OTHERS: Yeah, in the custom resource I'm and that triggers a reconciled not function.

YOU: And if the president had this advantage, the president would have to discuss his agency, and if the president had this advantage, the president would have to discuss his agency, and if the president had this advantage, the president would have to discuss his agency, and if the president had this advantage, and the other issues that we have in the past, we have been in the past, and the other side of the group is that this is a very important issue.

YOU: And that's what we have in this area.

OTHERS: We would have to check sure this operational fields and if how we see that I don't to know the field copy caches make is in true, the operator will have this.

OTHERS: to run the copy caches function and we would have to implement that function and implement that run.

OTHERS: So that's a difference.

OTHERS: Well here is just designing operational fields and implementing those operations.

YOU: Thank you.

OTHERS: Here is developing the scripts for everything the entire position and the operation and we would have to push the YAML definitions to the RACID report that is also code that we have to have and there's also instead to create the workflow templates for provisioning and a real operation that we need.

OTHERS: So, provision would look like, so in the ARGO workflows world, execute the workflow for with the right parameters to provision, I don't know, target NEC, execute the provisioning workload with the parameters that target needs.

OTHERS: And the workflow would push a state full set network policies ingress service, all the resources that you need to set up an NEC cluster to the ARGO CD repo.

OTHERS: Why?

OTHERS: Because we needed to be declarative and we needed to have a desired state.

OTHERS: So, we needed to have this step to push everything we create to the ARGO CD repo.

OTHERS: In the express operator world, it would be just push the custom resource representing that NEC or cluster.

YOU: I'm just going to ask you guys to go to the next slide.

OTHERS: all those, all the express nodes in that MEC cluster to the ARGO CD repo, the express operator would see that creation and translate the custom resource to pods network policies, ingress services creation, every other secondary resource that we need for an MEC cluster.

OTHERS: And the results would be the same in both, an MEC running in core and status.

OTHERS: I put a note here because I know that you guys like film in both alternatives we can use film or customize to ease the management of all the YAMOS that we would have.

OTHERS: We would be interfacing with a lot more YAMOS here in the solution, as you can see, because in this world we don't have a custom resource to wrap all this and to interface with.

OTHERS: So we would be interfacing with the stable set network policies in the, and here.

YOU: We've actually seen women singing about sex are moving out of their minds, their voices your voices and your voices.

YOU: The way we feel it and all that is going to be coming in the way we feel it.

YOU: We've already seen women singing by their minds.

YOU: We've also seen women singing by their minds.

YOU: We've seen women singing by their minds.

OTHERS: here in this world we would be interfacing with, depending on how we design it, something like we have right now, custom resource per express node, or we could also design custom resource for the entire cluster and have 10 plates for all the express nodes.

YOU: We've seen women singing.

OTHERS: That would be a long resource and that's why we didn't do that in the first place, but we could do it like that and that would be more like the stateful set that has the template for all.

OTHERS: So in the first one, you have a lot of flexibility because you can define everything there and the other, which is in the world, the world, I mean, in the operator's world, it's not that flexible, but it handles all the things without charging the operator in the definitions.

OTHERS: of those resources, right?

YOU: And now we're going to be talking about the rest of the discussion.

YOU: So I'm going to be talking to the other members.

YOU: So we're going to be talking about the rest of the discussion.

OTHERS: Right, and operation would be similar, but if you want, instead of covering operations right now, we can go to this, which is in line with what Herr mentioned.

OTHERS: That is, we try to run analysis of certain things that would be different in each world.

OTHERS: So here's what Herr said, in flexibility versus rig, sorry, someone says something.

OTHERS: No.

OTHERS: Ah, okay.

OTHERS: For our workflow, we think that scripts to provision and operate NEC would be fully exposed in the deployment repos.

OTHERS: This would make it flexible, since the study will have full control to change the scripts directly from the Atlas deployment repo, for example.

OTHERS: but there is no bill, no… artifact, no versioning.

YOU: I do want the details of this community.

YOU: Thank you so much, my friends.

OTHERS: It's changes to the scripts and the workflows would be only traceable by git commits, which is good, it's better than nothing.

OTHERS: But we think it would be a bit risky since any secretioning and operation wouldn't have a release process, wouldn't be part of a release process.

OTHERS: And we go a little bit deeper into that in the next one, but first the counterpart in the…

OTHERS: But hold on, this can be solved, right?

OTHERS: Because like you mentioned that this can go to Atlas deployment and my right didn't mean that but the scripts.

OTHERS: Yeah, the scripts would go in Atlas deployment.

OTHERS: That's why what would mean when we say they would be exposed in Atlas deployment, they wouldn't be part of a build in a separate repository.

OTHERS: Why?

OTHERS: And that's what I want to ask why?

OTHERS: because we are quotation That's how we manage our workflows today.

OTHERS: I haven't looked into yours, let me see one.

YOU: And I think that I am going to be the first to know what I am going to do.

YOU: So I think that's really good.

OTHERS: But that's generally what we do when we define a workflow template.

OTHERS: We have the script for every step of the workflow right there.

OTHERS: But I guess you could have images for the different steps in a separate repo and have a release process for all of those steps.

OTHERS: That's why we say here when we go to testing and we say, okay, there's no clear method to us to test an entire workflow into end.

OTHERS: But we could test the scripts in the middle.

OTHERS: Yeah.

OTHERS: That's actually what today's happening in the provisioning and the repository because we do have.

OTHERS: but it's like kind of set a weird setting functionality because we have a crazy inheritance tree That's a different story, but what gives you the this gives you the ability is like that you can version it you can run Unity you can run integration tests and so on and you can make it more reliable And say this way, so that's why I'm not a big fan of like putting it in Atlas The glue I haven't seen that you are saying and if you could could you say maybe one example So I can see what it's all about because I've been seeing it like I thought it's all manifest there I didn't know that people are the partners.

OTHERS: Yeah, it's basically it's basically a long manifest with the scripts, but I But I But I believe you can instead of having the scripts exposed in the manifest you can have images, you can have it pointed to images and have the code out for.

OTHERS: We can edit this.

OTHERS: It was just to say that there is a difference here is in the express operator, we have a source in a separate repo that is built, we have an artifact, a single artifact with the code to provision and operate a MEC.

OTHERS: It is like flexible because a new version has to be released if MEC provisioning and operation changes.

OTHERS: But that is not the case if you have the scripts exposed in Atlassic Loinment, but it will be a case if you have the steps of the workflow in separate repos that are built and version.

OTHERS: And we found this optionless risk because the artifact, since there is an artifact we can follow really.

OTHERS: process and basically tested and validated and have some time to harden it in a pre-prod environment.

OTHERS: Yeah, because this is actually one of the other points that was visible in our document or became more visible.

OTHERS: And it was that everybody is afraid of the operator because of its blast radius.

OTHERS: And my response to that is like, okay, why the problem is the blast radius.

OTHERS: And like because I really believe that if you have proper unit testing, integration testing, end-to-end testing, and then you have stages, you can be pretty sure that a small change cannot bring down clusters, don't say.

OTHERS: Or you can cut it very, very early.

OTHERS: Yeah.

OTHERS: Think of the blast radius within the operator, it's basically the past, it happened, and an issue where.

OTHERS: I know.

OTHERS: All the clusters, the cluster won't reconcile you properly.

OTHERS: One people by hand start deleting CRDs and stuff like that.

OTHERS: And of course, those CRDs weren't backup again, but that's an entire different story.

OTHERS: Yeah, yeah.

OTHERS: Plus I believe like it needs a different solution.

OTHERS: Like as we said, like if we 45 and we'll create a solid pipeline that has a test and everything.

OTHERS: You have to say, last radius using the operator or using a workflow, which is basically you have the power to change things.

OTHERS: Yeah.

OTHERS: Okay.

OTHERS: Right.

YOU: is like for the express operator.

YOU: But what we currently don't have inside of the deployment repos is an artifact for like the definition of let's say the Helmchar Nociai Like we were kind of just creating like what will be the closest thing to versioning like and like subdirectories like 0.0.1 0.0.2 and then we're just swapping like there's a there's no proper artifact there.

YOU: I think

YOU: Right, just say that once you've got a feeler, that you want to go as far as you can, then be more focused.

YOU: As far as you can, for a bit there's still positive results.

OTHERS: But Golden, Evan, because like now the discussion is like and also, I just didn't mention it before that we like to use Helm's Earth.

YOU: Thank you so much.

YOU: Can you say it?

YOU: Thank you so much.

OTHERS: Okay, it's like, I don't know why this happened, but it happened and it's like for me, it's like something that I found in the team, but it doesn't mean that we cannot even question that.

YOU: Thank you, thank you.

YOU: Right, thank you very much.

YOU: Thank you, thank you.

YOU: Thank you.

YOU: Thank you, thank you.

OTHERS: Because I know that most of the company is using customized instead of for Helm.

OTHERS: And plus there's no…

OTHERS: good support for Helm Tards.

OTHERS: There's no good support as we said like for versioning Helm Tards and so on even in the deployment repo.

OTHERS: Like even Qvernotes are running against the customized or the Sado deployments are running against customized artifacts and not against Helm Tards artifacts.

OTHERS: So there is a yeah truth is we don't sorry no no no I've missed no no we do not support Helm in Argo City.

OTHERS: We are the maintainers of Argo City.

YOU: And so that's like…

YOU: So, what are I'll you say doing?

OTHERS: Not that we change code of or anything of Argo City with maintainer I mean that we take the upstream releases of Argo City and we deploy them in Atlas and we take care of Argo City's Helm and we also manage the Argo City Repos and we do not support But customize it can be used.

YOU: that I have been taking these events for six months, and I'm sure I'm gonna make it live in the past.

OTHERS: We haven't blocked the ability to use home or case on it or case on it or any of the other methods that our city has to build manifests.

OTHERS: But we decided to go to customize and all the governance around Atlas.

YOU: But the changes that I have in the past, as for the past, that I do have, that I do have to say, like I do, level up in the past, that I am already going to hang out with the past, and you know that I am going to jump.

OTHERS: It was made with customize in mind.

OTHERS: That's why Kievern thinks can fail.

OTHERS: The repository pipelines can fail if you use home.

OTHERS: The other thing is why is that it decided to use home to template a me scene instead of customize and you can create me because I wasn't part of this discussion.

OTHERS: But when I asked this question, the answer I got was we couldn't do it with customize because this is true customise.

OTHERS: leverages the kind, the name, and the namespace to do patches.

OTHERS: That's the way that you do templates without doing templates with customised you do patches instead of templates.

OTHERS: Now, I don't know if this can be work, if you can work around this with components or other features that customised has that we don't use a lot, we don't use a lot of components.

OTHERS: But I understand that was why they went for help because with help you can you can make the names and the namespaces a template too.

OTHERS: And when with customised you can just do overrides.

OTHERS: Hey folks, one thing I actually did, so I'm going to start recording.

OTHERS: stay if you want and regard the decision.

YOU: but I do.

OTHERS: And we are going to set some other time with Luis for the next week so we can continue.

OTHERS: We have a lot of things to discuss.

OTHERS: And yeah, okay.

OTHERS: So I'm stopping right now.

OTHERS: Okay.

OTHERS: Recording stopped.

OTHERS: And I will, if you want to stay and continue the conversation, just stay and record it.

OTHERS: If you don't have time to go have another meetings, let's have another session next week.

OTHERS: But let's have another session for sure.

OTHERS: But from now on, it's voluntary and it's like a relaxed discussion.

OTHERS: I would say if anybody wants to stay.

OTHERS: Go for it.

OTHERS: And really appreciate it.

OTHERS: Thank you.

OTHERS: Any other thing like this thing?

OTHERS: I will assign to you a hostina the decision.

OTHERS: so you can record.

OTHERS: Bye bye.

OTHERS: It's OK, I think Augustine, I think we don't need to record.

OTHERS: We can just maybe finish what you've thought.

OTHERS: OK.

OTHERS: So I'm sorry.

OTHERS: Yeah, I don't know.

OTHERS: Maybe we can revisit Helen and see if we can use customize.

OTHERS: And yeah.

OTHERS: Yeah.

OTHERS: No, I'm not for it.

OTHERS: I've had kind of a similar answer.

OTHERS: They told me that, but it was simpler that they couldn't accomplish what they wanted with the customized.

OTHERS: That's why they went to help.

OTHERS: You gave a more detailed answer.

OTHERS: But yeah, anyway, so from what I understand, you are saying like let's use as a German was saying like let's use vanilla things.

YOU: through.

OTHERS: And you in the artwork, local, you're saying.

OTHERS: get rid of CRDs, do everything with Kubernetes resources, and use Argo workflow to handle the operations.

OTHERS: Let's say that's one solution.

OTHERS: And the other one is like, uh-huh.

OTHERS: Yeah, that's one alternative to just go for Argo workflow without anything else.

OTHERS: And the other one is go to express operator without anything else.

OTHERS: Okay, okay.

OTHERS: But keep keeping in this case, the custom resources and extend the operator.

OTHERS: And one question, we have though, is today, like, let's say that I go and I delete a frontend.

OTHERS: Is the operator going to handle this or things are going to break?

OTHERS: If you delete the custom resource kind frontend or if you delete the pod called frontend.

OTHERS: Well, the kind.

OTHERS: They're kind is going to delete the front end and delete the part, delete the service associated to that front end because you're deleting the primary resource from the desired state.

OTHERS: So what the operator understands in that operation is that you no longer want to front them.

OTHERS: Yeah.

OTHERS: And they so okay.

OTHERS: And then like things this is going to cause problems to the to the class there.

OTHERS: You know, because because like what I cannot understand is like they are they people are saying that yeah kind of MECs fragile and like if you do a specific operation in the way you're not supposed to do you're going to cause problems. And I'm like is this because of the custom resources and because we're not using stateful sets will say instead.

OTHERS: No, no, no, no.

OTHERS: What is it?

OTHERS: Is it is it some thing in the way that MECs was developed and like there are no cues in between.

YOU: and from the roof.

OTHERS: I think they mean that.

OTHERS: I think they mean that you have to follow this order.

YOU: And if you want to get to the floor, just click on the page, and then you can see.

YOU: You can also click on the chat, then click on the detail, and then click on it.

YOU: And then click on the detail, a small amount of toilet paper for a decent toilet.

OTHERS: If you don't follow it to tradition or to upgrade, if you don't follow it because I asked this question too, why do we have to follow an order because in Kubernetes you just create everything you need and things might fail at first with like probes because other dependencies are not abyet but you have a consistent eventually and eventually everything runs and it's healthy.

YOU: We have a limited amount of toilet paper.

YOU: We have a lot of toilet paper and we have a small toilet paper which is the small toilet paper.

OTHERS: But I asked Larry for example why this is not the case with any scene and basically his answer was it's not that it's not the case.

YOU: We have a lot of toilet paper which is the small toilet paper which is the small toilet paper.

OTHERS: But sometimes if you create all of this at the same time and you don't follow it.

OTHERS: this order.

YOU: We have a lot of toilet paper which is the small toilet paper.

OTHERS: Sometimes the people provisioning can have like errors in the express notes, logs, stack traces and they end up in a state where they don't really know what's happening and how to fix it.

OTHERS: So they discover that if they follow this order, everything is fine.

OTHERS: It's like a recipe.

OTHERS: But it was kind of like a trial and error process to end up to this.

OTHERS: I don't know.

OTHERS: If you ask me platform, which is the theme that develops express, should give us the recipe to deploy.

OTHERS: Exactly.

OTHERS: Yeah.

OTHERS: Bye.

OTHERS: Thank you.

YOU: I have a little bit of experience with this with DCR.

YOU: And the most recent changes that they've been making, which have been enabling a dynamic topology, we're able to spend up 100 nodes in five minutes and then take them all down.

YOU: And then those are recognized by the expressed apology.

YOU: So like these changes that would make it easier for us to deploy express in this less, I'd say, complicated way, I think they're coming and I think we should account for them.

OTHERS: I think that we should definitely have some sync with maybe a very brief one, because we don't want to have a lot of complexity in this project.

OTHERS: But maybe we should have some sync with platform and have them review this diagrams. And ask them if this is still necessary, because for example, here, I found two steps that are no longer necessary.

OTHERS: Yeah, I think they marked the end of red the things script.

OTHERS: that we do not require anymore.

OTHERS: Yeah.

OTHERS: It would be nice to have a partnership with a platform.

OTHERS: I think after we come with a technical, say more technical, more detailed document, like we should invite them to review.

OTHERS: Yeah.

YOU: Yeah, Sargeo would absolutely love that.

OTHERS: I know.

OTHERS: Okay.

OTHERS: In one last question, maybe.

OTHERS: So out of the two solutions, which one you're proposing, or which one you prefer?

OTHERS: Like, and according because you know more, what's the pros and cons of it?

OTHERS: I do not know more.

OTHERS: We know how to deploy Express.

OTHERS: We don't know how to operate Express.

OTHERS: That's a part that you know.

OTHERS: The all these things in config repo, we never touch config repo.

OTHERS: I just look at that configuration.

OTHERS: It's okay, it's externalized.

OTHERS: configuration, it's like values that you need for to make specific, like I don't know, say what is your URL, because maybe your application needs to know it.

OTHERS: It's like, you know, it's like, not like in the operation of the code itself, we'll say, when the procedure will say, you don't know what you're about.

YOU: So we have a few minutes left to discuss, I think that this is a very expensive situation.

YOU: I think that this is the most expensive situation.

OTHERS: That step is not part of the tooling I know and these operations, I'm not super familiar with them, I know that I'm being, yeah, I know that we can, I don't know, hit an express node in some end point to trigger them, but when we were asked to do the interpreter, the only requirement that we had from the study was we need to, a node, an express node, and be able to update its image, update its arguments, update, or turn it off, turn it on independently.

YOU: I think that this is a very expensive situation.

OTHERS: And that's why we want for an operator, and we couldn't go for a stafel sets.

YOU: I think that this is the most expensive situation.

YOU: This is the most expensive situation.

OTHERS: Because the stafel sets, you just have one template.

YOU: Hmm.

YOU: It's a very expensive situation.

YOU: Hmm.

YOU: It's a very expensive situation.

YOU: Hmm.

YOU: It's a very expensive situation.

YOU: Hmm.

OTHERS: You cannot have, I don't know, pod three, I would have five pods in a stafel set, you cannot grab pod number three and change the image, change things.

YOU: It's a very expensive situation.

YOU: Hmm.

YOU: It's a very expensive situation.

YOU: Hmm.

OTHERS: You just have one template, and everything is created from that template.

YOU: It's a very expensive situation.

YOU: Hmm.

YOU: It's a very expensive situation.

YOU: Hmm.

YOU: It's a very expensive situation.

YOU: Hmm.

YOU: It's a very expensive situation.

YOU: Hmm.

YOU: It's a very expensive situation.

YOU: Hmm.

YOU: It's a very expensive situation.

YOU: Hmm.

YOU: It's a very expensive situation.

YOU: Hmm.

OTHERS: That's why we didn't go for stafel sets, and that's why in this alternative, if we really want to interface with all of this, we would have to create, and I think it's here, we would have to create an stafel set per express node.

YOU: It's a very expensive situation.

OTHERS: Yeah.

YOU: Mm-hmm, yeah.

OTHERS: That thing balls, I I, would say that should involve the platforms team, because they need to make the application work like that.

OTHERS: So the need to fix the application.

YOU: I've been reading and writing recitigations, there were other activities, there were all other works, there were different types of recitations, there were several different technique that are good and effective in that way.

YOU: but for me it's too late to, for me, to be precise.

YOU: I would have asked a few of my viewers and feedbacks.

OTHERS: So that already that scenario with the Azure workflow is creating a huge dependency on us on that team, which we cannot control.

OTHERS: We don't have control over.

OTHERS: Yeah, that's part on, I think, platform could address part of that, but also release management has some requirements to just try and upgrade in a single front end.

OTHERS: Those types of requirements are coming from release management and not from platform.

OTHERS: But if we in the future go to release management and say, hey, this is not, I don't know, this design is not good for us for our operations.

OTHERS: We need to be able to deploy them.

YOU: is not good enough.

YOU: So this is going to be really, really well done.

YOU: There is a lot of different thing, especially in the military.

YOU: It's very good to be able to help.

OTHERS: in a in a stafel set and have all the copies of a front end from the same template.

OTHERS: So you need to drop these requirements.

YOU: If this is a company to take place, it's not working well enough, there's one thing I'm really going to do, and then the first thing that is it's not a company, is to be able to decide what to do.

YOU: They've just, always have a lot of skills.

YOU: There's one thing you can have about it.

OTHERS: Then with the thumbs up from release management, we go to platform and we say yeah just make it so we can have all of them from a template.

OTHERS: But I think we could run the same artifact from a…

YOU: Because this is a company that wants it to go on, and you can really help it go on.

YOU: And then you can actually help it to go on.

OTHERS: But I think what you said now, if release management has these type of requirements, it means that it goes deeper and like it means that probably the head out at this and people force them to take first in one front end so they don't bring the whole cluster down so customer cannot require credit from us.

OTHERS: And like I think that that's…

OTHERS: But it's an assumption means I could make assumptions but it sounds like it sounds like something like that.

OTHERS: Okay.

OTHERS: So, Evan, you wanted this example?

YOU: I think it's important to me.

YOU: and I think part of that requirement is due to the way that cash rebuilds are currently done, which is kind of like relying on one of the FE nodes.

YOU: But what we're like what we're effectively doing is decoupling the FE node that is currently the one that's rebuilding cash is or sorry being the synchronizer, which you know you choose say an FE node that's not down and it is going to be the synchronizer for the rest of the farmers.

YOU: Well we're no longer going to be using an FE node in the very near future.

YOU: So some of these requirements are also going to be changing for the better.

YOU: But I think we'll have to continue to revisit that.

YOU: And when we do talk to the platform because like the synchronizer node, right?

YOU: The synchronizer node is just an FE node.

YOU: And now that we have an FE node that we can just introduce to the topology without needing any specific configuration.

YOU: It just is dynamic.

YOU: The back of node doesn't need to be restarted or anything like that.

YOU: I think we're going to have a lot more flexibility than we currently have.

YOU: We're we have to do this node, that node, this node, because the back end needs to be aware.

YOU: It's just so I think we continue these conversations that we should have Sergio involved so he can speak to what he wants to see as the customer.

YOU: Because he definitely, I mean, I've talked to him a bit about it before.

YOU: Like his he doesn't he doesn't want to use the prod deployer.

YOU: He wants to be able to deploy like express like in in our in our go CD and how exactly we do that is up to us, but I think ideally within within our go CD.

OTHERS: Yeah!

YOU: There was another thing I wanted to mention about like the the two options we have here and like what I wanted to entertain and in terms of like meeting somewhere in the middle between these two things because I feel like I feel like it doesn't necessarily have to be one or the other.

OTHERS: I think, yeah, I do see that we could start mixing things.

OTHERS: So here at this point, because I don't think…

OTHERS: A human is actually pushing resources to an RCD repo or executing things.

OTHERS: I think you have a layer on top of this.

OTHERS: This would be a machine, something component.

OTHERS: Triggering execution of workflows or pushes to the RCD repo.

OTHERS: Based on, I don't know, G that takes it something like that.

OTHERS: I heard.

OTHERS: That's where I see another tool.

OTHERS: But if we want to use a mix of workflow and operator inside here, in the probation and the operation, I think we would really need to define really clearly the responsibility of the workflow and the operator.

OTHERS: Right now, we're in a situation.

OTHERS: like that.

OTHERS: We have the workflow and we have the operator.

OTHERS: And we have the operator creating like vanilla coordinates resources as secondary resources.

OTHERS: And we also have the workflow creating other resources like namespaces.

OTHERS: And we have the help creating things like network policies.

OTHERS: So we, one of the rules should be what the operator creates all the secondary resources.

OTHERS: And you just interface with the custom resource that represents the entire NEC cluster or a bunch of NEC nodes.

OTHERS: But all the network policy services in this are inside the operator.

OTHERS: And then yes, creating that custom resource, you have an network workflow that is monitoring, I don't know, GDA for provision requests and then pushes custom resource to the microsd network.

OTHERS: And we kind of already heard that.

OTHERS: That's probably the name of the idol.

YOU: I feel like where it benefits us we should leverage the operator and where it benefits us we should leverage a workflow like for example to make a commit to a repository and then wait for those syncs this changes to sync like Yeah, like I think the workflow in a perfect world is doing nothing more than making a commit to a repo and waiting for those resources to be of it they expected state as a result of that change and the operator it would be making those changes for us that in a perfect world I'd say but yeah because the operator was designed with you know in mind the prod deployer being the customer or the client it just is not possible right now which I feel is the reason the workflow has to make like compensate for that but yeah I would like to kind of move closer to this like this this way that we can like you said like define the role of what the operator should do what I'm going to do.

YOU: to help charge should do what the workflow should do so that we don't have to worry about duplicating efforts on any of these fronts, you know?

OTHERS: Yeah.

OTHERS: Okay.

OTHERS: Finally.

OTHERS: So I want to answer the question.

OTHERS: There were some issues of my preference is the operator.

OTHERS: Just because even if you remove this and you assume that we can, we can make artifacts for every workflow step and version them and test them as units and end to end.

OTHERS: Even if you remove this, having to interface with all of these and having a bunch of things with this.

OTHERS: We have a lot more of.

OTHERS: Banila Cornelius resources that represent an MEC cluster or that an enemy sea cluster needs to run, how interface with all of this, I think it would be worse than just interfacing with a custom resource that represents everything and just has a controller that translates and is able to manage all of the second that a resource under the hood.

OTHERS: Then I don't know if we got to these, but well, we could also show the state of the MSc cluster in that custom resource, like an aggregated state that is the state of all the secondary resources.

OTHERS: Failures we could see as we could publish as events, like you could do QCDL get events and get an express node or an express cluster is having issues.

OTHERS: I don't know how we could do that in workflows maybe they have events already.

OTHERS: And also if it fails, if the provision fails or anything fails, the operator will retry to, that means the reconciled sales between the desired state and the current state.

OTHERS: And the operator will continuously try to reconcile that, the desired and the current.

OTHERS: Whereas in the workflow, I don't know, I think you have a retrise, but eventually the workflow will fail and you have to look for it and, I don't know, deep, I get and rerun it.

OTHERS: But I don't know, it's a lot of work.

OTHERS: Moving all of the operations to an undesigning custom resource that can run all these operations is work.

OTHERS: Do you think, when it fits, if we give you a demo of what the provisioning and Z and the API server can do, or you are aware of it.

OTHERS: I don't think I'm aware of it.

OTHERS: I think we had a couple of demos of the workflow on the the data for deployments.

OTHERS: Yeah.

OTHERS: Yeah.

OTHERS: Yeah.

OTHERS: Yeah.

OTHERS: Yeah.

YOU: I remember in this picture, some people don't remember.

OTHERS: We can do in because we went a bit further, further with that and like now Camille also created a front end that you can see, it'll say easily outputs or log files from its step when it's running as a workflow and you can see failed or running state or completed and things like that anyway.

OTHERS: I think it's good to see what is there because we're thinking that this could be used in a second stage as a reporting mechanism or like for to increase visibility on deployment processes.

OTHERS: Anyway, so we know what kind of our framework can do and maybe it can fit so it can save us some effort.

OTHERS: But we also agree that investing in the operator and fixing the bugs or whatever and extending it is the right way to go.

OTHERS: Yeah, we haven't fixed them because we don't know if you guys are everyone, if we are aligned with moving forward with the express operator or not.

OTHERS: So it's not a priority because if we're going to move on with our workflows and just use vanilla coveninist resources, why fix it?

OTHERS: Yeah, look, I think that.

OTHERS: But I also like the, I'm sorry.

OTHERS: Go ahead, go ahead.

OTHERS: I also like the idea of just standardizing first with what we have and then doing this lift and then cleaning up the overlap of responsibility and the replicated responsibility that we have.

OTHERS: Yeah.

YOU: or What is it like to record it?

YOU: What is your name?

YOU: What is it like to record it?

YOU: What was the same thing?

YOU: What is it like to record it?

OTHERS: And actually, I think that we could do, I don't know if we can do this, if we have the visibility to do this, but if we could identify the blockers that we have to take the OCI flavor and move it to color and implement it in color, that would be amazing because we would have a view or we could estimate the effort to standardize first and then analyze these alternatives and flatten the stack.

YOU: but you still have so much to think about this.

YOU: How would that be?

YOU: It'll be more about the least of the questions.

YOU: Yeah, I think, yeah.

OTHERS: But we could do standardization earlier, I think.

YOU: It's kind of like, is there a difference with the lighting as well as the lighting?

YOU: Yes.

YOU: Yeah.

YOU: That's a really nice way of sounding here, especially with the lights on there, and the light is on, even for the lights on there?

YOU: Yeah.

YOU: And what about the lights?

YOU: Yeah, the lights on there, but this is different.

YOU: I think it's really different.

OTHERS: I don't know, I remember Michal mentioning that the ingress was one of the blockers, but right now Cedric is deployed in colors, so that wouldn't be a blocker anymore.

OTHERS: I don't know if it had anything else.

YOU: I think that the lights on here, 'cause the lights on here are on here, because the lights on there are also on there, and the light is on.

YOU: Very nice.

YOU: See you next time.

OTHERS: I don't know if we are the only ones that know.

OTHERS: about it.

OTHERS: I would ask now, good do you think it can give us this answer?

YOU: So it's because these are the actual pages-- it's not your own pages, but it's your own.

OTHERS: Like it goes, I can't.

YOU: And then some of these are the pages you're going to go through with the pages that you're using and the pages name that you're using, and to use them.

OTHERS: Maybe we don't have people anymore that can give us that answer, but maybe what we can do to find this out is just do a PLC, try to run an MEC cluster with that flavor in Golo and see where it breaks.

OTHERS: Yeah, maybe we can start with that.

YOU: So if you're using the pages that you have, simply text, and if you'd like to have a page that you're on, you're going to be using the same page.

OTHERS: Okay, okay, that's one, okay, good.

OTHERS: So we do have an action item.

OTHERS: I also make a note that we'll give you a demo of what provisioning in G is for, because it started as a way to provision new accounts for the MEC clusters, but it turned out to be an automation framework.

OTHERS: And because I know that database teams are using it for migrating databases, we do provisioning of other applications, with go to your IPR.

OTHERS: and create users and stuff like that.

OTHERS: So it's kind of more broader now, the use case.

OTHERS: It's not only that.

OTHERS: Or they use it for executing Groovy scripts in all MBC clusters and things like that.

OTHERS: So it's kind of more like an automation framework at the moment.

OTHERS: That's nice.

YOU: Yeah.

OTHERS: If we could include a provisioning of databases in this solution tool, it would be amazing because the current solution is, it's also something that was tailored to Aurora and it's not working very well in Kubernetes.

OTHERS: If DVC is out of the scope of this, we didn't consider it, but if we could include it, that would be amazing.

YOU: I would love to do that because the current way that we use PG scripts and run a job.

OTHERS: Yeah.

OTHERS: Doesn't make sense.

YOU: It's just it is even with our most ridiculous thing like.

OTHERS: Yeah, don't get excited because I think that's how the migration started happening.

OTHERS: We're still using some images.

YOU: I

OTHERS: provided by the BAs.

OTHERS: It looks.

OTHERS: Yeah, they are using PICY scripts for I.

OTHERS: I was present in the target migration.

OTHERS: The target DV migration today and they are using PICY scripts, but yeah, doesn't mean that we can.

OTHERS: Make it part of this list.

OTHERS: Okay, okay.

YOU: Like in OCIs, like they are provisioning databases via like, you know, the deployment repo and, uh, the health chart, or maybe not a health chart, maybe I don't know.

YOU: But what's the significance is that it's possible and that we should, like, if we can, um, account for that and this as well.

YOU: But, uh, something I also wanted to mention is that like, okay, these like huge migration efforts that we have from going from one deployment method to another are pretty, I mean, it's a lot of work and I, and I, and one thing I, I hope that we are able to do in this process is come up with, like a way to be able to do this work behind the scenes without having to do this massive migration so that like in the meantime L1 or whoever doesn't have to like no oh we're on we're using Prada Plotter for this express cluster.

YOU: Oh we're using OCI for this oh we're using this over using that like if through leveraging this automation framework we can make that decision not have to be made by them so that based on where it ever it is deployed that it can be triggered in that way so that's I just I like having gone through the DC migration effort I just it's so having to just sit there in my grade everything I hope that I hope that we can somehow avoid having to do that in this process of migrating to whatever the you know the new and improved deployment method is I hope that we can do that.

OTHERS: lets do here at the a Project Unicorn.

YOU: Yeah, the, uh, yeah.

YOU: Yeah.

OTHERS: Yeah, it little sounds like Yorovgan bit has a very of bad luck here.

OTHERS: steps Like, anyway.

OTHERS: Anyway, and okay.

OTHERS: What is that?

OTHERS: have

OTHERS: What you is that?

OTHERS: Have you …

OTHERS: heard about Project Phoenix have and Project Unicorn?

OTHERS: Books?

OTHERS: you

OTHERS: Oh, ….

OTHERS: Project Phoenix, are you ready?

OTHERS: Yeah, so you guys are second one.

YOU: , yeah.

OTHERS: Second one, which is called Project Unicorn.

OTHERS: Yeah.

OTHERS: It's kind of taking place in the same timeline, but different story.

OTHERS: It's nice.

YOU: Yeah.

OTHERS: I'm reading it right now.

OTHERS: Oh, I didn't know about that one.

OTHERS: Yeah, I will look it up.

OTHERS: Okay, let's put the full stop.

OTHERS: It was a great discussion.

OTHERS: I think we at least we agreed in some things.

OTHERS: And like, let's repeat it and like, we will take this step further.

OTHERS: Great.

OTHERS: Okay.

OTHERS: maybe for next time I would also say that is our agenda and you can and say what is your agenda so we can see what we're doing.

OTHERS: Like because the date was kind of weird.

OTHERS: Everybody had their own agenda.

OTHERS: Yeah.

YOU: Now remove the main material, make sure to remove spring drain and remove the excess water from the surface.

OTHERS: OK.

OTHERS: Let's sync on that on the SRA provision in China maybe.

OTHERS: Yeah, sure.

OTHERS: OK.

OTHERS: I believe that we are all.

OTHERS: So should we really see to do that?

OTHERS: OK.

OTHERS: See you guys.

OTHERS: Thanks.

OTHERS: Thank you.

OTHERS: Bye.

OTHERS: was an opportunity for me to do.

----

**Review and Standardization of Deployment Models**:
- The consensus was on the need to standardize deployment methods across different environments.
- The discussion leaned towards adopting the OCI model due to its declarative nature and the ability to maintain a desired state.
- However, there was also a suggestion to first identify blockers in transitioning other models (like the GovCloud or COLO) to the OCI model and potentially conduct a proof of concept to assess feasibility.

**Focus on Operator and Workflow Integration**:
- The group discussed the merits of using an operator versus workflows for deployment and operational tasks.
- There was a preference for using the operator due to its ability to manage and reconcile resources efficiently.
- However, there was also an acknowledgment that a combination of workflows and operators might be necessary for certain tasks, suggesting a more integrated approach.

**Automation and Simplification**:
- The need to simplify and automate processes was highlighted, particularly regarding database provisioning and deployment processes.
- The group discussed leveraging existing automation frameworks to streamline these processes.

**Project Demonstration and Collaboration**:
- A demonstration of what the PROV-NG can do was proposed for the next meeting.
- This would provide a clearer understanding of the capabilities and how they might be integrated into the current project.
- Collaboration with other teams, especially the platform team, was also deemed important to align strategies and understand technical requirements.

**Action Item – Deployment in Colo**:
- There was a specific action item to run a proof of concept on deploying using the OCI model in a COLO environment to identify any challenges or blockers.

**Further Discussion and Alignment**:
- The group acknowledged the need for further discussion to align on the technical direction, especially regarding the use of Helm charts versus customized solutions.
- There was also a suggestion to create a more detailed technical document for review in future meetings.

**Engage with Stakeholders**:
- Engaging with stakeholders such as release management and the platform team was suggested to ensure that all operational and deployment requirements are understood and considered in the standardization process.



---


Based on the transcript, several factors were discussed that might affect the decision to use workflows as a replacement for the express operator. Here are some key considerations:

1. **Flexibility and Control**: Workflows offer a high degree of flexibility since they allow for the execution of custom scripts and direct manipulation of deployment processes. However, this flexibility can also lead to complexity and less predictability in deployment and operational tasks.
2. **Complexity in Managing Resources**: Using workflows can lead to a situation where you're interfacing with a wide array of Kubernetes resources directly. This can be more complex and error-prone compared to using an operator, which abstracts and manages these resources.
3. **Automation and Reconciliation**: Operators are specifically designed to manage resources in a Kubernetes environment. They constantly work to ensure that the actual state of resources matches the desired state, automatically correcting any deviations. This continuous reconciliation process is a key feature of operators that might not be as efficiently handled by workflows.
4. **Integration with Existing Systems**: The express operator might already be integrated with existing systems and processes. Replacing it with workflows could require significant changes and reengineering, along with retraining of personnel.
5. **Testing and Reliability**: Operators, being more standardized, might offer more straightforward ways to test and ensure reliability. Workflows, while flexible, might require more extensive and complex testing processes to ensure they perform as expected.
6. **Versioning and Release Management**: The operator can be versioned and released as a single artifact, making it easier to manage and track changes. With workflows, especially if they involve multiple scripts and steps, versioning and release management can be more challenging.
7. **Failures and Error Handling**: Operators are generally designed to handle failures and errors by retrying operations or rolling back changes. With workflows, handling failures might require manual intervention or additional logic built into the workflow.
8. **Stakeholder Requirements**: The transcript mentioned that some requirements, such as those from release management, might be more aligned with the operator model. Switching to workflows could necessitate renegotiating these requirements or adapting them to fit a workflow-based approach.

In summary, while workflows offer flexibility and direct control, they also bring complexity and potential challenges in resource management, testing, and error handling. The express operator, being a more specialized tool within the Kubernetes ecosystem, offers benefits in terms of automation, reconciliation, and easier management of lifecycle and versioning. The decision to replace the operator with workflows would depend on balancing these factors against the specific needs and capabilities of the organization.


---
